Directory structure:
â””â”€â”€ almandine/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ devenv.lock
    â”œâ”€â”€ devenv.nix
    â”œâ”€â”€ devenv.yaml
    â”œâ”€â”€ go.mod
    â”œâ”€â”€ go.sum
    â”œâ”€â”€ install.ps1
    â”œâ”€â”€ install.sh
    â”œâ”€â”€ .devenv.flake.nix
    â”œâ”€â”€ .envrc
    â”œâ”€â”€ .pre-commit-config.yaml
    â”œâ”€â”€ _test_sandboxes/
    â”œâ”€â”€ cmd/
    â”‚   â””â”€â”€ almd/
    â”‚       â””â”€â”€ main.go
    â”œâ”€â”€ docs/
    â”‚   â””â”€â”€ SECURITY.md
    â”œâ”€â”€ internal/
    â”‚   â”œâ”€â”€ cli/
    â”‚   â”‚   â”œâ”€â”€ add/
    â”‚   â”‚   â”‚   â”œâ”€â”€ add.go
    â”‚   â”‚   â”‚   â””â”€â”€ add_test.go
    â”‚   â”‚   â”œâ”€â”€ init/
    â”‚   â”‚   â”‚   â”œâ”€â”€ init.go
    â”‚   â”‚   â”‚   â””â”€â”€ init_test.go
    â”‚   â”‚   â”œâ”€â”€ install/
    â”‚   â”‚   â”‚   â”œâ”€â”€ install.go
    â”‚   â”‚   â”‚   â””â”€â”€ install_test.go
    â”‚   â”‚   â”œâ”€â”€ list/
    â”‚   â”‚   â”‚   â”œâ”€â”€ list.go
    â”‚   â”‚   â”‚   â””â”€â”€ list_test.go
    â”‚   â”‚   â”œâ”€â”€ remove/
    â”‚   â”‚   â”‚   â”œâ”€â”€ remove.go
    â”‚   â”‚   â”‚   â””â”€â”€ remove_test.go
    â”‚   â”‚   â””â”€â”€ self/
    â”‚   â”‚       â””â”€â”€ self.go
    â”‚   â””â”€â”€ core/
    â”‚       â”œâ”€â”€ config/
    â”‚       â”‚   â”œâ”€â”€ config.go
    â”‚       â”‚   â””â”€â”€ config_test.go
    â”‚       â”œâ”€â”€ downloader/
    â”‚       â”‚   â”œâ”€â”€ downloader.go
    â”‚       â”‚   â””â”€â”€ downloader_test.go
    â”‚       â”œâ”€â”€ hasher/
    â”‚       â”‚   â”œâ”€â”€ hasher.go
    â”‚       â”‚   â””â”€â”€ hasher_test.go
    â”‚       â”œâ”€â”€ lockfile/
    â”‚       â”‚   â”œâ”€â”€ lockfile.go
    â”‚       â”‚   â””â”€â”€ lockfile_test.go
    â”‚       â”œâ”€â”€ project/
    â”‚       â”‚   â”œâ”€â”€ project.go
    â”‚       â”‚   â””â”€â”€ project_test.go
    â”‚       â””â”€â”€ source/
    â”‚           â”œâ”€â”€ github_api.go
    â”‚           â”œâ”€â”€ github_api_test.go
    â”‚           â”œâ”€â”€ source.go
    â”‚           â””â”€â”€ source_test.go
    â”œâ”€â”€ project/
    â”‚   â”œâ”€â”€ PRD.md
    â”‚   â””â”€â”€ TASKS.md
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â””â”€â”€ sign_releases.py
    â”œâ”€â”€ src/
    â”‚   â””â”€â”€ lib/
    â”œâ”€â”€ .cursor/
    â”œâ”€â”€ .devenv/
    â”œâ”€â”€ .direnv/
    â”œâ”€â”€ .github/
    â”‚   â”œâ”€â”€ copilot-instructions.md
    â”‚   â”œâ”€â”€ dependabot.yml
    â”‚   â”œâ”€â”€ scripts/
    â”‚   â”‚   â””â”€â”€ determine_next_version.py
    â”‚   â””â”€â”€ workflows/
    â”‚       â”œâ”€â”€ ci.yml
    â”‚       â”œâ”€â”€ codeql.yml
    â”‚       â”œâ”€â”€ dependency-review.yml
    â”‚       â”œâ”€â”€ release.yml
    â”‚       â”œâ”€â”€ scorecard.yml
    â”‚       â””â”€â”€ slsa-provenance.yml
    â”œâ”€â”€ .roo/
    â””â”€â”€ .slsa-goreleaser/
        â”œâ”€â”€ darwin-amd64.yml
        â”œâ”€â”€ darwin-arm64.yml
        â”œâ”€â”€ linux-amd64.yml
        â”œâ”€â”€ linux-arm64.yml
        â””â”€â”€ windows-amd64.yml

================================================
File: README.md
================================================
# Almandine â€“ Lua Package Manager ğŸ’

![License](https://img.shields.io/github/license/nightconcept/almandine)
![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/nightconcept/almandine/ci.yml)
[![Coverage Status](https://coveralls.io/repos/github/nightconcept/almandine/badge.svg)](https://coveralls.io/github/nightconcept/almandine)
![GitHub last commit](https://img.shields.io/github/last-commit/nightconcept/almandine)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/nightconcept/almandine/badge)](https://scorecard.dev/viewer/?uri=github.com/nightconcept/almandine)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10539/badge)](https://www.bestpractices.dev/projects/10539)

A modern, cross-platform, developer-friendly package manager for Lua projects.
Easily manage, install, and update Lua single-file dependencies..

## Features

- ğŸ“¦ **Easy Dependency Management**: Add, remove, and update Lua single-file dependencies with simple commands.
- ğŸ”’ **Reproducible Installs**: Lockfiles ensure consistent environments across machines.
- ğŸ› ï¸ **Cross-Platform**: Works on Linux, macOS, and Windows.

## ğŸš€ Installation

You can install `almd` by running the following commands in your terminal. These scripts will download and run the appropriate installer for your system from the `main` branch of the official repository.

### macOS and Linux

```sh
curl -LsSf https://raw.githubusercontent.com/nightconcept/almandine/main/install.sh | sh
```

### Windows

```powershell
powershell -ExecutionPolicy Bypass -c "irm https://raw.githubusercontent.com/nightconcept/almandine/main/install.ps1 | iex"
```
## Requirements

### macOS/Linux
- [Nix](https://nixos.org/)
- [devenv](https://devenv.sh/)

### Windows
- Go 1.24
- [pre-commit](https://pre-commit.com/)
- [xc](https://github.com/joerdav/xc) task runner

_Note: These can all be installed via Scoop._


## Usage

```sh
almd init                # Create a new Lua project
almd add <package>       # Add a dependency
almd remove <package>    # Remove a dependency
almd install             # Install dependencies
almd list                # List installed dependencies
almd self update         # Update almd
```

## Tasks

### build

Builds the `almd` binary.

```sh
go build -o build/almd ./cmd/almd
go build -o build/almd.exe ./cmd/almd
```

### lint

Run lint.

```sh
golangci-lint run
```

### test

Run tests.

```sh
go test ./...
```

### ready

Prepare for commit.

```sh
go test ./...
go fmt ./...
go vet ./...
go mod tidy -v
golangci-lint run --fix
gitingest -o project/digest.txt -e *.toml,*.txt,.roo/*,.cursor/*,build/*,.devenv/*,.direnv/*,project/digest.txt .
```

### sign

Sign releases with GPG key.

```sh
python scripts/sign_releases.py nightconcept/almandine --yes
```

### yolo

Build and install the `almd` binary to Windows.

```sh
go build -o build/almd.exe ./cmd/almd
pwsh.exe -ExecutionPolicy Bypass -File ./install.ps1 --local
```

## License

This project is licensed under the MIT License. See [LICENSE](docs/LICENSE) for details.



================================================
File: LICENSE
================================================
MIT License

Copyright (c) 2025 Danny Solivan

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
File: devenv.lock
================================================
{
  "nodes": {
    "devenv": {
      "locked": {
        "dir": "src/modules",
        "lastModified": 1746423062,
        "owner": "cachix",
        "repo": "devenv",
        "rev": "aba5cf8412827fdb637fceb2c305d10fcea907c6",
        "type": "github"
      },
      "original": {
        "dir": "src/modules",
        "owner": "cachix",
        "repo": "devenv",
        "type": "github"
      }
    },
    "flake-compat": {
      "flake": false,
      "locked": {
        "lastModified": 1733328505,
        "owner": "edolstra",
        "repo": "flake-compat",
        "rev": "ff81ac966bb2cae68946d5ed5fc4994f96d0ffec",
        "type": "github"
      },
      "original": {
        "owner": "edolstra",
        "repo": "flake-compat",
        "type": "github"
      }
    },
    "git-hooks": {
      "inputs": {
        "flake-compat": "flake-compat",
        "gitignore": "gitignore",
        "nixpkgs": [
          "nixpkgs"
        ]
      },
      "locked": {
        "lastModified": 1742649964,
        "owner": "cachix",
        "repo": "git-hooks.nix",
        "rev": "dcf5072734cb576d2b0c59b2ac44f5050b5eac82",
        "type": "github"
      },
      "original": {
        "owner": "cachix",
        "repo": "git-hooks.nix",
        "type": "github"
      }
    },
    "gitignore": {
      "inputs": {
        "nixpkgs": [
          "git-hooks",
          "nixpkgs"
        ]
      },
      "locked": {
        "lastModified": 1709087332,
        "owner": "hercules-ci",
        "repo": "gitignore.nix",
        "rev": "637db329424fd7e46cf4185293b9cc8c88c95394",
        "type": "github"
      },
      "original": {
        "owner": "hercules-ci",
        "repo": "gitignore.nix",
        "type": "github"
      }
    },
    "nixpkgs": {
      "locked": {
        "lastModified": 1745934659,
        "owner": "cachix",
        "repo": "devenv-nixpkgs",
        "rev": "fbc071e5c11e23fba50037de37268e3d8a1858eb",
        "type": "github"
      },
      "original": {
        "owner": "cachix",
        "ref": "rolling",
        "repo": "devenv-nixpkgs",
        "type": "github"
      }
    },
    "root": {
      "inputs": {
        "devenv": "devenv",
        "git-hooks": "git-hooks",
        "nixpkgs": "nixpkgs",
        "pre-commit-hooks": [
          "git-hooks"
        ]
      }
    }
  },
  "root": "root",
  "version": 7
}



================================================
File: devenv.nix
================================================
{ pkgs, inputs, ... }:

let
  xc = pkgs.buildGoModule rec {
    pname = "xc";
    version = "v0.8.5";
    subPackages = ["cmd/xc"];
    src = pkgs.fetchFromGitHub {
      owner = "joerdav";
      repo = "xc";
      rev = version;
      sha256 = "sha256-eaFHK7VsfLSgSJehv4urxq8qMPT+zzs2tRypz4q+MLc=";
    };
    vendorHash = "sha256-EbIuktQ2rExa2DawyCamTrKRC1yXXMleRB8/pcKFY5c=";
  };
in
{
  packages = with pkgs; [
    golangci-lint
    pre-commit
    xc
  ];

  languages.go = {
    enable = true;
  };
languages.python = {
    enable = true;
    venv.enable = true;
    venv.requirements = ''
      gitingest
      requests
      python-gnupg
    '';
  };

  enterShell = ''
    # Ensure pre-commit hook is installed/updated on direnv/devenv entry
    if [ -d .git ]; then
      pre-commit install --install-hooks --overwrite || true
    fi
  '';
}


================================================
File: devenv.yaml
================================================
# yaml-language-server: $schema=https://devenv.sh/devenv.schema.json
inputs:
  nixpkgs:
    url: github:cachix/devenv-nixpkgs/rolling

# If you're using non-OSS software, you can set allowUnfree to true.
# allowUnfree: true

# If you're willing to use a package that's vulnerable
# permittedInsecurePackages:
#  - "openssl-1.1.1w"

# If you have more than one devenv you can merge them
#imports:
# - ./backend



================================================
File: go.mod
================================================
module github.com/nightconcept/almandine

go 1.24.0

require (
	github.com/BurntSushi/toml v1.5.0
	github.com/Masterminds/semver/v3 v3.3.1
	github.com/creativeprojects/go-selfupdate v1.5.0
	github.com/fatih/color v1.18.0
	github.com/stretchr/testify v1.10.0
	github.com/urfave/cli/v2 v2.27.6
)

require (
	code.gitea.io/sdk/gitea v0.21.0 // indirect
	github.com/42wim/httpsig v1.2.2 // indirect
	github.com/cpuguy83/go-md2man/v2 v2.0.5 // indirect
	github.com/davecgh/go-spew v1.1.1 // indirect
	github.com/davidmz/go-pageant v1.0.2 // indirect
	github.com/go-fed/httpsig v1.1.0 // indirect
	github.com/google/go-github/v30 v30.1.0 // indirect
	github.com/google/go-querystring v1.1.0 // indirect
	github.com/hashicorp/go-cleanhttp v0.5.2 // indirect
	github.com/hashicorp/go-retryablehttp v0.7.7 // indirect
	github.com/hashicorp/go-version v1.7.0 // indirect
	github.com/mattn/go-colorable v0.1.13 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/pmezard/go-difflib v1.0.0 // indirect
	github.com/russross/blackfriday/v2 v2.1.0 // indirect
	github.com/ulikunitz/xz v0.5.12 // indirect
	github.com/xanzy/go-gitlab v0.115.0 // indirect
	github.com/xrash/smetrics v0.0.0-20240521201337-686a1a2994c1 // indirect
	golang.org/x/crypto v0.37.0 // indirect
	golang.org/x/oauth2 v0.29.0 // indirect
	golang.org/x/sys v0.32.0 // indirect
	golang.org/x/time v0.11.0 // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
)



================================================
File: go.sum
================================================
code.gitea.io/sdk/gitea v0.21.0 h1:69n6oz6kEVHRo1+APQQyizkhrZrLsTLXey9142pfkD4=
code.gitea.io/sdk/gitea v0.21.0/go.mod h1:tnBjVhuKJCn8ibdyyhvUyxrR1Ca2KHEoTWoukNhXQPA=
github.com/42wim/httpsig v1.2.2 h1:ofAYoHUNs/MJOLqQ8hIxeyz2QxOz8qdSVvp3PX/oPgA=
github.com/42wim/httpsig v1.2.2/go.mod h1:P/UYo7ytNBFwc+dg35IubuAUIs8zj5zzFIgUCEl55WY=
github.com/BurntSushi/toml v1.5.0 h1:W5quZX/G/csjUnuI8SUYlsHs9M38FC7znL0lIO+DvMg=
github.com/BurntSushi/toml v1.5.0/go.mod h1:ukJfTF/6rtPPRCnwkur4qwRxa8vTRFBF0uk2lLoLwho=
github.com/Masterminds/semver/v3 v3.3.1 h1:QtNSWtVZ3nBfk8mAOu/B6v7FMJ+NHTIgUPi7rj+4nv4=
github.com/Masterminds/semver/v3 v3.3.1/go.mod h1:4V+yj/TJE1HU9XfppCwVMZq3I84lprf4nC11bSS5beM=
github.com/cpuguy83/go-md2man/v2 v2.0.5 h1:ZtcqGrnekaHpVLArFSe4HK5DoKx1T0rq2DwVB0alcyc=
github.com/cpuguy83/go-md2man/v2 v2.0.5/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=
github.com/creativeprojects/go-selfupdate v1.5.0 h1:4zuFafc/qGpymx7umexxth2y2lJXoBR49c3uI0Hr+zU=
github.com/creativeprojects/go-selfupdate v1.5.0/go.mod h1:Pewm8hY7Xe1ne7P8irVBAFnXjTkRuxbbkMlBeTdumNQ=
github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/davidmz/go-pageant v1.0.2 h1:bPblRCh5jGU+Uptpz6LgMZGD5hJoOt7otgT454WvHn0=
github.com/davidmz/go-pageant v1.0.2/go.mod h1:P2EDDnMqIwG5Rrp05dTRITj9z2zpGcD9efWSkTNKLIE=
github.com/fatih/color v1.18.0 h1:S8gINlzdQ840/4pfAwic/ZE0djQEH3wM94VfqLTZcOM=
github.com/fatih/color v1.18.0/go.mod h1:4FelSpRwEGDpQ12mAdzqdOukCy4u8WUtOY6lkT/6HfU=
github.com/go-fed/httpsig v1.1.0 h1:9M+hb0jkEICD8/cAiNqEB66R87tTINszBRTjwjQzWcI=
github.com/go-fed/httpsig v1.1.0/go.mod h1:RCMrTZvN1bJYtofsG4rd5NaO5obxQ5xBkdiS7xsT7bM=
github.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=
github.com/google/go-cmp v0.5.2/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=
github.com/google/go-cmp v0.5.9 h1:O2Tfq5qg4qc4AmwVlvv0oLiVAGB7enBSJ2x2DqQFi38=
github.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=
github.com/google/go-github/v30 v30.1.0 h1:VLDx+UolQICEOKu2m4uAoMti1SxuEBAl7RSEG16L+Oo=
github.com/google/go-github/v30 v30.1.0/go.mod h1:n8jBpHl45a/rlBUtRJMOG4GhNADUQFEufcolZ95JfU8=
github.com/google/go-querystring v1.0.0/go.mod h1:odCYkC5MyYFN7vkCjXpyrEuKhc/BUO6wN/zVPAxq5ck=
github.com/google/go-querystring v1.1.0 h1:AnCroh3fv4ZBgVIf1Iwtovgjaw/GiKJo8M8yD/fhyJ8=
github.com/google/go-querystring v1.1.0/go.mod h1:Kcdr2DB4koayq7X8pmAG4sNG59So17icRSOU623lUBU=
github.com/hashicorp/go-cleanhttp v0.5.2 h1:035FKYIWjmULyFRBKPs8TBQoi0x6d9G4xc9neXJWAZQ=
github.com/hashicorp/go-cleanhttp v0.5.2/go.mod h1:kO/YDlP8L1346E6Sodw+PrpBSV4/SoxCXGY6BqNFT48=
github.com/hashicorp/go-hclog v1.6.3 h1:Qr2kF+eVWjTiYmU7Y31tYlP1h0q/X3Nl3tPGdaB11/k=
github.com/hashicorp/go-hclog v1.6.3/go.mod h1:W4Qnvbt70Wk/zYJryRzDRU/4r0kIg0PVHBcfoyhpF5M=
github.com/hashicorp/go-retryablehttp v0.7.7 h1:C8hUCYzor8PIfXHa4UrZkU4VvK8o9ISHxT2Q8+VepXU=
github.com/hashicorp/go-retryablehttp v0.7.7/go.mod h1:pkQpWZeYWskR+D1tR2O5OcBFOxfA7DoAO6xtkuQnHTk=
github.com/hashicorp/go-version v1.7.0 h1:5tqGy27NaOTB8yJKUZELlFAS/LTKJkrmONwQKeRZfjY=
github.com/hashicorp/go-version v1.7.0/go.mod h1:fltr4n8CU8Ke44wwGCBoEymUuxUHl09ZGVZPK5anwXA=
github.com/mattn/go-colorable v0.1.13 h1:fFA4WZxdEF4tXPZVKMLwD8oUnCTTo08duU7wxecdEvA=
github.com/mattn/go-colorable v0.1.13/go.mod h1:7S9/ev0klgBDR4GtXTXX8a3vIGJpMovkB8vQcUbaXHg=
github.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=
github.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=
github.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=
github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
github.com/russross/blackfriday/v2 v2.1.0 h1:JIOH55/0cWyOuilr9/qlrm0BSXldqnqwMsf35Ld67mk=
github.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=
github.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=
github.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=
github.com/ulikunitz/xz v0.5.12 h1:37Nm15o69RwBkXM0J6A5OlE67RZTfzUxTj8fB3dfcsc=
github.com/ulikunitz/xz v0.5.12/go.mod h1:nbz6k7qbPmH4IRqmfOplQw/tblSgqTqBwxkY0oWt/14=
github.com/urfave/cli/v2 v2.27.6 h1:VdRdS98FNhKZ8/Az8B7MTyGQmpIr36O1EHybx/LaZ4g=
github.com/urfave/cli/v2 v2.27.6/go.mod h1:3Sevf16NykTbInEnD0yKkjDAeZDS0A6bzhBH5hrMvTQ=
github.com/xanzy/go-gitlab v0.115.0 h1:6DmtItNcVe+At/liXSgfE/DZNZrGfalQmBRmOcJjOn8=
github.com/xanzy/go-gitlab v0.115.0/go.mod h1:5XCDtM7AM6WMKmfDdOiEpyRWUqui2iS9ILfvCZ2gJ5M=
github.com/xrash/smetrics v0.0.0-20240521201337-686a1a2994c1 h1:gEOO8jv9F4OT7lGCjxCBTO/36wtF6j2nSip77qHd4x4=
github.com/xrash/smetrics v0.0.0-20240521201337-686a1a2994c1/go.mod h1:Ohn+xnUBiLI6FVj/9LpzZWtj1/D6lUovWYBkxHVV3aM=
golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=
golang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=
golang.org/x/crypto v0.0.0-20210513164829-c07d793c2f9a/go.mod h1:P+XmwS30IXTQdn5tA2iutPOUgjI07+tq3H3K9MVA1s8=
golang.org/x/crypto v0.37.0 h1:kJNSjF/Xp7kU0iB2Z+9viTPMW4EqqsrywMXLJOOsXSE=
golang.org/x/crypto v0.37.0/go.mod h1:vg+k43peMZ0pUMhYmVAWysMK35e6ioLh3wB8ZCAfbVc=
golang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=
golang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=
golang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=
golang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=
golang.org/x/oauth2 v0.29.0 h1:WdYw2tdTK1S8olAzWHdgeqfy+Mtm9XNhv/xJsY65d98=
golang.org/x/oauth2 v0.29.0/go.mod h1:onh5ek6nERTohokkhCD/y2cV4Do3fxFHFuAejCkRWT8=
golang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
golang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.32.0 h1:s77OFDvIQeibCmezSnk/q6iAfkdiQaJi4VzroCFrN20=
golang.org/x/sys v0.32.0/go.mod h1:BJP2sWEmIv4KK5OTEluFJCKSidICx8ciO85XgH3Ak8k=
golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=
golang.org/x/term v0.31.0 h1:erwDkOK1Msy6offm1mOgvspSkslFnIGsFnxOKoufg3o=
golang.org/x/term v0.31.0/go.mod h1:R4BeIy7D95HzImkxGkTW1UQTtP54tio2RyHz7PwK0aw=
golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
golang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
golang.org/x/time v0.11.0 h1:/bpjEDfN9tkoN/ryeYHnv5hcMlc8ncjMcM4XBk5NWV0=
golang.org/x/time v0.11.0/go.mod h1:CDIdPxbZBQxdj6cxyCIdrNogrJKMJ7pr37NYpMcMDSg=
golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
google.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=



================================================
File: install.ps1
================================================
# Installer script for almd on Windows (PowerShell)
# Fetches and installs almd CLI from the latest (or specified) GitHub release, or locally with -local

$Repo = "nightconcept/almandine"
$AppHome = "$env:USERPROFILE\.almd"
$WrapperDir = "$env:LOCALAPPDATA\Programs\almd"
$TmpDir = [System.IO.Path]::Combine([System.IO.Path]::GetTempPath(), [System.Guid]::NewGuid().ToString())
$Version = $null
$LocalMode = $false

# Usage: install.ps1 [-local] [version]
foreach ($arg in $args) {
  if ($arg -eq '--local') {
    $LocalMode = $true
  } elseif (-not $Version) {
    $Version = $arg
  }
}

function Download($url, $dest) {
  if (Get-Command Invoke-WebRequest -ErrorAction SilentlyContinue) {
    Invoke-WebRequest -Uri $url -OutFile $dest -UseBasicParsing
  } elseif (Get-Command curl.exe -ErrorAction SilentlyContinue) {
    curl.exe -L $url -o $dest
  } elseif (Get-Command wget.exe -ErrorAction SilentlyContinue) {
    wget.exe $url -O $dest
  } else {
    Write-Error "Neither Invoke-WebRequest, curl, nor wget found. Please install one and re-run."
    exit 1
  }
}

function GithubApi($url) {
  if (Get-Command Invoke-RestMethod -ErrorAction SilentlyContinue) {
    return Invoke-RestMethod -Uri $url -UseBasicParsing
  } elseif (Get-Command curl.exe -ErrorAction SilentlyContinue) {
    $json = curl.exe -s $url
    return $json | ConvertFrom-Json
  } elseif (Get-Command wget.exe -ErrorAction SilentlyContinue) {
    $json = wget.exe -qO- $url
    return $json | ConvertFrom-Json
  } else {
    Write-Error "Neither Invoke-RestMethod, curl, nor wget found. Please install one and re-run."
    exit 1
  }
}

if ($LocalMode) {
  Write-Host "[DEV] Installing from local repository ..."
  New-Item -ItemType Directory -Path $AppHome -Force | Out-Null
  New-Item -ItemType Directory -Path $WrapperDir -Force | Out-Null
  Copy-Item -Path ./build/almd.exe -Destination (Join-Path $WrapperDir 'almd.exe') -Force
  Write-Host "[DEV] Local installation complete!"
  Write-Host "Make sure $WrapperDir is in your Path environment variable. You may need to restart your terminal or system."
  exit 0
}

if (!(Test-Path $TmpDir)) { New-Item -ItemType Directory -Path $TmpDir | Out-Null }

# Fetch latest tag from GitHub if version not specified
if ($Version) {
  $Tag = $Version
} else {
  Write-Host "Fetching Almandine version info ..."
  $TagsApiUrl = "https://api.github.com/repos/$Repo/tags?per_page=1"
  $Tags = GithubApi $TagsApiUrl
  if ($Tags -is [System.Array] -and $Tags.Count -gt 0) {
    $Tag = $Tags[0].name
  } elseif ($Tags.name) {
    $Tag = $Tags.name
  } else {
    Write-Error "Could not determine latest tag from GitHub."
    exit 1
  }
}

$VersionForAsset = if ($Tag.StartsWith("v")) { $Tag.Substring(1) } else { $Tag }
$AssetFilename = "almd_$($VersionForAsset)_windows_amd64.zip"
$ArchiveUrl = "https://github.com/$Repo/releases/download/$Tag/$AssetFilename"
$ArchiveName = $AssetFilename # Use the actual asset filename

Write-Host "Downloading Almandine release asset for tag $Tag ($AssetFilename) ..."
$ZipPath = Join-Path $TmpDir $ArchiveName
Download $ArchiveUrl $ZipPath

Write-Host "Extracting Almandine ..."
Add-Type -AssemblyName System.IO.Compression.FileSystem
# Extract almd.exe directly to the TmpDir, assuming it's at the root of the zip
[System.IO.Compression.ZipFile]::ExtractToDirectory($ZipPath, $TmpDir)

# almd.exe should now be directly in $TmpDir
$AlmdExePathInTmp = Join-Path $TmpDir "almd.exe"
if (!(Test-Path $AlmdExePathInTmp)) {
    Write-Error "Could not find almd.exe in the extracted archive at $AlmdExePathInTmp."
    # List files in TmpDir for debugging
    Write-Host "Contents of ${TmpDir}:"
    Get-ChildItem -Path $TmpDir | ForEach-Object { Write-Host $_.Name }
    exit 1
}

Write-Host "Installing Almandine ..."
# Check for previous install and warn if present
if (Test-Path $AppHome) {
  Write-Host ""
  Write-Host "âš ï¸  WARNING: Previous Almandine install detected at $AppHome. It will be OVERWRITTEN! âš ï¸" -ForegroundColor Yellow
  Write-Host ""
}
New-Item -ItemType Directory -Path $AppHome -Force | Out-Null
New-Item -ItemType Directory -Path $WrapperDir -Force | Out-Null

# Copy the binary to the wrapper directory
Copy-Item -Path $AlmdExePathInTmp -Destination (Join-Path $WrapperDir 'almd.exe') -Force

Write-Host "Installation complete!"
Write-Host "Make sure $WrapperDir is in your Path environment variable. You may need to restart your terminal or system."

Remove-Item -Recurse -Force $TmpDir



================================================
File: install.sh
================================================
#!/bin/sh
# Installer script for almd on Linux/macOS
# Fetches and installs almd from GitHub Releases, or locally with --local
# Requires: curl or wget, unzip, (jq optional for best experience)
set -e

REPO="nightconcept/almandine"
APP_HOME="$HOME/.almd"
PRIMARY_WRAPPER_DIR="/usr/local/bin"
FALLBACK_WRAPPER_DIR="$HOME/.local/bin"
WRAPPER_DIR=""
TMP_DIR="$(mktemp -d)"
VERSION=""
LOCAL_MODE=0

# Determine install location: /usr/local/bin (preferred), $HOME/.local/bin (fallback)
if [ -w "$PRIMARY_WRAPPER_DIR" ]; then
  WRAPPER_DIR="$PRIMARY_WRAPPER_DIR"
else
  WRAPPER_DIR="$FALLBACK_WRAPPER_DIR"
fi

# Usage: install.sh [--local] [version]
while [ $# -gt 0 ]; do
  case "$1" in
    --local)
      LOCAL_MODE=1
      ;;
    *)
      VERSION="$1"
      ;;
  esac
  shift
done

# Helper: download file (curl or wget)
download() {
  url="$1"
  dest="$2"
  if command -v curl >/dev/null 2>&1; then
    curl -L --fail --retry 3 -o "$dest" "$url"
  elif command -v wget >/dev/null 2>&1; then
    wget -O "$dest" "$url"
  else
    printf '%s\n' "Error: Neither curl nor wget found. Please install one and re-run." >&2
    exit 1
  fi
}

if [ "$LOCAL_MODE" -eq 1 ]; then
  printf '%s\n' "[DEV] Installing local almd binary..."
  mkdir -p "$APP_HOME" # Keep for potential app config/data

  # Ensure WRAPPER_DIR exists and copy the local binary 'almd' to it
  mkdir -p "$WRAPPER_DIR"
  cp ./build/almd "$WRAPPER_DIR/almd" # Use the 'almd' binary from the project root
  chmod +x "$WRAPPER_DIR/almd"

  printf '\n[DEV] Local almd binary installation complete!\n'
  printf 'Make sure %s is in your PATH. You may need to restart your shell.\n' "$WRAPPER_DIR"
  exit 0
fi

# Determine tag to install
if [ -n "$VERSION" ]; then
  TAG="$VERSION"
else
  printf '%s\n' "Fetching latest tag ..."
  TAG=$(curl -sL "https://api.github.com/repos/$REPO/tags?per_page=1" | \
    grep '"name"' | head -n1 | sed -E 's/ *\"name\": *\"([^\"]+)\".*/\1/')
  if [ -z "$TAG" ]; then
    printf '%s\n' "Error: Could not determine latest tag from GitHub." >&2
    exit 1
  fi
fi

ARCHIVE_URL="https://github.com/$REPO/archive/refs/tags/$TAG.zip"
ARCHIVE_NAME="$(echo "$REPO-$TAG.zip" | tr '/' '-')"

printf '%s\n' "Downloading archive for tag $TAG ..."
download "$ARCHIVE_URL" "$TMP_DIR/$ARCHIVE_NAME"

printf '%s\n' "Extracting CLI ..."
unzip -q -o "$TMP_DIR/$ARCHIVE_NAME" -d "$TMP_DIR"

# Find extracted folder (name format: almandine-<tag> or almandine-v<tag>)
EXTRACTED_DIR="$TMP_DIR/almandine-$TAG"
if [ ! -d "$EXTRACTED_DIR" ]; then
  EXTRACTED_DIR="$TMP_DIR/almandine-v$TAG"
  if [ ! -d "$EXTRACTED_DIR" ]; then
    printf '%s\n' "Error: Could not find extracted directory for tag $TAG." >&2
    exit 1
  fi
fi

printf '%s\n' "Installing CLI to $APP_HOME ..."
mkdir -p "$APP_HOME"
cp -r "$EXTRACTED_DIR/src" "$APP_HOME/"

printf '%s\n' "Installing wrapper script to $WRAPPER_DIR ..."
mkdir -p "$WRAPPER_DIR"
cp "$EXTRACTED_DIR/install/almd" "$WRAPPER_DIR/almd"
chmod +x "$WRAPPER_DIR/almd"

printf '\nInstallation complete!\n'
printf 'Make sure %s is in your PATH. You may need to restart your shell.\n' "$WRAPPER_DIR"

# Check if $WRAPPER_DIR is in PATH, recommend adding if missing
case ":$PATH:" in
  *:"$WRAPPER_DIR":*)
    # Already in PATH, nothing to do
    ;;
  *)
    printf '\n[INFO] %s is not in your PATH.\n' "$WRAPPER_DIR"
    if [ "$WRAPPER_DIR" = "$PRIMARY_WRAPPER_DIR" ]; then
      printf 'You may want to add it to your PATH or check your shell configuration.\n'
    else
      printf 'To add it, run (for bash):\n  echo ''export PATH="$HOME/.local/bin:$PATH"'' >> ~/.bashrc && source ~/.bashrc\n'
      printf 'Or for zsh:\n  echo ''export PATH="$HOME/.local/bin:$PATH"'' >> ~/.zshrc && source ~/.zshrc\n'
      printf 'Then restart your terminal or run ''exec $SHELL'' to reload your PATH.\n'
    fi
    ;;
esac

rm -rf "$TMP_DIR"



================================================
File: .devenv.flake.nix
================================================
{
  inputs =
    let
      version = "1.6.0";
system = "x86_64-linux";
devenv_root = "/home/danny/git/almandine";
devenv_dotfile = ./.devenv;
devenv_dotfile_string = ".devenv";
container_name = null;
devenv_tmpdir = "/run/user/1000/";
devenv_runtime = "/run/user/1000/devenv-8ad1c7f";
devenv_istesting = false;
devenv_direnvrc_latest_version = 1;

        in {
        git-hooks.url = "github:cachix/git-hooks.nix";
      git-hooks.inputs.nixpkgs.follows = "nixpkgs";
      pre-commit-hooks.follows = "git-hooks";
      nixpkgs.url = "github:cachix/devenv-nixpkgs/rolling";
      devenv.url = "github:cachix/devenv?dir=src/modules";
      } // (if builtins.pathExists (devenv_dotfile + "/flake.json")
      then builtins.fromJSON (builtins.readFile (devenv_dotfile +  "/flake.json"))
      else { });

      outputs = { nixpkgs, ... }@inputs:
        let
          version = "1.6.0";
system = "x86_64-linux";
devenv_root = "/home/danny/git/almandine";
devenv_dotfile = ./.devenv;
devenv_dotfile_string = ".devenv";
container_name = null;
devenv_tmpdir = "/run/user/1000/";
devenv_runtime = "/run/user/1000/devenv-8ad1c7f";
devenv_istesting = false;
devenv_direnvrc_latest_version = 1;

            devenv =
            if builtins.pathExists (devenv_dotfile + "/devenv.json")
            then builtins.fromJSON (builtins.readFile (devenv_dotfile + "/devenv.json"))
            else { };
          getOverlays = inputName: inputAttrs:
            map
              (overlay:
                let
                  input = inputs.${inputName} or (throw "No such input `${inputName}` while trying to configure overlays.");
                in
                  input.overlays.${overlay} or (throw "Input `${inputName}` has no overlay called `${overlay}`. Supported overlays: ${nixpkgs.lib.concatStringsSep ", " (builtins.attrNames input.overlays)}"))
              inputAttrs.overlays or [ ];
          overlays = nixpkgs.lib.flatten (nixpkgs.lib.mapAttrsToList getOverlays (devenv.inputs or { }));
          pkgs = import nixpkgs {
            inherit system;
            config = {
              allowUnfree = devenv.allowUnfree or false;
              allowBroken = devenv.allowBroken or false;
              permittedInsecurePackages = devenv.permittedInsecurePackages or [ ];
            };
            inherit overlays;
          };
          lib = pkgs.lib;
          importModule = path:
            if lib.hasPrefix "./" path
            then if lib.hasSuffix ".nix" path
            then ./. + (builtins.substring 1 255 path)
            else ./. + (builtins.substring 1 255 path) + "/devenv.nix"
            else if lib.hasPrefix "../" path
            then throw "devenv: ../ is not supported for imports"
            else
              let
                paths = lib.splitString "/" path;
                name = builtins.head paths;
                input = inputs.${name} or (throw "Unknown input ${name}");
                subpath = "/${lib.concatStringsSep "/" (builtins.tail paths)}";
                devenvpath = "${input}" + subpath;
                devenvdefaultpath = devenvpath + "/devenv.nix";
              in
              if lib.hasSuffix ".nix" devenvpath
              then devenvpath
              else if builtins.pathExists devenvdefaultpath
              then devenvdefaultpath
              else throw (devenvdefaultpath + " file does not exist for input ${name}.");
          project = pkgs.lib.evalModules {
            specialArgs = inputs // { inherit inputs; };
            modules = [
              ({ config, ... }: {
                _module.args.pkgs = pkgs.appendOverlays (config.overlays or [ ]);
              })
              (inputs.devenv.modules + /top-level.nix)
              {
                devenv.cliVersion = version;
                devenv.root = devenv_root;
                devenv.dotfile = devenv_root + "/" + devenv_dotfile_string;
              }
              (pkgs.lib.optionalAttrs (inputs.devenv.isTmpDir or false) {
                devenv.tmpdir = devenv_tmpdir;
                devenv.runtime = devenv_runtime;
              })
              (pkgs.lib.optionalAttrs (inputs.devenv.hasIsTesting or false) {
                devenv.isTesting = devenv_istesting;
              })
              (pkgs.lib.optionalAttrs (container_name != null) {
                container.isBuilding = pkgs.lib.mkForce true;
                containers.${container_name}.isBuilding = true;
              })
              ({ options, ... }: {
                config.devenv = pkgs.lib.optionalAttrs (builtins.hasAttr "direnvrcLatestVersion" options.devenv) {
                  direnvrcLatestVersion = devenv_direnvrc_latest_version;
                };
              })
            ] ++ (map importModule (devenv.imports or [ ])) ++ [
              (if builtins.pathExists ./devenv.nix then ./devenv.nix else { })
              (devenv.devenv or { })
              (if builtins.pathExists ./devenv.local.nix then ./devenv.local.nix else { })
              (if builtins.pathExists (devenv_dotfile + "/cli-options.nix") then import (devenv_dotfile + "/cli-options.nix") else { })
            ];
          };
          config = project.config;

          options = pkgs.nixosOptionsDoc {
            options = builtins.removeAttrs project.options [ "_module" ];
            warningsAreErrors = false;
            # Unpack Nix types, e.g. literalExpression, mDoc.
            transformOptions =
              let isDocType = v: builtins.elem v [ "literalDocBook" "literalExpression" "literalMD" "mdDoc" ];
              in lib.attrsets.mapAttrs (_: v:
                if v ? _type && isDocType v._type then
                  v.text
                else if v ? _type && v._type == "derivation" then
                  v.name
                else
                  v
              );
          };

          build = options: config:
            lib.concatMapAttrs
              (name: option:
                if builtins.hasAttr "type" option then
                  if option.type.name == "output" || option.type.name == "outputOf" then {
                    ${name} = config.${name};
                  } else { }
                else
                  let v = build option config.${name};
                  in if v != { } then {
                    ${name} = v;
                  } else { }
              )
              options;

          systems = [ "x86_64-linux" "aarch64-linux" "x86_64-darwin" "aarch64-darwin" ];
        in
        {
          devShell = lib.genAttrs systems (system: config.shell);
          packages = lib.genAttrs systems (system: {
            optionsJSON = options.optionsJSON;
            # deprecated
            inherit (config) info procfileScript procfileEnv procfile;
            ci = config.ciDerivation;
          });
          devenv = config;
          build = build project.options project.config;
        };
      }



================================================
File: .envrc
================================================
export DIRENV_WARN_TIMEOUT=20s

eval "$(devenv direnvrc)"

# The use_devenv function supports passing flags to the devenv command
# For example: use devenv --impure --option services.postgres.enable:bool true
use devenv



================================================
File: .pre-commit-config.yaml
================================================
# Top-level pre-commit config for Go project
repos:
  - repo: local
    hooks:
      - id: gofmt
        name: gofmt
        entry: gofmt -l -w
        language: golang
        types: [go]
      - id: go-vet
        name: go vet
        entry: go vet ./...
        language: golang
        types: [go]
        pass_filenames: false
      - id: go-mod-tidy
        name: go mod tidy
        entry: go mod tidy -v
        language: golang
        types: [go]
        files: ^go\.(mod|sum)$
        pass_filenames: false
        always_run: true
      - id: golangci-lint
        name: golangci-lint
        entry: golangci-lint run --fix
        language: system
        types: [go]
        pass_filenames: false
  - repo: https://github.com/gitleaks/gitleaks
    rev: v8.16.3
    hooks:
      - id: gitleaks
  - repo: https://github.com/jumanjihouse/pre-commit-hooks
    rev: 3.0.0
    hooks:
      - id: shellcheck
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: end-of-file-fixer
      - id: trailing-whitespace




================================================
File: cmd/almd/main.go
================================================
package main

import (
	"log"
	"os"

	"github.com/urfave/cli/v2"

	"github.com/nightconcept/almandine/internal/cli/add"
	initcmd "github.com/nightconcept/almandine/internal/cli/init"
	"github.com/nightconcept/almandine/internal/cli/install"
	"github.com/nightconcept/almandine/internal/cli/list"
	"github.com/nightconcept/almandine/internal/cli/remove"
	"github.com/nightconcept/almandine/internal/cli/self"
)

// version is the application version, set at build time.
var version = "dev" // Default to "dev" if not set by ldflags

// The main function, where the program execution begins.
func main() {
	app := &cli.App{
		Name:    "almd",
		Usage:   "Lua package manager for single-file dependencies",
		Version: version,
		Action: func(c *cli.Context) error {
			// Default action if no command is specified
			_ = cli.ShowAppHelp(c)
			return nil
		},
		Commands: []*cli.Command{
			initcmd.InitCmd(),
			add.AddCmd(),
			remove.RemoveCmd(),
			install.InstallCmd(),
			list.ListCmd(),
			self.SelfCmd(),
		},
	}

	if err := app.Run(os.Args); err != nil {
		log.Fatal(err)
	}
}



================================================
File: docs/SECURITY.md
================================================
# Security Policy

The Almandine team and community take the security of our software seriously. We appreciate your efforts to responsibly disclose your findings, and we will make every effort to acknowledge your contributions.

## Reporting a Vulnerability

If you believe you have found a security vulnerability in Almandine, please report it to us as soon as possible. We ask that you do not disclose the vulnerability publicly until we have had a chance to address it.

Please report vulnerabilities via one of the following methods:

* **Email:** Send an email to `[dark@nightconcept.net](mailto:dark@nightconcept.net)` with a detailed description of the vulnerability, steps to reproduce it, and any potential impact.
* **Issue Tracker (Private):** If you prefer, you can report the vulnerability through our private issue tracker `[here](https://github.com/nightconcept/almandine/security/advisories)`.

We aim to acknowledge receipt of your vulnerability report within **3 business days**.

## Disclosure Policy

Our goal is to address and fix any reported security vulnerability in a timely manner. Here is our general process:

1. **Confirmation:** We will confirm the vulnerability and determine its impact. We may contact you for more information during this phase. This typically takes up to **7 days**.
2. **Remediation:** Our team will work on a fix for the vulnerability. The timeline for this can vary depending on the complexity of the vulnerability, but we aim to have a patch ready within **30 days** of confirmation. For more complex issues, this might extend up to **90 days**.
3. **Disclosure:** Once the vulnerability is fixed and a new version is released, we will make a public disclosure. This disclosure will typically include a description of the vulnerability and credit to the reporter, unless you request to remain anonymous. We believe in transparent disclosure practices.

We are committed to a coordinated vulnerability disclosure process. We expect to work closely with the reporter throughout the lifecycle of the vulnerability.

## Scope

This policy applies to the latest stable release of Almandine. If you are using an older version, please consider upgrading before reporting a vulnerability, as it may have already been addressed.

## Out of Scope

The following are generally considered out of scope for our vulnerability disclosure program:

* Denial of service attacks that require significant volumetric resources.
*Social engineering or phishing attacks.
*Vulnerabilities in third-party dependencies (please report those to the respective projects, though we appreciate a heads-up if it impacts Almandine).

Thank you for helping keep Almandine secure. Your efforts in responsible disclosure are highly valued.



================================================
File: internal/cli/add/add.go
================================================
// Package add implements the 'add' command for Almandine CLI.
// It downloads external dependencies, saves them to the project,
// and maintains project configuration and lock files.
package add

import (
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/fatih/color"
	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/downloader"
	"github.com/nightconcept/almandine/internal/core/hasher"
	"github.com/nightconcept/almandine/internal/core/lockfile"
	"github.com/nightconcept/almandine/internal/core/project"
	"github.com/nightconcept/almandine/internal/core/source"
	"github.com/urfave/cli/v2"
)

func parseAddArgs(cCtx *cli.Context) (sourceURLInput, targetDir, customName string, verbose bool, err error) {
	if cCtx.NArg() > 0 {
		sourceURLInput = cCtx.Args().Get(0)
	} else {
		return "", "", "", false, fmt.Errorf("<source_url> argument is required")
	}
	targetDir = cCtx.String("directory")
	customName = cCtx.String("name")
	verbose = cCtx.Bool("verbose")
	return
}

func processSourceURL(sourceURLInput string) (*source.ParsedSourceInfo, error) {
	parsedInfo, err := source.ParseSourceURL(sourceURLInput)
	if err != nil {
		return nil, fmt.Errorf("parsing source URL '%s': %w", sourceURLInput, err)
	}
	return parsedInfo, nil
}

func downloadDependency(rawURL string) ([]byte, error) {
	fileContent, err := downloader.DownloadFile(rawURL)
	if err != nil {
		return nil, fmt.Errorf("downloading file from '%s': %w", rawURL, err)
	}
	return fileContent, nil
}

func determineFileNames(parsedInfo *source.ParsedSourceInfo, customName string) (dependencyNameInManifest, fileNameOnDisk string, err error) {
	suggestedBaseName := strings.TrimSuffix(parsedInfo.SuggestedFilename, filepath.Ext(parsedInfo.SuggestedFilename))
	suggestedExtension := filepath.Ext(parsedInfo.SuggestedFilename)

	if customName != "" {
		dependencyNameInManifest = customName
		fileNameOnDisk = customName + suggestedExtension
	} else {
		if suggestedBaseName == "" || suggestedBaseName == "." || suggestedBaseName == "/" {
			return "", "", fmt.Errorf("could not infer a valid base filename from URL's suggested filename: '%s'. Use -n to specify a name", parsedInfo.SuggestedFilename)
		}
		dependencyNameInManifest = suggestedBaseName
		fileNameOnDisk = parsedInfo.SuggestedFilename
	}

	if fileNameOnDisk == "" || fileNameOnDisk == "." || fileNameOnDisk == "/" {
		return "", "", fmt.Errorf("could not determine a valid final filename for saving. Inferred name was empty or invalid")
	}
	return dependencyNameInManifest, fileNameOnDisk, nil
}

func saveDependencyFile(projectRoot, targetDir, fileNameOnDisk string, fileContent []byte) (fullPath, relativeDestPath string, err error) {
	fullPath = filepath.Join(projectRoot, targetDir, fileNameOnDisk)
	relativeDestPath = filepath.ToSlash(filepath.Join(targetDir, fileNameOnDisk))

	dirToCreate := filepath.Dir(fullPath)
	if mkdirErr := os.MkdirAll(dirToCreate, 0755); mkdirErr != nil {
		return "", "", fmt.Errorf("creating directory '%s': %w", dirToCreate, mkdirErr)
	}

	if writeErr := os.WriteFile(fullPath, fileContent, 0644); writeErr != nil {
		return fullPath, "", fmt.Errorf("writing file '%s': %w", fullPath, writeErr) // Return fullPath for potential cleanup
	}
	return fullPath, relativeDestPath, nil
}

func calculateIntegrityHash(parsedInfo *source.ParsedSourceInfo, fileContent []byte) (string, error) {
	fileHashSHA256, hashErr := hasher.CalculateSHA256(fileContent)
	if hashErr != nil {
		return "", fmt.Errorf("calculating SHA256 hash: %w", hashErr)
	}

	isLikelyCommitSHA := func(ref string) bool {
		if len(ref) != 40 {
			return false
		}
		for _, r := range ref {
			if (r < '0' || r > '9') && (r < 'a' || r > 'f') && (r < 'A' || r > 'F') {
				return false
			}
		}
		return true
	}

	if parsedInfo.Provider == "github" && parsedInfo.Owner != "" && parsedInfo.Repo != "" && parsedInfo.PathInRepo != "" && parsedInfo.Ref != "" && !strings.HasPrefix(parsedInfo.Ref, "error:") {
		if isLikelyCommitSHA(parsedInfo.Ref) {
			return fmt.Sprintf("commit:%s", parsedInfo.Ref), nil
		}
		commitSHA, getCommitErr := source.GetLatestCommitSHAForFile(parsedInfo.Owner, parsedInfo.Repo, parsedInfo.PathInRepo, parsedInfo.Ref)
		if getCommitErr != nil {
			// Fallback to SHA256 if commit SHA cannot be fetched
			return fileHashSHA256, nil
		}
		return fmt.Sprintf("commit:%s", commitSHA), nil
	}
	return fileHashSHA256, nil
}

func updateProjectManifest(projectRoot, dependencyNameInManifest, canonicalURL, relativeDestPath string) error {
	proj, loadTomlErr := config.LoadProjectToml(projectRoot)
	if loadTomlErr != nil {
		if os.IsNotExist(loadTomlErr) {
			expectedProjectTomlPath := filepath.Join(projectRoot, config.ProjectTomlName)
			return fmt.Errorf("project.toml not found at '%s' (no such file or directory): %w", expectedProjectTomlPath, loadTomlErr)
		}
		return fmt.Errorf("loading %s: %w", config.ProjectTomlName, loadTomlErr)
	}

	if proj.Dependencies == nil {
		proj.Dependencies = make(map[string]project.Dependency)
	}
	proj.Dependencies[dependencyNameInManifest] = project.Dependency{
		Source: canonicalURL,
		Path:   relativeDestPath,
	}

	if writeTomlErr := config.WriteProjectToml(projectRoot, proj); writeTomlErr != nil {
		return fmt.Errorf("writing %s: %w", config.ProjectTomlName, writeTomlErr)
	}
	return nil
}

func updateLockfile(projectRoot, dependencyNameInManifest, rawURL, relativeDestPath, integrityHash string) error {
	lf, loadLockErr := lockfile.Load(projectRoot)
	if loadLockErr != nil {
		// If lockfile doesn't exist, Load creates a new one, so this error is likely a real issue.
		return fmt.Errorf("loading/initializing %s: %w", lockfile.LockfileName, loadLockErr)
	}

	lf.AddOrUpdatePackage(dependencyNameInManifest, rawURL, relativeDestPath, integrityHash)

	if saveLockErr := lockfile.Save(projectRoot, lf); saveLockErr != nil {
		return fmt.Errorf("saving %s: %w", lockfile.LockfileName, saveLockErr)
	}
	return nil
}

// AddCmd provides the CLI command definition for 'add'.
func AddCmd() *cli.Command {
	return &cli.Command{
		Name:      "add",
		Usage:     "Downloads a dependency and adds it to the project",
		ArgsUsage: "<source_url>",
		Flags: []cli.Flag{
			&cli.StringFlag{Name: "directory", Aliases: []string{"d"}, Usage: "Specify the target directory for the dependency", Value: "src/lib/"},
			&cli.StringFlag{Name: "name", Aliases: []string{"n"}, Usage: "Specify the name for the dependency (defaults to filename from URL)"},
			&cli.BoolFlag{Name: "verbose", Usage: "Enable verbose output"},
		},
		Action: func(cCtx *cli.Context) (err error) { // Named return 'err' for defer to access
			startTime := time.Now()
			projectRoot := "." // Assuming current directory is project root

			sourceURLInput, targetDir, customName, verbose, parseErr := parseAddArgs(cCtx)
			if parseErr != nil {
				err = cli.Exit(fmt.Sprintf("Error parsing 'add' arguments: %v", parseErr), 1)
				return
			}
			_ = verbose // Placeholder for future verbose logging

			parsedInfo, processURLErr := processSourceURL(sourceURLInput)
			if processURLErr != nil {
				err = cli.Exit(fmt.Sprintf("Error processing source URL '%s': %v", sourceURLInput, processURLErr), 1)
				return
			}

			fileContent, downloadErr := downloadDependency(parsedInfo.RawURL)
			if downloadErr != nil {
				err = cli.Exit(fmt.Sprintf("Error downloading from '%s': %v", parsedInfo.RawURL, downloadErr), 1)
				return
			}

			dependencyNameInManifest, fileNameOnDisk, determineNamesErr := determineFileNames(parsedInfo, customName)
			if determineNamesErr != nil {
				err = cli.Exit(fmt.Sprintf("Error determining file names: %v", determineNamesErr), 1)
				return
			}

			fullPath, relativeDestPath, saveFileErr := saveDependencyFile(projectRoot, targetDir, fileNameOnDisk, fileContent)
			// fileWritten is true if saveFileErr is nil, or if saveFileErr is not nil but fullPath was determined (meaning an attempt to write was made).
			fileWritten := saveFileErr == nil || (saveFileErr != nil && fullPath != "")

			// Defer cleanup logic. This runs when the Action function returns.
			// It checks the Action's named return 'err'.
			defer func() {
				if err != nil && fileWritten { // If the Action is returning an error AND a file was (potentially partially) written
					cleanupErr := os.Remove(fullPath)
					if cleanupErr != nil {
						var errWriter io.Writer = os.Stderr
						if cCtx.App != nil && cCtx.App.ErrWriter != nil {
							errWriter = cCtx.App.ErrWriter
						}
						_, _ = fmt.Fprintf(errWriter, "Warning: Failed to clean up downloaded file '%s' during error handling: %v\n", fullPath, cleanupErr)
					}
				}
			}()

			if saveFileErr != nil {
				err = cli.Exit(fmt.Sprintf("Error saving dependency file to '%s': %v. Attempting to clean up.", fullPath, saveFileErr), 1)
				return // This sets Action's 'err' and triggers the defer.
			}
			// At this point, file is successfully written.
			// Subsequent errors will set Action's 'err' and trigger the deferred cleanup.

			integrityHash, integrityHashErr := calculateIntegrityHash(parsedInfo, fileContent)
			if integrityHashErr != nil {
				err = cli.Exit(fmt.Sprintf("Error calculating integrity hash: %v. File '%s' was saved but is now being cleaned up.", integrityHashErr, fullPath), 1)
				return
			}

			manifestErr := updateProjectManifest(projectRoot, dependencyNameInManifest, parsedInfo.CanonicalURL, relativeDestPath)
			if manifestErr != nil {
				err = cli.Exit(fmt.Sprintf("Error updating project manifest: %v. File '%s' was saved but is now being cleaned up. %s may be in an inconsistent state.", manifestErr, fullPath, config.ProjectTomlName), 1)
				return
			}

			lockfileErr := updateLockfile(projectRoot, dependencyNameInManifest, parsedInfo.RawURL, relativeDestPath, integrityHash)
			if lockfileErr != nil {
				err = cli.Exit(fmt.Sprintf("Error updating lockfile: %v. File '%s' saved and %s updated, but lockfile operation failed. %s and %s may be inconsistent. Downloaded file '%s' is being cleaned up.", lockfileErr, fullPath, config.ProjectTomlName, config.ProjectTomlName, lockfile.LockfileName, fullPath), 1)
				return
			}

			// Success: print output
			_, _ = color.New(color.FgWhite).Println("Packages: +1")
			_, _ = color.New(color.FgGreen).Println("++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++")
			fmt.Println("Progress: resolved 1, downloaded 1, added 1, done")
			fmt.Println()
			_, _ = color.New(color.FgWhite, color.Bold).Println("dependencies:")
			dependencyVersionStr := parsedInfo.Ref
			if dependencyVersionStr == "" || strings.HasPrefix(dependencyVersionStr, "error:") {
				parts := strings.Split(parsedInfo.CanonicalURL, "@")
				if len(parts) > 1 {
					dependencyVersionStr = parts[len(parts)-1]
				} else {
					dependencyVersionStr = "latest" // Or some other default
				}
			}
			_, _ = color.New(color.FgGreen).Printf("+ %s %s\n", dependencyNameInManifest, dependencyVersionStr)
			fmt.Println()
			duration := time.Since(startTime)
			fmt.Printf("Done in %.1fs\n", duration.Seconds())

			return nil // Explicitly return nil on success
		},
	}
}



================================================
File: internal/cli/add/add_test.go
================================================
// Package add provides the 'add' command implementation for the Almandine CLI.
// Tests in this file verify the dependency addition behavior across various scenarios:
// - GitHub repository integration with version tags and commit hashes
// - Error handling for missing files, download failures, and write permissions
// - File management including cleanup on partial failures
package add

import (
	"fmt"
	"net/http"
	"net/http/httptest"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/BurntSushi/toml"
	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/lockfile"
	"github.com/nightconcept/almandine/internal/core/project"
	"github.com/nightconcept/almandine/internal/core/source"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"github.com/urfave/cli/v2"
)

// SetTestModeBypassHostValidation enables mock server testing without GitHub host validation.
// This is needed because the test mock server uses http:// instead of https://, which would
// normally be rejected by the GitHub client's host validation.
func init() {
	source.SetTestModeBypassHostValidation(true)
}

// setupAddTestEnvironment creates an isolated test environment with a project.toml.
// It returns the path to a temporary directory that will be automatically cleaned up
// after the test completes. The initialProjectTomlContent parameter allows tests to
// start with a specific project configuration.
func setupAddTestEnvironment(t *testing.T, initialProjectTomlContent string) (tempDir string) {
	t.Helper()
	tempDir = t.TempDir()

	if initialProjectTomlContent != "" {
		projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
		err := os.WriteFile(projectTomlPath, []byte(initialProjectTomlContent), 0644)
		require.NoError(t, err, "Failed to write initial project.toml")
	}
	return tempDir
}

// runAddCommand executes the 'add' command in a specific working directory.
// It temporarily changes the working directory and suppresses the CLI's default
// exit behavior to allow test assertions on command failures.
func runAddCommand(t *testing.T, workDir string, addCmdArgs ...string) error {
	t.Helper()

	originalWd, err := os.Getwd()
	require.NoError(t, err, "Failed to get current working directory")
	err = os.Chdir(workDir)
	require.NoError(t, err, "Failed to change to working directory: %s", workDir)
	defer func() {
		require.NoError(t, os.Chdir(originalWd), "Failed to restore original working directory")
	}()

	app := &cli.App{
		Name: "almd-test-add",
		Commands: []*cli.Command{
			AddCmd(),
		},
		// Suppress help printer during tests unless specifically testing help output
		Writer:    os.Stderr, // Default, or io.Discard for cleaner test logs
		ErrWriter: os.Stderr, // Default, or io.Discard
		ExitErrHandler: func(context *cli.Context, err error) {
			// Do nothing by default, let the test assertions handle errors from app.Run()
			// This prevents os.Exit(1) from urfave/cli from stopping the test run
		},
	}

	cliArgs := []string{"almd-test-add", "add"}
	cliArgs = append(cliArgs, addCmdArgs...)

	return app.Run(cliArgs)
}

// startMockServer creates a test HTTP server that simulates GitHub's API and raw content
// responses. It takes a map of paths to their corresponding responses, allowing tests to
// simulate both successful and error scenarios for API calls and file downloads.
func startMockServer(t *testing.T, pathResponses map[string]struct {
	Body string
	Code int
}) *httptest.Server {
	t.Helper()
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Construct path with query for matching, as GitHub API calls include queries.
		requestPathWithQuery := r.URL.Path
		if r.URL.RawQuery != "" {
			requestPathWithQuery += "?" + r.URL.RawQuery
		}

		for path, response := range pathResponses {
			// Allow simple path match or path with query match
			if r.Method == http.MethodGet && (r.URL.Path == path || requestPathWithQuery == path) {
				w.WriteHeader(response.Code)
				_, err := w.Write([]byte(response.Body))
				assert.NoError(t, err, "Mock server failed to write response body for path: %s", path)
				return
			}
		}
		t.Logf("Mock server: unexpected request: Method %s, Path %s, Query %s", r.Method, r.URL.Path, r.URL.RawQuery)
		http.NotFound(w, r)
	}))
	t.Cleanup(server.Close) // Ensure server is closed after the test
	return server
}

// readProjectToml parses and validates the project configuration files. They ensure the
// files are properly formatted and contain the expected content after command execution.
func readProjectToml(t *testing.T, tomlPath string) project.Project {
	t.Helper()
	bytes, err := os.ReadFile(tomlPath)
	require.NoError(t, err, "Failed to read project.toml: %s", tomlPath)

	var projCfg project.Project
	err = toml.Unmarshal(bytes, &projCfg)
	require.NoError(t, err, "Failed to unmarshal project.toml: %s", tomlPath)
	return projCfg
}

// readAlmdLockToml parses and validates the project configuration files. They ensure the
// files are properly formatted and contain the expected content after command execution.
func readAlmdLockToml(t *testing.T, lockPath string) project.LockFile {
	t.Helper()
	bytes, err := os.ReadFile(lockPath)
	require.NoError(t, err, "Failed to read almd-lock.toml: %s", lockPath)

	var lockCfg project.LockFile
	err = toml.Unmarshal(bytes, &lockCfg)
	require.NoError(t, err, "Failed to unmarshal almd-lock.toml: %s", lockPath)
	return lockCfg
}

// TestAddCommand_Success_ExplicitNameAndDir verifies the happy path for adding a
// dependency with explicit name (-n) and directory (-d) flags. This represents the
// most common usage pattern where users want control over dependency placement.
func TestAddCommand_Success_ExplicitNameAndDir(t *testing.T) {
	initialTomlContent := `
[package]
name = "test-project"
version = "0.1.0"
`
	tempDir := setupAddTestEnvironment(t, initialTomlContent)

	mockContent := "// This is a mock lua library content\nlocal lib = {}\nfunction lib.hello() print('hello from lua lib') end\nreturn lib\n"
	mockFileURLPath := "/testowner/testrepo/v1.0.0/mylib_script.lua"
	mockCommitSHA := "fixedmockshaforexplicittest1234567890"
	mockAPIPathForCommits := fmt.Sprintf("/repos/%s/%s/commits?path=%s&sha=%s&per_page=1", "testowner", "testrepo", "mylib_script.lua", "v1.0.0")
	mockAPIResponseBody := fmt.Sprintf(`[{"sha": "%s"}]`, mockCommitSHA)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		mockFileURLPath:       {Body: mockContent, Code: http.StatusOK},
		mockAPIPathForCommits: {Body: mockAPIResponseBody, Code: http.StatusOK},
	}
	mockServer := startMockServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	dependencyURL := mockServer.URL + mockFileURLPath
	dependencyName := "mylib"
	dependencyDir := "vendor/custom"

	err := runAddCommand(t, tempDir,
		"-n", dependencyName,
		"-d", dependencyDir,
		dependencyURL,
	)
	require.NoError(t, err, "almd add command failed")

	extractedSourceFileExtension := filepath.Ext(mockFileURLPath)
	expectedFileNameOnDisk := dependencyName + extractedSourceFileExtension

	downloadedFilePath := filepath.Join(tempDir, dependencyDir, expectedFileNameOnDisk)
	require.FileExists(t, downloadedFilePath, "Downloaded file does not exist at expected path: %s", downloadedFilePath)

	contentBytes, readErr := os.ReadFile(downloadedFilePath)
	require.NoError(t, readErr, "Failed to read downloaded file: %s", downloadedFilePath)
	assert.Equal(t, mockContent, string(contentBytes), "Downloaded file content mismatch")

	projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	projCfg := readProjectToml(t, projectTomlPath)

	require.NotNil(t, projCfg.Dependencies, "Dependencies map in project.toml is nil")
	depEntry, ok := projCfg.Dependencies[dependencyName]
	require.True(t, ok, "Dependency entry not found in project.toml for: %s", dependencyName)

	expectedCanonicalSource := "github:testowner/testrepo/mylib_script.lua@v1.0.0"
	assert.Equal(t, expectedCanonicalSource, depEntry.Source, "Dependency source mismatch in project.toml")
	assert.Equal(t, filepath.ToSlash(filepath.Join(dependencyDir, expectedFileNameOnDisk)), depEntry.Path, "Dependency path mismatch in project.toml")

	lockFilePath := filepath.Join(tempDir, "almd-lock.toml")
	require.FileExists(t, lockFilePath, "almd-lock.toml was not created")
	lockCfg := readAlmdLockToml(t, lockFilePath)

	assert.Equal(t, "1", lockCfg.APIVersion, "API version in almd-lock.toml mismatch")
	require.NotNil(t, lockCfg.Package, "Packages map in almd-lock.toml is nil")
	lockPkgEntry, ok := lockCfg.Package[dependencyName]
	require.True(t, ok, "Package entry not found in almd-lock.toml for: %s", dependencyName)

	assert.Equal(t, dependencyURL, lockPkgEntry.Source, "Package source mismatch in almd-lock.toml (raw URL)")
	assert.Equal(t, filepath.ToSlash(filepath.Join(dependencyDir, expectedFileNameOnDisk)), lockPkgEntry.Path, "Package path mismatch in almd-lock.toml")

	expectedHash := "commit:" + mockCommitSHA
	assert.Equal(t, expectedHash, lockPkgEntry.Hash, "Package hash mismatch in almd-lock.toml")
}

// TestAddCommand_Success_InferredName_DefaultDir verifies that dependencies can be
// added without explicit naming, testing the package's name inference logic and
// default directory placement when no -d flag is provided.
func TestAddCommand_Success_InferredName_DefaultDir(t *testing.T) {
	initialTomlContent := `
[package]
name = "test-project-inferred"
version = "0.1.0"
`
	tempDir := setupAddTestEnvironment(t, initialTomlContent)

	mockContent := "// This is a mock lua library for inferred name test\nlocal lib = {}\nreturn lib\n"
	mockFileURLPath_Inferred := "/inferredowner/inferredrepo/mainbranch/test_dependency_file.lua"
	mockCommitSHA_Inferred := "fixedmockshaforinferredtest1234567890"
	mockAPIPathForCommits_Inferred := fmt.Sprintf("/repos/%s/%s/commits?path=%s&sha=%s&per_page=1", "inferredowner", "inferredrepo", "test_dependency_file.lua", "mainbranch")
	mockAPIResponseBody_Inferred := fmt.Sprintf(`[{"sha": "%s"}]`, mockCommitSHA_Inferred)

	pathResps_Inferred := map[string]struct {
		Body string
		Code int
	}{
		mockFileURLPath_Inferred:       {Body: mockContent, Code: http.StatusOK},
		mockAPIPathForCommits_Inferred: {Body: mockAPIResponseBody_Inferred, Code: http.StatusOK},
	}
	mockServer := startMockServer(t, pathResps_Inferred)

	originalGHAPIBaseURL_Inferred := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL_Inferred }()

	dependencyURL := mockServer.URL + mockFileURLPath_Inferred

	err := runAddCommand(t, tempDir, dependencyURL)
	require.NoError(t, err, "almd add command failed")

	sourceFileName := filepath.Base(mockFileURLPath_Inferred)
	inferredDepName := strings.TrimSuffix(sourceFileName, filepath.Ext(sourceFileName))

	expectedDiskFileName := sourceFileName
	expectedDirOnDisk := "src/lib"
	downloadedFilePath := filepath.Join(tempDir, expectedDirOnDisk, expectedDiskFileName)

	require.FileExists(t, downloadedFilePath, "Downloaded file does not exist at expected path: %s", downloadedFilePath)
	contentBytes, readErr := os.ReadFile(downloadedFilePath)
	require.NoError(t, readErr, "Failed to read downloaded file: %s", downloadedFilePath)
	assert.Equal(t, mockContent, string(contentBytes), "Downloaded file content mismatch")

	projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	projCfg := readProjectToml(t, projectTomlPath)

	require.NotNil(t, projCfg.Dependencies, "Dependencies map in project.toml is nil")
	depEntry, ok := projCfg.Dependencies[inferredDepName]
	require.True(t, ok, "Dependency entry not found in project.toml for inferred name: %s", inferredDepName)

	expectedCanonicalSource := "github:inferredowner/inferredrepo/test_dependency_file.lua@mainbranch"
	assert.Equal(t, expectedCanonicalSource, depEntry.Source, "Dependency source mismatch in project.toml")

	expectedPathInToml := filepath.ToSlash(filepath.Join(expectedDirOnDisk, expectedDiskFileName))
	assert.Equal(t, expectedPathInToml, depEntry.Path, "Dependency path mismatch in project.toml")

	lockFilePath := filepath.Join(tempDir, "almd-lock.toml")
	require.FileExists(t, lockFilePath, "almd-lock.toml was not created")
	lockCfg := readAlmdLockToml(t, lockFilePath)

	assert.Equal(t, "1", lockCfg.APIVersion, "API version in almd-lock.toml mismatch")
	require.NotNil(t, lockCfg.Package, "Packages map in almd-lock.toml is nil")
	lockPkgEntry, ok := lockCfg.Package[inferredDepName]
	require.True(t, ok, "Package entry not found in almd-lock.toml for inferred name: %s", inferredDepName)

	assert.Equal(t, dependencyURL, lockPkgEntry.Source, "Package source mismatch in almd-lock.toml (raw URL)")
	assert.Equal(t, expectedPathInToml, lockPkgEntry.Path, "Package path mismatch in almd-lock.toml")

	expectedHash := "commit:" + mockCommitSHA_Inferred
	assert.Equal(t, expectedHash, lockPkgEntry.Hash, "Package hash mismatch in almd-lock.toml")
}

// TestAddCommand_GithubURLWithCommitHash verifies handling of GitHub URLs that
// specify exact commit hashes instead of tags/branches. This is important for
// users who need to pin dependencies to specific commits for reproducibility.
func TestAddCommand_GithubURLWithCommitHash(t *testing.T) {
	initialTomlContent := `
[package]
name = "test-project-commit-hash"
version = "0.1.0"
`
	tempDir := setupAddTestEnvironment(t, initialTomlContent)

	mockContent := "// Mock Lib with specific commit\nlocal lib = { info = \"version_commit123\" }\nreturn lib\n"
	directCommitSHA := "commitabc123def456ghi789jkl012mno345pqr"
	mockFileURLPath := fmt.Sprintf("/ghowner/ghrepo/%s/mylib.lua", directCommitSHA)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		mockFileURLPath: {Body: mockContent, Code: http.StatusOK},
	}
	mockAPIPathForCommits := fmt.Sprintf("/repos/ghowner/ghrepo/commits?path=mylib.lua&sha=%s&per_page=1", directCommitSHA)
	pathResps[mockAPIPathForCommits] = struct {
		Body string
		Code int
	}{
		Body: fmt.Sprintf(`[{"sha": "%s"}]`, directCommitSHA),
		Code: http.StatusOK,
	}
	mockServer := startMockServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL

	defer func() {
		source.GithubAPIBaseURL = originalGHAPIBaseURL
	}()

	dependencyURL := mockServer.URL + mockFileURLPath

	dependencyName := "mylibcommit"
	dependencyDir := "libs/gh"

	err := runAddCommand(t, tempDir,
		"-n", dependencyName,
		"-d", dependencyDir,
		dependencyURL,
	)
	require.NoError(t, err, "almd add command failed for GitHub URL with commit hash")

	expectedFileNameOnDisk := dependencyName + ".lua"
	downloadedFilePath := filepath.Join(tempDir, dependencyDir, expectedFileNameOnDisk)

	require.FileExists(t, downloadedFilePath)
	contentBytes, _ := os.ReadFile(downloadedFilePath)
	assert.Equal(t, mockContent, string(contentBytes))

	projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	projCfg := readProjectToml(t, projectTomlPath)
	depEntry, ok := projCfg.Dependencies[dependencyName]
	require.True(t, ok, "Dependency entry not found in project.toml")

	expectedCanonicalSource := fmt.Sprintf("github:ghowner/ghrepo/mylib.lua@%s", directCommitSHA)
	assert.Equal(t, expectedCanonicalSource, depEntry.Source)
	assert.Equal(t, filepath.ToSlash(filepath.Join(dependencyDir, expectedFileNameOnDisk)), depEntry.Path)

	lockFilePath := filepath.Join(tempDir, "almd-lock.toml")
	require.FileExists(t, lockFilePath)
	lockCfg := readAlmdLockToml(t, lockFilePath)
	lockPkgEntry, ok := lockCfg.Package[dependencyName]
	require.True(t, ok, "Package entry not found in almd-lock.toml")

	assert.Equal(t, dependencyURL, lockPkgEntry.Source)
	assert.Equal(t, filepath.ToSlash(filepath.Join(dependencyDir, expectedFileNameOnDisk)), lockPkgEntry.Path)

	expectedHashWithCommit := "commit:" + directCommitSHA
	assert.Equal(t, expectedHashWithCommit, lockPkgEntry.Hash, "Package hash mismatch in almd-lock.toml (direct commit hash)")
}

// TestAddCommand_DownloadFailure verifies proper error handling and cleanup when
// a dependency download fails. The test ensures no partial state is left behind
// in the project configuration or filesystem.
func TestAddCommand_DownloadFailure(t *testing.T) {
	initialTomlContent := `
[package]
name = "test-project-dlfail"
version = "0.1.0"
`
	tempDir := setupAddTestEnvironment(t, initialTomlContent)

	mockFileURLPath := "/owner/repo/main/nonexistent.lua"
	pathResps := map[string]struct {
		Body string
		Code int
	}{
		mockFileURLPath: {Body: "File not found", Code: http.StatusNotFound},
	}
	mockServer := startMockServer(t, pathResps)
	dependencyURL := mockServer.URL + mockFileURLPath

	err := runAddCommand(t, tempDir, dependencyURL)

	require.Error(t, err, "almd add command should return an error on download failure")

	if exitErr, ok := err.(cli.ExitCoder); ok {
		assert.Contains(t, exitErr.Error(), "downloading file from", "Error message should indicate download failure")
		assert.Contains(t, exitErr.Error(), "status code 404", "Error message should indicate 404 status")
	} else {
		assert.Fail(t, "Expected cli.ExitError for command failure")
	}

	expectedFilePath := filepath.Join(tempDir, "src/lib/nonexistent.lua")
	_, statErr := os.Stat(expectedFilePath)
	assert.True(t, os.IsNotExist(statErr), "Dependency file should not have been created on download failure")

	projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	projCfg := readProjectToml(t, projectTomlPath)
	assert.Equal(t, "test-project-dlfail", projCfg.Package.Name, "project.toml package name should be unchanged")
	assert.Len(t, projCfg.Dependencies, 0, "project.toml should have no dependencies after a failed add")

	lockFilePath := filepath.Join(tempDir, "almd-lock.toml")
	_, statErrLock := os.Stat(lockFilePath)
	assert.True(t, os.IsNotExist(statErrLock), "almd-lock.toml should not have been created on download failure")
}

// TestAddCommand_ProjectTomlNotFound verifies the error handling when attempting
// to add a dependency to a project without a project.toml file. This protects
// against accidental dependency additions outside of Almandine projects.
func TestAddCommand_ProjectTomlNotFound(t *testing.T) {
	tempDir := setupAddTestEnvironment(t, "")

	mockContent := "// Some content"
	mockFileURLPath := "/owner/repo/main/somefile.lua"
	pathResps := map[string]struct {
		Body string
		Code int
	}{
		mockFileURLPath: {Body: mockContent, Code: http.StatusOK},
	}
	mockServer := startMockServer(t, pathResps)
	dependencyURL := mockServer.URL + mockFileURLPath

	err := runAddCommand(t, tempDir, dependencyURL)

	require.Error(t, err, "almd add command should return an error when project.toml is not found")

	if exitErr, ok := err.(cli.ExitCoder); ok {
		assert.Contains(t, exitErr.Error(), "project.toml", "Error message should indicate project.toml was not found or could not be loaded")
		assert.Contains(t, exitErr.Error(), "no such file or directory", "Error message details should reflect os.IsNotExist")
	} else {
		assert.Fail(t, "Expected a cli.ExitError if command was to fail as per task requirements")
	}

	expectedFilePath := filepath.Join(tempDir, "src/lib/somefile.lua")
	_, statErr := os.Stat(expectedFilePath)
	assert.True(t, os.IsNotExist(statErr), "Dependency file should not have been created if project.toml is missing and command errored")

	lockFilePath := filepath.Join(tempDir, "almd-lock.toml")
	_, statErrLock := os.Stat(lockFilePath)
	assert.True(t, os.IsNotExist(statErrLock), "almd-lock.toml should not have been created if project.toml is missing and command errored")

	projectTomlPathMain := filepath.Join(tempDir, config.ProjectTomlName)
	_, statErrProject := os.Stat(projectTomlPathMain)
	assert.True(t, os.IsNotExist(statErrProject), "project.toml should not have been created by the add command if it was missing and an error was expected")
}

// TestAddCommand_CleanupOnFailure_LockfileWriteError verifies that the command
// properly cleans up any downloaded files and maintains project.toml consistency
// when it fails to write the lockfile. This is crucial for preventing partial
// or inconsistent project states that could break dependency management.
func TestAddCommand_CleanupOnFailure_LockfileWriteError(t *testing.T) {
	initialTomlContent := `
[package]
name = "test-cleanup-project"
version = "0.1.0"
`
	tempDir := setupAddTestEnvironment(t, initialTomlContent)
	projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)

	mockContent := "// Mock library content for cleanup test\\nlocal m = {}\\nfunction m.do() return 'ok' end\\nreturn m"

	mockOwner := "testowner"
	mockRepo := "testrepo"
	mockRef := "main"
	mockFileName := "mocklib.lua"
	mockFileURLPath := fmt.Sprintf("/%s/%s/%s/%s", mockOwner, mockRepo, mockRef, mockFileName)

	mockCommitSHA := "mockcleanupcommitsha1234567890"
	mockAPIPathForCommits := fmt.Sprintf("/repos/%s/%s/commits?path=%s&sha=%s&per_page=1", mockOwner, mockRepo, mockFileName, mockRef)
	mockAPIResponseBody := fmt.Sprintf(`[{"sha": "%s"}]`, mockCommitSHA)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		mockFileURLPath:       {Body: mockContent, Code: http.StatusOK},
		mockAPIPathForCommits: {Body: mockAPIResponseBody, Code: http.StatusOK},
	}
	mockServer := startMockServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	dependencyURL := mockServer.URL + mockFileURLPath

	sourceFileName := mockFileName
	expectedDepName := strings.TrimSuffix(sourceFileName, filepath.Ext(sourceFileName))
	defaultLibsDir := "src/lib"
	expectedDownloadedFilePath := filepath.Join(tempDir, defaultLibsDir, sourceFileName)

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	err := os.Mkdir(lockFilePath, 0755)
	require.NoError(t, err, "Test setup: Failed to create %s as a directory", lockfile.LockfileName)

	cmdErr := runAddCommand(t, tempDir, dependencyURL)

	require.Error(t, cmdErr, "almd add command should return an error due to lockfile write failure")

	if exitErr, ok := cmdErr.(cli.ExitCoder); ok {
		errorOutput := strings.ToLower(exitErr.Error())
		assert.Contains(t, errorOutput, "lockfile", "Error message should mention 'lockfile'")
		assert.Contains(t, errorOutput, lockfile.LockfileName, "Error message should mention the lockfile name")
		assert.Condition(t, func() bool {
			return strings.Contains(errorOutput, "is a directory") ||
				strings.Contains(errorOutput, "toml") ||
				strings.Contains(errorOutput, "permission denied")
		}, "Error message details should indicate a write/type issue with the lockfile path: %s", errorOutput)
	} else {
		lowerCmdErr := strings.ToLower(cmdErr.Error())
		assert.Contains(t, lowerCmdErr, "lockfile", "Direct error message should mention 'lockfile': %v", cmdErr)
		assert.Fail(t, "Expected command error to be a cli.ExitCoder, got %T: %v", cmdErr, cmdErr)
	}

	_, statErr := os.Stat(expectedDownloadedFilePath)
	assert.True(t, os.IsNotExist(statErr),
		"Downloaded dependency file '%s' should have been removed after lockfile write failure.", expectedDownloadedFilePath)

	projCfg := readProjectToml(t, projectTomlPath)
	depEntry, ok := projCfg.Dependencies[expectedDepName]
	require.True(t, ok, "Dependency '%s' should still be listed in project.toml. Current dependencies: %v", expectedDepName, projCfg.Dependencies)

	expectedCanonicalSource := fmt.Sprintf("github:%s/%s/%s@%s", mockOwner, mockRepo, mockFileName, mockRef)
	assert.Equal(t, expectedCanonicalSource, depEntry.Source, "Dependency source in project.toml for '%s' is incorrect", expectedDepName)
	assert.Equal(t, filepath.ToSlash(filepath.Join(defaultLibsDir, sourceFileName)), depEntry.Path,
		"Dependency path in project.toml is incorrect for '%s'", expectedDepName)

	lockFileStat, statLockErr := os.Stat(lockFilePath)
	require.NoError(t, statLockErr, "Should be able to stat the %s path (which is a directory)", lockfile.LockfileName)
	assert.True(t, lockFileStat.IsDir(), "%s should remain a directory", lockfile.LockfileName)

	_, err = os.ReadFile(lockFilePath)
	require.Error(t, err, "Attempting to read %s (which is a dir) as a file should fail", lockfile.LockfileName)
}



================================================
File: internal/cli/init/init.go
================================================
package init

import (
	"bufio"
	"fmt"
	"os"
	"strings"

	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/project"
	"github.com/urfave/cli/v2"
)

// promptWithDefault asks the user for input and returns the entered value or a default if input is empty.
// Returns an error if reading input fails.
func promptWithDefault(reader *bufio.Reader, promptText string, defaultValue string) (string, error) {
	if defaultValue != "" {
		fmt.Printf("%s (default: %s): ", promptText, defaultValue)
	} else {
		fmt.Printf("%s: ", promptText)
	}

	input, err := reader.ReadString('\n')
	if err != nil {
		return "", fmt.Errorf("failed to read input for '%s': %w", promptText, err)
	}
	input = strings.TrimSpace(input)
	if input == "" {
		return defaultValue, nil
	}
	return input, nil
}

// InitCmd returns the definition for the "init" command.
func InitCmd() *cli.Command {
	return &cli.Command{
		Name:  "init",
		Usage: "Initialize a new Almandine project (creates project.toml)",
		Action: func(c *cli.Context) error {
			fmt.Println("Starting project initialization...")

			reader := bufio.NewReader(os.Stdin)

			var packageName, version, license, description string
			var err error

			packageName, err = promptWithDefault(reader, "Package name", "my-almandine-project")
			if err != nil {
				return cli.Exit(err.Error(), 1)
			}

			version, err = promptWithDefault(reader, "Version", "0.1.0")
			if err != nil {
				return cli.Exit(err.Error(), 1)
			}

			license, err = promptWithDefault(reader, "License", "MIT")
			if err != nil {
				return cli.Exit(err.Error(), 1)
			}

			description, err = promptWithDefault(reader, "Description (optional)", "")
			if err != nil {
				return cli.Exit(err.Error(), 1)
			}

			fmt.Println("\n--- Collected Metadata ---")
			fmt.Printf("Package Name: %s\n", packageName)
			fmt.Printf("Version:      %s\n", version)
			fmt.Printf("License:      %s\n", license)
			fmt.Printf("Description:  %s\n", description)
			fmt.Println("--------------------------")

			scripts := make(map[string]string)

			if _, exists := scripts["run"]; !exists {
				scripts["run"] = "lua src/main.lua"
			}

			projectData := project.Project{
				Package: &project.PackageInfo{
					Name:        packageName,
					Version:     version,
					License:     license,
					Description: description,
				},
				Scripts: scripts,
			}

			err = config.WriteProjectToml(".", &projectData)
			if err != nil {
				return cli.Exit(fmt.Sprintf("Error writing project.toml: %v", err), 1)
			}

			fmt.Println("\nSuccessfully initialized project and wrote project.toml.")
			return nil
		},
	}
}



================================================
File: internal/cli/init/init_test.go
================================================
// Package init provides functionality for initializing new Almandine projects.
// Tests in this package verify the project initialization behavior and configuration generation.
package init

import (
	"bytes"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/BurntSushi/toml"
	"github.com/nightconcept/almandine/internal/core/project"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"github.com/urfave/cli/v2"
)

// simulateInput creates a pipe and writes the given inputs to simulate user input for prompts.
func simulateInput(inputs []string) (*os.File, *os.File, error) {
	r, w, err := os.Pipe()
	if err != nil {
		return nil, nil, err
	}
	inputString := strings.Join(inputs, "\n") + "\n"
	_, err = w.WriteString(inputString)
	if err != nil {
		_ = r.Close()
		_ = w.Close()
		return nil, nil, err
	}
	_ = w.Close()
	return r, w, nil
}

// captureOutput creates a pipe and buffer to capture stdout for testing.
func captureOutput() (*os.File, *os.File, *bytes.Buffer, error) {
	r, w, err := os.Pipe()
	if err != nil {
		return nil, nil, nil, err
	}
	var buf bytes.Buffer
	_, _ = w.Write([]byte{})
	return r, w, &buf, nil
}

// TestInitCommand verifies that the init command correctly handles custom user inputs
// and generates a valid project configuration with specified values. This test ensures
// the interactive prompts work and the resulting TOML file contains the expected content.
func TestInitCommand(t *testing.T) {
	tempDir, err := os.MkdirTemp("", "almandine_init_test")
	require.NoError(t, err, "Failed to create temporary directory")
	defer func() { _ = os.RemoveAll(tempDir) }()

	originalWd, err := os.Getwd()
	require.NoError(t, err, "Failed to get current working directory")
	err = os.Chdir(tempDir)
	require.NoError(t, err, "Failed to change to temporary directory")
	defer func() { _ = os.Chdir(originalWd) }()

	simulatedInputs := []string{
		"test-project",         // Package name
		"1.2.3",                // Version
		"Apache-2.0",           // License
		"A test project",       // Description
		"",                     // Empty script name (finish scripts)
		"my-dep",               // Dependency name 1
		"github.com/user/repo", // Dependency source 1
		"",                     // Empty dependency name (finish dependencies)
	}

	oldStdin := os.Stdin
	rStdin, _, err := simulateInput(simulatedInputs)
	require.NoError(t, err, "Failed to simulate stdin")
	os.Stdin = rStdin
	defer func() { os.Stdin = oldStdin; _ = rStdin.Close() }()

	oldStdout := os.Stdout
	rStdout, wStdout, _, err := captureOutput()
	require.NoError(t, err, "Failed to capture stdout")
	os.Stdout = wStdout
	defer func() { os.Stdout = oldStdout; _ = wStdout.Close(); _ = rStdout.Close() }()

	app := &cli.App{
		Name: "almandine-test",
		Commands: []*cli.Command{
			InitCmd(),
		},
	}

	runErr := app.Run([]string{"almandine-test", "init"})

	assert.NoError(t, runErr, "Init command returned an error")

	tomlPath := filepath.Join(tempDir, "project.toml")
	_, err = os.Stat(tomlPath)
	require.NoError(t, err, "project.toml was not created")

	tomlBytes, err := os.ReadFile(tomlPath)
	require.NoError(t, err, "Failed to read project.toml")

	var generatedConfig project.Project
	err = toml.Unmarshal(tomlBytes, &generatedConfig)
	require.NoError(t, err, "Failed to unmarshal project.toml")

	assert.Equal(t, "test-project", generatedConfig.Package.Name, "Package name mismatch")
	assert.Equal(t, "1.2.3", generatedConfig.Package.Version, "Version mismatch")
	assert.Equal(t, "Apache-2.0", generatedConfig.Package.License, "License mismatch")
	assert.Equal(t, "A test project", generatedConfig.Package.Description, "Description mismatch")

	expectedScripts := map[string]string{
		"run": "lua src/main.lua",
	}
	assert.Equal(t, expectedScripts, generatedConfig.Scripts, "Scripts mismatch")
}

// TestInitCommand_DefaultsAndEmpty verifies that the init command properly handles
// default values and empty inputs. This ensures the command maintains backward
// compatibility and provides sensible defaults when users skip optional inputs.
func TestInitCommand_DefaultsAndEmpty(t *testing.T) {
	tempDir, err := os.MkdirTemp("", "almandine_init_test_defaults")
	require.NoError(t, err, "Failed to create temporary directory")
	defer func() { _ = os.RemoveAll(tempDir) }()

	originalWd, err := os.Getwd()
	require.NoError(t, err, "Failed to get current working directory")
	err = os.Chdir(tempDir)
	require.NoError(t, err, "Failed to change to temporary directory")
	defer func() { _ = os.Chdir(originalWd) }()

	simulatedInputs := []string{
		"default-proj", // Package name
		"",             // Version (use default)
		"",             // License (use default)
		"",             // Description (empty)
		"",             // Empty script name (finish scripts)
		"",             // Empty dependency name (finish dependencies)
	}

	oldStdin := os.Stdin
	rStdin, _, err := simulateInput(simulatedInputs)
	require.NoError(t, err, "Failed to simulate stdin")
	os.Stdin = rStdin
	defer func() { os.Stdin = oldStdin; _ = rStdin.Close() }()

	oldStdout := os.Stdout
	rStdout, wStdout, _, err := captureOutput()
	require.NoError(t, err, "Failed to capture stdout")
	os.Stdout = wStdout
	defer func() { os.Stdout = oldStdout; _ = wStdout.Close(); _ = rStdout.Close() }()

	app := &cli.App{
		Name: "almandine-test",
		Commands: []*cli.Command{
			InitCmd(),
		},
	}
	runErr := app.Run([]string{"almandine-test", "init"})

	assert.NoError(t, runErr, "Init command returned an error")

	tomlPath := filepath.Join(tempDir, "project.toml")
	tomlBytes, err := os.ReadFile(tomlPath)
	require.NoError(t, err, "Failed to read project.toml")

	var generatedConfig project.Project
	err = toml.Unmarshal(tomlBytes, &generatedConfig)
	require.NoError(t, err, "Failed to unmarshal project.toml")

	assert.Equal(t, "default-proj", generatedConfig.Package.Name, "Package name mismatch")
	assert.Equal(t, "0.1.0", generatedConfig.Package.Version, "Version mismatch (default expected)")
	assert.Equal(t, "MIT", generatedConfig.Package.License, "License mismatch (default expected)")
	assert.Equal(t, "", generatedConfig.Package.Description, "Description should be empty")

	expectedScripts := map[string]string{
		"run": "lua src/main.lua",
	}
	assert.Equal(t, expectedScripts, generatedConfig.Scripts, "Scripts mismatch (only default expected)")

	assert.Nil(t, generatedConfig.Dependencies, "Dependencies should be nil/omitted")
}



================================================
File: internal/cli/install/install.go
================================================
// Package install implements the dependency installation functionality.
package install

import (
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strings"

	"github.com/urfave/cli/v2"

	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/downloader"
	"github.com/nightconcept/almandine/internal/core/hasher"
	"github.com/nightconcept/almandine/internal/core/lockfile"
	coreproject "github.com/nightconcept/almandine/internal/core/project"
	"github.com/nightconcept/almandine/internal/core/source"
)

// isCommitSHARegex matches valid Git commit SHAs of varying lengths (7-40 chars).
// This range covers both short and full-length commit hashes.
var isCommitSHARegex = regexp.MustCompile(`^[0-9a-f]{7,40}$`)

// dependencyToProcess tracks the source configuration for each dependency
// that needs to be processed during the install/update operation.
type dependencyToProcess struct {
	Name   string
	Source string
	Path   string
}

// dependencyInstallState tracks both the target state (from project.toml) and
// current state (from lockfile) for each dependency, along with resolution details.
type dependencyInstallState struct {
	Name              string
	ProjectTomlSource string
	ProjectTomlPath   string
	TargetRawURL      string
	TargetCommitHash  string
	LockedRawURL      string
	LockedCommitHash  string
	Provider          string
	Owner             string
	Repo              string
	PathInRepo        string
	NeedsAction       bool
	ActionReason      string
}

// loadInstallConfigAndArgs loads necessary configurations and parses CLI arguments.
func loadInstallConfigAndArgs(c *cli.Context) (projCfg *coreproject.Project, lf *lockfile.Lockfile, dependencyNames []string, force bool, verbose bool, err error) {
	verbose = c.Bool("verbose")
	force = c.Bool("force")

	if verbose {
		_, _ = fmt.Fprintln(os.Stdout, "Executing 'install' command...")
		if force {
			_, _ = fmt.Fprintln(os.Stdout, "Force install/update enabled.")
		}
	}

	dependencyNames = c.Args().Slice()
	if verbose {
		if len(dependencyNames) > 0 {
			_, _ = fmt.Fprintf(os.Stdout, "Targeted dependencies for install/update: %v\n", dependencyNames)
		} else {
			_, _ = fmt.Fprintln(os.Stdout, "Targeting all dependencies for install/update.")
		}
	}

	projCfg, err = config.LoadProjectToml(".")
	if err != nil {
		if errors.Is(err, os.ErrNotExist) {
			return nil, nil, nil, false, verbose, cli.Exit("Error: project.toml not found in the current directory. Please run 'almd init' first.", 1)
		}
		return nil, nil, nil, false, verbose, cli.Exit(fmt.Sprintf("Error loading project.toml: %v", err), 1)
	}
	if verbose {
		_, _ = fmt.Fprintf(os.Stdout, "Successfully loaded project.toml (Package: %s)\n", projCfg.Package.Name)
	}

	lf, err = lockfile.Load(".")
	if err != nil {
		// If lockfile doesn't exist, we initialize a new one instead of erroring out.
		// The install process will populate it.
		if errors.Is(err, os.ErrNotExist) {
			if verbose {
				_, _ = fmt.Fprintln(os.Stdout, "almd-lock.toml not found, will create a new one.")
			}
			lf = &lockfile.Lockfile{
				ApiVersion: lockfile.APIVersion,
				Package:    make(map[string]lockfile.PackageEntry),
			}
			err = nil // Clear the error as we've handled it by creating a new lockfile struct
		} else {
			return nil, nil, nil, false, verbose, cli.Exit(fmt.Sprintf("Error loading almd-lock.toml: %v", err), 1)
		}
	}

	if verbose && err == nil { // err == nil means lockfile was loaded or initialized successfully
		_, _ = fmt.Fprintln(os.Stdout, "Successfully loaded or initialized almd-lock.toml.")
	}

	if lf.Package == nil {
		lf.Package = make(map[string]lockfile.PackageEntry)
	}
	if lf.ApiVersion == "" {
		lf.ApiVersion = lockfile.APIVersion
	}
	return projCfg, lf, dependencyNames, force, verbose, nil
}

// collectDependenciesToProcess determines which dependencies to process based on arguments or all from project.toml.
func collectDependenciesToProcess(projCfg *coreproject.Project, dependencyNames []string, verbose bool) ([]dependencyToProcess, error) {
	var dependenciesToProcessList []dependencyToProcess

	if len(dependencyNames) == 0 {
		if len(projCfg.Dependencies) == 0 {
			_, _ = fmt.Fprintln(os.Stdout, "No dependencies found in project.toml to install/update.")
			return nil, nil // Return nil, nil to indicate no error but no work
		}
		if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "Processing all %d dependencies from project.toml...\n", len(projCfg.Dependencies))
		}
		for name, depDetails := range projCfg.Dependencies {
			dependenciesToProcessList = append(dependenciesToProcessList, dependencyToProcess{
				Name:   name,
				Source: depDetails.Source,
				Path:   depDetails.Path,
			})
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "  Targeting: %s (Source: %s, Path: %s)\n", name, depDetails.Source, depDetails.Path)
			}
		}
	} else {
		if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "Processing %d specified dependencies...\n", len(dependencyNames))
		}
		for _, name := range dependencyNames {
			depDetails, ok := projCfg.Dependencies[name]
			if !ok {
				_, _ = fmt.Fprintf(os.Stderr, "Warning: Dependency '%s' specified for install/update not found in project.toml. Skipping.\n", name)
				continue
			}
			dependenciesToProcessList = append(dependenciesToProcessList, dependencyToProcess{
				Name:   name,
				Source: depDetails.Source,
				Path:   depDetails.Path,
			})
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "  Targeting: %s (Source: %s, Path: %s)\n", name, depDetails.Source, depDetails.Path)
			}
		}
		if len(dependenciesToProcessList) == 0 {
			_, _ = fmt.Fprintln(os.Stdout, "No specified dependencies were found in project.toml to install/update.")
			return nil, nil // Return nil, nil to indicate no error but no work
		}
	}

	if verbose {
		_, _ = fmt.Fprintf(os.Stdout, "Total dependencies to process: %d\n", len(dependenciesToProcessList))
	}
	return dependenciesToProcessList, nil
}

// resolveInstallStates resolves the target and locked states for each dependency.
func resolveInstallStates(dependenciesToProcessList []dependencyToProcess, lf *lockfile.Lockfile, verbose bool) ([]dependencyInstallState, error) {
	var installStates []dependencyInstallState

	if verbose && len(dependenciesToProcessList) > 0 {
		_, _ = fmt.Fprintln(os.Stdout, "\nResolving target versions and current lock states...")
	}

	for _, depToProcess := range dependenciesToProcessList {
		if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "Processing dependency: %s (Source: %s)\n", depToProcess.Name, depToProcess.Source)
		}

		parsedSourceInfo, err := source.ParseSourceURL(depToProcess.Source)
		if err != nil {
			_, _ = fmt.Fprintf(os.Stderr, "Warning: Could not parse source URL for dependency '%s' (%s): %v. Skipping.\n", depToProcess.Name, depToProcess.Source, err)
			continue
		}

		var resolvedCommitHash = parsedSourceInfo.Ref
		var finalTargetRawURL = parsedSourceInfo.RawURL

		if parsedSourceInfo.Provider == "github" && !isCommitSHARegex.MatchString(parsedSourceInfo.Ref) {
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "  Ref '%s' for '%s' is not a full commit SHA. Attempting to resolve latest commit for path '%s'...\n", parsedSourceInfo.Ref, depToProcess.Name, parsedSourceInfo.PathInRepo)
			}
			latestSHA, err := source.GetLatestCommitSHAForFile(parsedSourceInfo.Owner, parsedSourceInfo.Repo, parsedSourceInfo.PathInRepo, parsedSourceInfo.Ref)
			if err != nil {
				_, _ = fmt.Fprintf(os.Stderr, "  Warning: Could not resolve ref '%s' to a specific commit for '%s': %v. Proceeding with ref as is.\n", parsedSourceInfo.Ref, depToProcess.Name, err)
			} else {
				if verbose {
					_, _ = fmt.Fprintf(os.Stdout, "  Resolved ref '%s' to commit SHA: %s for '%s'\n", parsedSourceInfo.Ref, latestSHA, depToProcess.Name)
				}
				resolvedCommitHash = latestSHA
				finalTargetRawURL = strings.Replace(parsedSourceInfo.RawURL, "/"+parsedSourceInfo.Ref+"/", "/"+latestSHA+"/", 1)
			}
		} else if verbose && parsedSourceInfo.Provider == "github" {
			_, _ = fmt.Fprintf(os.Stdout, "  Ref '%s' for '%s' appears to be a commit SHA. Using it directly.\n", parsedSourceInfo.Ref, depToProcess.Name)
		}

		currentState := dependencyInstallState{
			Name:              depToProcess.Name,
			ProjectTomlSource: depToProcess.Source,
			ProjectTomlPath:   depToProcess.Path,
			TargetRawURL:      finalTargetRawURL,
			TargetCommitHash:  resolvedCommitHash,
			Provider:          parsedSourceInfo.Provider,
			Owner:             parsedSourceInfo.Owner,
			Repo:              parsedSourceInfo.Repo,
			PathInRepo:        parsedSourceInfo.PathInRepo,
		}

		if lockDetails, ok := lf.Package[depToProcess.Name]; ok {
			currentState.LockedRawURL = lockDetails.Source
			currentState.LockedCommitHash = lockDetails.Hash
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "  Found in lockfile: Name: %s, Locked Source: %s, Locked Hash: %s\n", depToProcess.Name, lockDetails.Source, lockDetails.Hash)
			}
		} else {
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "  Dependency '%s' not found in lockfile.\n", depToProcess.Name)
			}
		}
		installStates = append(installStates, currentState)
	}

	if verbose && len(installStates) > 0 {
		_, _ = fmt.Fprintln(os.Stdout, "\nFinished resolving versions. States to compare:")
		for _, s := range installStates {
			_, _ = fmt.Fprintf(os.Stdout, "  - Name: %s, TargetCommit: %s, TargetURL: %s, LockedHash: %s, LockedURL: %s\n", s.Name, s.TargetCommitHash, s.TargetRawURL, s.LockedCommitHash, s.LockedRawURL)
		}
	}
	return installStates, nil
}

// filterDependenciesRequiringAction identifies which dependencies actually need an install/update.
func filterDependenciesRequiringAction(installStates []dependencyInstallState, force bool, verbose bool) []dependencyInstallState {
	var dependenciesThatNeedAction []dependencyInstallState

	if verbose && len(installStates) > 0 {
		_, _ = fmt.Fprintln(os.Stdout, "\nDetermining which dependencies need install/update...")
	}

	for _, state := range installStates { // Use index to modify original slice for NeedsAction and ActionReason
		reason := ""
		needsAction := false

		if force {
			needsAction = true
			reason = "Install/Update forced by user (--force)."
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "  - %s: Needs install/update (forced).\n", state.Name)
			}
		}

		if !needsAction && state.LockedCommitHash == "" {
			needsAction = true
			reason = "Dependency present in project.toml but not in almd-lock.toml."
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "  - %s: Needs install/update (not in lockfile).\n", state.Name)
			}
		}

		if !needsAction {
			if _, err := os.Stat(state.ProjectTomlPath); errors.Is(err, os.ErrNotExist) {
				needsAction = true
				reason = fmt.Sprintf("Local file missing at path: %s.", state.ProjectTomlPath)
				if verbose {
					_, _ = fmt.Fprintf(os.Stdout, "  - %s: Needs install/update (file missing at %s).\n", state.Name, state.ProjectTomlPath)
				}
			} else if err != nil {
				_, _ = fmt.Fprintf(os.Stderr, "Warning: Could not stat file for dependency '%s' at '%s': %v. Assuming install/update check is needed.\n", state.Name, state.ProjectTomlPath, err)
				needsAction = true
				reason = fmt.Sprintf("Error checking local file status at %s: %v.", state.ProjectTomlPath, err)
			}
		}

		if !needsAction && state.TargetCommitHash != "" && state.LockedCommitHash != "" {
			var lockedSHA string
			if strings.HasPrefix(state.LockedCommitHash, "commit:") {
				lockedSHA = strings.TrimPrefix(state.LockedCommitHash, "commit:")
			}

			if lockedSHA != "" && state.TargetCommitHash != lockedSHA {
				needsAction = true
				reason = fmt.Sprintf("Target commit hash (%s) differs from locked commit hash (%s).", state.TargetCommitHash, lockedSHA)
				if verbose {
					_, _ = fmt.Fprintf(os.Stdout, "  - %s: Needs install/update (target commit %s != locked commit %s).\n", state.Name, state.TargetCommitHash, lockedSHA)
				}
			} else if lockedSHA == "" && strings.HasPrefix(state.LockedCommitHash, "sha256:") && isCommitSHARegex.MatchString(state.TargetCommitHash) {
				needsAction = true
				reason = fmt.Sprintf("Target is now a specific commit (%s), but lockfile has a content hash (%s).", state.TargetCommitHash, state.LockedCommitHash)
				if verbose {
					_, _ = fmt.Fprintf(os.Stdout, "  - %s: Needs install/update (target is specific commit %s, lockfile has content hash %s).\n", state.Name, state.TargetCommitHash, state.LockedCommitHash)
				}
			}
		}

		if needsAction {
			// Modify a copy to avoid altering the original installStates slice passed around,
			// and append this modified copy to dependenciesThatNeedAction.
			actionableState := state // Make a copy
			actionableState.NeedsAction = true
			actionableState.ActionReason = reason
			dependenciesThatNeedAction = append(dependenciesThatNeedAction, actionableState)
		} else if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "  - %s: Already up-to-date.\n", state.Name)
		}
	}
	return dependenciesThatNeedAction
}

// executeInstallOperations performs the download, hashing, file saving, and lockfile data updates.
func executeInstallOperations(dependenciesThatNeedAction []dependencyInstallState, lf *lockfile.Lockfile, verbose bool) (successfulActions int, err error) {
	if verbose && len(dependenciesThatNeedAction) > 0 {
		_, _ = fmt.Fprintln(os.Stdout, "\nPerforming install/update for identified dependencies...")
	}

	for _, dep := range dependenciesThatNeedAction {
		if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "  Installing/Updating '%s' from %s\n", dep.Name, dep.TargetRawURL)
		}

		fileContent, downloadErr := downloader.DownloadFile(dep.TargetRawURL)
		if downloadErr != nil {
			_, _ = fmt.Fprintf(os.Stderr, "Error: Failed to download dependency '%s' from '%s': %v\n", dep.Name, dep.TargetRawURL, downloadErr)
			continue // Skip to next dependency
		}
		if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "    Successfully downloaded %s (%d bytes)\n", dep.Name, len(fileContent))
		}

		var integrityHash string
		if dep.Provider == "github" && isCommitSHARegex.MatchString(dep.TargetCommitHash) {
			integrityHash = "commit:" + dep.TargetCommitHash
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "    Using commit hash for integrity: %s\n", integrityHash)
			}
		} else {
			contentHash, hashErr := hasher.CalculateSHA256(fileContent)
			if hashErr != nil {
				_, _ = fmt.Fprintf(os.Stderr, "Error: Failed to calculate SHA256 hash for dependency '%s': %v\n", dep.Name, hashErr)
				continue
			}
			integrityHash = contentHash
			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "    Calculated content hash for integrity: %s\n", integrityHash)
			}
		}

		targetDir := filepath.Dir(dep.ProjectTomlPath)
		if mkdirErr := os.MkdirAll(targetDir, os.ModePerm); mkdirErr != nil {
			_, _ = fmt.Fprintf(os.Stderr, "Error: Failed to create directory '%s' for dependency '%s': %v\n", targetDir, dep.Name, mkdirErr)
			continue
		}
		if writeErr := os.WriteFile(dep.ProjectTomlPath, fileContent, 0644); writeErr != nil {
			_, _ = fmt.Fprintf(os.Stderr, "Error: Failed to write file '%s' for dependency '%s': %v\n", dep.ProjectTomlPath, dep.Name, writeErr)
			continue
		}
		if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "    Successfully saved %s to %s\n", dep.Name, dep.ProjectTomlPath)
		}

		lf.Package[dep.Name] = lockfile.PackageEntry{
			Source: dep.TargetRawURL,
			Path:   dep.ProjectTomlPath,
			Hash:   integrityHash,
		}
		if verbose {
			_, _ = fmt.Fprintf(os.Stdout, "    Updated lockfile entry for %s: Path=%s, Hash=%s, SourceURL=%s\n", dep.Name, dep.ProjectTomlPath, integrityHash, dep.TargetRawURL)
		}
		successfulActions++
	}
	return successfulActions, nil
}

// InstallCmd creates a new install command that handles dependency management.
func InstallCmd() *cli.Command {
	return &cli.Command{
		Name:      "install",
		Usage:     "Installs or updates project dependencies based on project.toml",
		ArgsUsage: "[dependency_names...]",
		Flags: []cli.Flag{
			&cli.BoolFlag{
				Name:    "force",
				Aliases: []string{"f"},
				Usage:   "Force install/update even if versions appear to match",
			},
			&cli.BoolFlag{
				Name:  "verbose",
				Usage: "Enable verbose output",
			},
		},
		Action: func(c *cli.Context) error {
			projCfg, lf, dependencyNames, force, verbose, err := loadInstallConfigAndArgs(c)
			if err != nil {
				return err // Error is already a cli.Exit
			}

			dependenciesToProcessList, err := collectDependenciesToProcess(projCfg, dependencyNames, verbose)
			if err != nil {
				return cli.Exit(fmt.Sprintf("Error collecting dependencies to process: %v", err), 1)
			}
			if dependenciesToProcessList == nil { // Indicates no work to do, message already printed
				return nil
			}

			installStates, err := resolveInstallStates(dependenciesToProcessList, lf, verbose)
			if err != nil {
				return cli.Exit(fmt.Sprintf("Error resolving dependency states: %v", err), 1)
			}

			dependenciesThatNeedAction := filterDependenciesRequiringAction(installStates, force, verbose)

			if len(dependenciesThatNeedAction) == 0 {
				_, _ = fmt.Fprintln(os.Stdout, "All targeted dependencies are already up-to-date.")
				return nil
			}

			if verbose {
				_, _ = fmt.Fprintf(os.Stdout, "\nDependencies to be installed/updated (%d):\n", len(dependenciesThatNeedAction))
				for _, dep := range dependenciesThatNeedAction {
					_, _ = fmt.Fprintf(os.Stdout, "  - %s (Reason: %s)\n", dep.Name, dep.ActionReason)
				}
			}

			successfulActions, err := executeInstallOperations(dependenciesThatNeedAction, lf, verbose)
			if err != nil {
				// This error isn't currently returned by executeInstallOperations but good for future proofing
				return cli.Exit(fmt.Sprintf("Critical error during install operations: %v", err), 1)
			}

			if successfulActions > 0 {
				lf.ApiVersion = lockfile.APIVersion // Ensure API version is set
				if err := lockfile.Save(".", lf); err != nil {
					return cli.Exit(fmt.Sprintf("Error: Failed to save updated almd-lock.toml: %v", err), 1)
				}
				if verbose {
					_, _ = fmt.Fprintf(os.Stdout, "\nSuccessfully saved almd-lock.toml with %d action(s).\n", successfulActions)
				}
				_, _ = fmt.Fprintf(os.Stdout, "Successfully installed/updated %d dependenc(ies).\n", successfulActions)
			} else {
				if len(dependenciesThatNeedAction) > 0 { // Implies all actions failed
					_, _ = fmt.Fprintln(os.Stderr, "No dependencies were successfully installed/updated due to errors.")
					return cli.Exit("Install/Update process completed with errors for all targeted dependencies.", 1)
				}
				// If dependenciesThatNeedAction was empty, this path shouldn't be reached due to earlier check.
			}
			return nil
		},
	}
}



================================================
File: internal/cli/install/install_test.go
================================================
// Package install_test contains tests for the 'install' command, focusing on dependency
// resolution, download handling, and error scenarios. These tests use mock HTTP servers
// to simulate GitHub API and raw content responses.
package install_test

import (
	"fmt"
	"net/http"
	"net/http/httptest"
	"os"
	"path/filepath"
	"testing"

	"github.com/BurntSushi/toml"
	installcmd "github.com/nightconcept/almandine/internal/cli/install"
	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/lockfile"
	"github.com/nightconcept/almandine/internal/core/project"
	"github.com/nightconcept/almandine/internal/core/source"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"github.com/urfave/cli/v2"
)

func init() {
	// Enable host validation bypass for testing with mock server
	source.SetTestModeBypassHostValidation(true)
}

// startMockHTTPServer creates an HTTP test server that serves predefined responses for
// specific paths, simulating GitHub's API and raw content servers. Other paths return 404.
// This allows testing various GitHub API response scenarios without network access.
func startMockHTTPServer(t *testing.T, pathResponses map[string]struct {
	Body string
	Code int
}) *httptest.Server {
	t.Helper()
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		requestPathWithQuery := r.URL.Path
		if r.URL.RawQuery != "" {
			requestPathWithQuery += "?" + r.URL.RawQuery
		}

		for path, response := range pathResponses {
			if r.Method == http.MethodGet && (r.URL.Path == path || requestPathWithQuery == path) {
				w.WriteHeader(response.Code)
				_, err := w.Write([]byte(response.Body))
				assert.NoError(t, err, "Mock server failed to write response body for path: %s", path)
				return
			}
		}
		t.Logf("Mock server: unexpected request: Method %s, Path %s, Query %s", r.Method, r.URL.Path, r.URL.RawQuery)
		http.NotFound(w, r)
	}))
	t.Cleanup(server.Close)
	return server
}

// setupInstallTestEnvironment prepares a test environment with configurable project files.
// It creates a temporary directory and initializes it with the provided project.toml,
// almd-lock.toml, and mock dependency files, simulating various project states.
func setupInstallTestEnvironment(t *testing.T, initialProjectTomlContent string, initialLockfileContent string, mockDepFiles map[string]string) (tempDir string) {
	t.Helper()
	tempDir = t.TempDir()

	if initialProjectTomlContent != "" {
		projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
		err := os.WriteFile(projectTomlPath, []byte(initialProjectTomlContent), 0644)
		require.NoError(t, err, "Failed to write initial project.toml")
	}

	if initialLockfileContent != "" {
		lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)
		err := os.WriteFile(lockfilePath, []byte(initialLockfileContent), 0644)
		require.NoError(t, err, "Failed to write initial almd-lock.toml")
	}

	for relPath, content := range mockDepFiles {
		absPath := filepath.Join(tempDir, relPath)
		err := os.MkdirAll(filepath.Dir(absPath), 0755)
		require.NoError(t, err, "Failed to create directory for mock dep file: %s", filepath.Dir(absPath))
		err = os.WriteFile(absPath, []byte(content), 0644)
		require.NoError(t, err, "Failed to write mock dependency file: %s", absPath)
	}

	return tempDir
}

// runInstallCommand executes the 'install' command in a specified directory.
// It temporarily changes the working directory, runs the command, and ensures
// the original working directory is restored, even if the command fails.
func runInstallCommand(t *testing.T, workDir string, installCmdArgs ...string) error {
	t.Helper()

	originalWd, err := os.Getwd()
	require.NoError(t, err, "Failed to get current working directory")
	err = os.Chdir(workDir)
	require.NoError(t, err, "Failed to change to working directory: %s", workDir)
	defer func() {
		require.NoError(t, os.Chdir(originalWd), "Failed to restore original working directory")
	}()

	app := &cli.App{
		Name: "almd-test-install",
		Commands: []*cli.Command{
			installcmd.InstallCmd(),
		},
		Writer:    os.Stderr,
		ErrWriter: os.Stderr,
		ExitErrHandler: func(context *cli.Context, err error) {
			// Do nothing, let test assertions handle errors
		},
	}

	cliArgs := []string{"almd-test-install", "install"}
	cliArgs = append(cliArgs, installCmdArgs...)

	return app.Run(cliArgs)
}

// readProjectToml reads and unmarshals the project.toml file into a Project struct.
// It ensures the file exists and is valid TOML.
func readProjectToml(t *testing.T, tomlPath string) project.Project {
	t.Helper()
	bytes, err := os.ReadFile(tomlPath)
	require.NoError(t, err, "Failed to read project.toml: %s", tomlPath)

	var projCfg project.Project
	err = toml.Unmarshal(bytes, &projCfg)
	require.NoError(t, err, "Failed to unmarshal project.toml: %s", tomlPath)
	return projCfg
}

// readAlmdLockToml reads and unmarshals the almd-lock.toml file into a Lockfile struct.
// It ensures the file exists and is valid TOML.
func readAlmdLockToml(t *testing.T, lockPath string) lockfile.Lockfile {
	t.Helper()
	bytes, err := os.ReadFile(lockPath)
	require.NoError(t, err, "Failed to read almd-lock.toml: %s", lockPath)

	var lockCfg lockfile.Lockfile
	err = toml.Unmarshal(bytes, &lockCfg)
	require.NoError(t, err, "Failed to unmarshal almd-lock.toml: %s", lockPath)
	return lockCfg
}

// TestInstallCommand_OneDepNeedsUpdate_CommitHashChange verifies that when a dependency's
// remote commit changes, the install command correctly downloads and updates the file
// and lockfile while preserving project.toml.
func TestInstallCommand_OneDepNeedsUpdate_CommitHashChange(t *testing.T) {
	// Test setup and assertions for dependency update scenario
	depAName := "depA"
	depAPath := "libs/depA.lua"
	depAOriginalContent := "local depA_v1 = true"
	depANewContent := "local depA_v2 = true; print('updated')"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-install-project"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/testrepo/%s@main"
path = "%s"
`, depAName, depAPath, depAPath)

	initialLockfile := fmt.Sprintf(`
api_version = "1"

[package.%s]
source = "https://raw.githubusercontent.com/testowner/testrepo/commit1_sha_abcdef1234567890/%s"
path = "%s"
hash = "commit:commit1_sha_abcdef1234567890"
`, depAName, depAPath, depAPath)

	mockFiles := map[string]string{
		depAPath: depAOriginalContent,
	}

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfile, mockFiles)

	commit2SHA := "fedcba0987654321abcdef1234567890"
	githubAPIPathForDepA := fmt.Sprintf("/repos/testowner/testrepo/commits?path=%s&sha=main&per_page=1", depAPath)
	githubAPIResponseForDepA := fmt.Sprintf(`[{"sha": "%s"}]`, commit2SHA)
	rawDownloadPathDepA := fmt.Sprintf("/testowner/testrepo/%s/%s", commit2SHA, depAPath)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDepA: {Body: githubAPIResponseForDepA, Code: http.StatusOK},
		rawDownloadPathDepA:  {Body: depANewContent, Code: http.StatusOK},
	}
	mockServer := startMockHTTPServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir)
	require.NoError(t, err, "almd install command failed")

	depAFilePath := filepath.Join(tempDir, depAPath)
	updatedContentBytes, readErr := os.ReadFile(depAFilePath)
	require.NoError(t, readErr, "Failed to read updated depA file: %s", depAFilePath)
	assert.Equal(t, depANewContent, string(updatedContentBytes), "depA file content mismatch after install")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	updatedLockCfg := readAlmdLockToml(t, lockFilePath)

	require.NotNil(t, updatedLockCfg.Package, "Packages map in almd-lock.toml is nil after install")
	depALockEntry, ok := updatedLockCfg.Package[depAName]
	require.True(t, ok, "depA entry not found in almd-lock.toml after install")

	expectedLockSourceURL := mockServer.URL + rawDownloadPathDepA
	assert.Equal(t, expectedLockSourceURL, depALockEntry.Source, "depA lockfile source URL mismatch")
	assert.Equal(t, depAPath, depALockEntry.Path, "depA lockfile path mismatch")
	assert.Equal(t, "commit:"+commit2SHA, depALockEntry.Hash, "depA lockfile hash mismatch")

	projTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	currentProjCfg := readProjectToml(t, projTomlPath)
	depAProjEntry, ok := currentProjCfg.Dependencies[depAName]
	require.True(t, ok, "depA entry not found in project.toml")
	assert.Equal(t, fmt.Sprintf("github:testowner/testrepo/%s@main", depAPath), depAProjEntry.Source, "project.toml source for depA should not change")
}

// TestInstallCommand_SpecificDepInstall_OneNeedsUpdate verifies that installing a specific
// dependency only updates that dependency, leaving others unchanged, even if they also
// have updates available.
func TestInstallCommand_SpecificDepInstall_OneNeedsUpdate(t *testing.T) {
	// Test setup and assertions for specific dependency install scenario
	depAName := "depA"
	depAPath := "libs/depA.lua"
	depAOriginalContent := "local depA_v1 = true"
	depANewContent := "local depA_v2 = true; print('updated A')"
	depACommit1HexSHA := "abcdef1234567890abcdef1234567890"
	depACommit2HexSHA := "fedcba0987654321fedcba0987654321"

	depBName := "depB"
	depBPath := "modules/depB.lua"
	depBOriginalContent := "local depB_v1 = true"
	depBNewContent := "local depB_v2 = true; print('updated B')"
	depBCommit1HexSHA := "1234567890abcdef1234567890abcdef"
	depBCommit2HexSHA := "0987654321fedcba0987654321fedcba"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-specific-install"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/testrepo/%s@main"
path = "%s"

[dependencies.%s]
source = "github:anotherowner/anotherrepo/%s@main"
path = "%s"
`, depAName, depAPath, depAPath, depBName, depBPath, depBPath)

	initialLockfile := fmt.Sprintf(`
api_version = "1"

[package.%s]
source = "https://raw.githubusercontent.com/testowner/testrepo/%s/%s"
path = "%s"
hash = "commit:%s"

[package.%s]
source = "https://raw.githubusercontent.com/anotherowner/anotherrepo/%s/%s"
path = "%s"
hash = "commit:%s"
`, depAName, depACommit1HexSHA, depAPath, depAPath, depACommit1HexSHA,
		depBName, depBCommit1HexSHA, depBPath, depBPath, depBCommit1HexSHA)

	mockFiles := map[string]string{
		depAPath: depAOriginalContent,
		depBPath: depBOriginalContent,
	}

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfile, mockFiles)

	githubAPIPathForDepA := fmt.Sprintf("/repos/testowner/testrepo/commits?path=%s&sha=main&per_page=1", depAPath)
	githubAPIResponseForDepA := fmt.Sprintf(`[{"sha": "%s"}]`, depACommit2HexSHA)
	rawDownloadPathDepA := fmt.Sprintf("/testowner/testrepo/%s/%s", depACommit2HexSHA, depAPath)

	githubAPIPathForDepB := fmt.Sprintf("/repos/anotherowner/anotherrepo/commits?path=%s&sha=main&per_page=1", depBPath)
	githubAPIResponseForDepB := fmt.Sprintf(`[{"sha": "%s"}]`, depBCommit2HexSHA)
	rawDownloadPathDepB := fmt.Sprintf("/anotherowner/anotherrepo/%s/%s", depBCommit2HexSHA, depBPath)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDepA: {Body: githubAPIResponseForDepA, Code: http.StatusOK},
		rawDownloadPathDepA:  {Body: depANewContent, Code: http.StatusOK},
		githubAPIPathForDepB: {Body: githubAPIResponseForDepB, Code: http.StatusOK},
		rawDownloadPathDepB:  {Body: depBNewContent, Code: http.StatusOK},
	}
	mockServer := startMockHTTPServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir, depAName)
	require.NoError(t, err, "almd install %s command failed", depAName)

	depAFilePath := filepath.Join(tempDir, depAPath)
	updatedContentBytesA, readErrA := os.ReadFile(depAFilePath)
	require.NoError(t, readErrA, "Failed to read updated depA file: %s", depAFilePath)
	assert.Equal(t, depANewContent, string(updatedContentBytesA), "depA file content mismatch after specific install")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	updatedLockCfg := readAlmdLockToml(t, lockFilePath)
	require.NotNil(t, updatedLockCfg.Package, "Packages map in almd-lock.toml is nil")

	depALockEntry, okA := updatedLockCfg.Package[depAName]
	require.True(t, okA, "depA entry not found in almd-lock.toml after specific install")
	expectedLockSourceURLA := mockServer.URL + rawDownloadPathDepA
	assert.Equal(t, expectedLockSourceURLA, depALockEntry.Source, "depA lockfile source URL mismatch")
	assert.Equal(t, "commit:"+depACommit2HexSHA, depALockEntry.Hash, "depA lockfile hash mismatch")

	depBFilePath := filepath.Join(tempDir, depBPath)
	contentBytesB, readErrB := os.ReadFile(depBFilePath)
	require.NoError(t, readErrB, "Failed to read depB file: %s", depBFilePath)
	assert.Equal(t, depBOriginalContent, string(contentBytesB), "depB file content should not have changed")

	depBLockEntry, okB := updatedLockCfg.Package[depBName]
	require.True(t, okB, "depB entry not found in almd-lock.toml")
	expectedLockSourceURLBOriginal := fmt.Sprintf("https://raw.githubusercontent.com/anotherowner/anotherrepo/%s/%s", depBCommit1HexSHA, depBPath)
	assert.Equal(t, expectedLockSourceURLBOriginal, depBLockEntry.Source, "depB lockfile source URL should be unchanged")
	assert.Equal(t, "commit:"+depBCommit1HexSHA, depBLockEntry.Hash, "depB lockfile hash should be unchanged")

	projTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	currentProjCfg := readProjectToml(t, projTomlPath)
	depAProjEntry := currentProjCfg.Dependencies[depAName]
	assert.Equal(t, fmt.Sprintf("github:testowner/testrepo/%s@main", depAPath), depAProjEntry.Source)
	depBProjEntry := currentProjCfg.Dependencies[depBName]
	assert.Equal(t, fmt.Sprintf("github:anotherowner/anotherrepo/%s@main", depBPath), depBProjEntry.Source)
}

// TestInstallCommand_AllDepsUpToDate verifies that when all dependencies are current,
// the install command makes no changes to files or lockfile entries.
func TestInstallCommand_AllDepsUpToDate(t *testing.T) {
	// Test setup and assertions for up-to-date dependencies scenario
	depAName := "depA"
	depAPath := "libs/depA.lua"
	depAContent := "local depA_v_current = true"
	depACommitCurrentSHA := "commitA_sha_current12345"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-uptodate-project"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/testrepo/%s@main"
path = "%s"
`, depAName, depAPath, depAPath)

	initialLockfile := fmt.Sprintf(`
api_version = "1"

[package.%s]
source = "https://raw.githubusercontent.com/testowner/testrepo/%s/%s"
path = "%s"
hash = "commit:%s"
`, depAName, depACommitCurrentSHA, depAPath, depAPath, depACommitCurrentSHA)

	mockFiles := map[string]string{
		depAPath: depAContent,
	}

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfile, mockFiles)

	githubAPIPathForDepA := fmt.Sprintf("/repos/testowner/testrepo/commits?path=%s&sha=main&per_page=1", depAPath)
	githubAPIResponseForDepA := fmt.Sprintf(`[{"sha": "%s"}]`, depACommitCurrentSHA)
	rawDownloadPathDepA := fmt.Sprintf("/testowner/testrepo/%s/%s", depACommitCurrentSHA, depAPath)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDepA: {Body: githubAPIResponseForDepA, Code: http.StatusOK},
		rawDownloadPathDepA:  {Body: depAContent, Code: http.StatusOK},
	}
	mockServer := startMockHTTPServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir)
	require.NoError(t, err, "almd install command failed")

	depAFilePath := filepath.Join(tempDir, depAPath)
	currentContentBytes, readErr := os.ReadFile(depAFilePath)
	require.NoError(t, readErr, "Failed to read depA file: %s", depAFilePath)
	assert.Equal(t, depAContent, string(currentContentBytes), "depA file content should be unchanged")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	currentLockCfg := readAlmdLockToml(t, lockFilePath)
	originalLockCfg := lockfile.Lockfile{}
	errUnmarshal := toml.Unmarshal([]byte(initialLockfile), &originalLockCfg)
	require.NoError(t, errUnmarshal, "Failed to unmarshal original lockfile content for comparison")

	assert.Equal(t, originalLockCfg, currentLockCfg, "almd-lock.toml should be unchanged")

	projTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	currentProjCfg := readProjectToml(t, projTomlPath)
	originalProjCfg := project.Project{}
	errUnmarshalProj := toml.Unmarshal([]byte(initialProjectToml), &originalProjCfg)
	require.NoError(t, errUnmarshalProj, "Failed to unmarshal original project.toml content for comparison")
	assert.Equal(t, originalProjCfg, currentProjCfg, "project.toml should be unchanged")
}

// TestInstallCommand_DepInProjectToml_MissingFromLockfile verifies that dependencies
// present in project.toml but missing from the lockfile are correctly downloaded
// and added to the lockfile.
func TestInstallCommand_DepInProjectToml_MissingFromLockfile(t *testing.T) {
	// Test setup and assertions for missing lockfile entry scenario
	depNewName := "depNew"
	depNewPath := "libs/depNew.lua"
	depNewContent := "local depNewContent = true"
	depNewCommitSHA := "abcdef1234567890abcdef1234567890"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-missing-lockfile-entry"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/newrepo/%s@main"
path = "%s"
`, depNewName, depNewPath, depNewPath)

	initialLockfile := `
api_version = "1"
[package]
`

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfile, nil)

	githubAPIPathForDepNew := fmt.Sprintf("/repos/testowner/newrepo/commits?path=%s&sha=main&per_page=1", depNewPath)
	githubAPIResponseForDepNew := fmt.Sprintf(`[{"sha": "%s"}]`, depNewCommitSHA)
	rawDownloadPathDepNew := fmt.Sprintf("/testowner/newrepo/%s/%s", depNewCommitSHA, depNewPath)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDepNew: {Body: githubAPIResponseForDepNew, Code: http.StatusOK},
		rawDownloadPathDepNew:  {Body: depNewContent, Code: http.StatusOK},
	}
	mockServer := startMockHTTPServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir)
	require.NoError(t, err, "almd install command failed")

	depNewFilePath := filepath.Join(tempDir, depNewPath)
	contentBytes, readErr := os.ReadFile(depNewFilePath)
	require.NoError(t, readErr, "Failed to read depNew file: %s", depNewFilePath)
	assert.Equal(t, depNewContent, string(contentBytes), "depNew file content mismatch")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	updatedLockCfg := readAlmdLockToml(t, lockFilePath)

	require.NotNil(t, updatedLockCfg.Package, "Packages map in almd-lock.toml is nil")
	depNewLockEntry, ok := updatedLockCfg.Package[depNewName]
	require.True(t, ok, "depNew entry not found in almd-lock.toml after install")

	expectedLockSourceURL := mockServer.URL + rawDownloadPathDepNew
	assert.Equal(t, expectedLockSourceURL, depNewLockEntry.Source, "depNew lockfile source URL mismatch")
	assert.Equal(t, depNewPath, depNewLockEntry.Path, "depNew lockfile path mismatch")
	assert.Equal(t, "commit:"+depNewCommitSHA, depNewLockEntry.Hash, "depNew lockfile hash mismatch")
}

// TestInstallCommand_LocalFileMissing verifies that when a dependency's local file
// is missing but its lockfile entry exists, the file is re-downloaded using the
// locked source if the remote version matches.
func TestInstallCommand_LocalFileMissing(t *testing.T) {
	// Test setup and assertions for missing local file scenario
	depAName := "depA"
	depAPath := "libs/depA.lua"
	depAContent := "local depA_content_from_lock = true"
	depALockedCommitSHA := "fedcba0987654321fedcba0987654321"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-local-file-missing"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/testrepo/%s@main"
path = "%s"
`, depAName, depAPath, depAPath)

	initialLockfile := fmt.Sprintf(`
api_version = "1"

[package.%s]
source = "https://raw.githubusercontent.com/testowner/testrepo/%s/%s"
path = "%s"
hash = "commit:%s"
`, depAName, depALockedCommitSHA, depAPath, depAPath, depALockedCommitSHA)

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfile, nil)

	githubAPIPathForDepA := fmt.Sprintf("/repos/testowner/testrepo/commits?path=%s&sha=main&per_page=1", depAPath)
	githubAPIResponseForDepA := fmt.Sprintf(`[{"sha": "%s"}]`, depALockedCommitSHA)
	rawDownloadPathDepA := fmt.Sprintf("/testowner/testrepo/%s/%s", depALockedCommitSHA, depAPath)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDepA: {Body: githubAPIResponseForDepA, Code: http.StatusOK},
		rawDownloadPathDepA:  {Body: depAContent, Code: http.StatusOK},
	}
	mockServer := startMockHTTPServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir, depAName)
	require.NoError(t, err, "almd install %s command failed", depAName)

	depAFilePath := filepath.Join(tempDir, depAPath)
	contentBytes, readErr := os.ReadFile(depAFilePath)
	require.NoError(t, readErr, "Failed to read re-downloaded depA file: %s", depAFilePath)
	assert.Equal(t, depAContent, string(contentBytes), "depA file content mismatch after re-download")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	updatedLockCfg := readAlmdLockToml(t, lockFilePath)

	require.NotNil(t, updatedLockCfg.Package, "Packages map in almd-lock.toml is nil")
	depALockEntry, ok := updatedLockCfg.Package[depAName]
	require.True(t, ok, "depA entry not found in almd-lock.toml after install")

	expectedLockSourceURL := mockServer.URL + rawDownloadPathDepA
	assert.Equal(t, expectedLockSourceURL, depALockEntry.Source, "depA lockfile source URL mismatch")
	assert.Equal(t, depAPath, depALockEntry.Path, "depA lockfile path mismatch")
	assert.Equal(t, "commit:"+depALockedCommitSHA, depALockEntry.Hash, "depA lockfile hash mismatch")
}

// TestInstallCommand_ForceInstallUpToDateDependency verifies that the --force flag
// causes re-download of dependencies even when they're up to date, ensuring the
// local files match their remote versions exactly.
func TestInstallCommand_ForceInstallUpToDateDependency(t *testing.T) {
	// Test setup and assertions for force install scenario
	depAName := "depA"
	depAPath := "libs/depA.lua"
	depAContent := "local depA_v_current = true"
	depACommitCurrentSHA := "a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-force-install-project"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/testrepo/%s@main"
path = "%s"
`, depAName, depAPath, depAPath)

	initialLockfileContent := fmt.Sprintf(`
api_version = "1"

[package.%s]
source = "https://raw.githubusercontent.com/testowner/testrepo/%s/%s"
path = "%s"
hash = "commit:%s"
`, depAName, depACommitCurrentSHA, depAPath, depAPath, depACommitCurrentSHA)

	mockFiles := map[string]string{
		depAPath: depAContent,
	}

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfileContent, mockFiles)

	githubAPIPathForDepA := fmt.Sprintf("/repos/testowner/testrepo/commits?path=%s&sha=main&per_page=1", depAPath)
	githubAPIResponseForDepA := fmt.Sprintf(`[{"sha": "%s"}]`, depACommitCurrentSHA)
	rawDownloadPathDepA := fmt.Sprintf("/testowner/testrepo/%s/%s", depACommitCurrentSHA, depAPath)

	downloadEndpointCalled := false
	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDepA: {Body: githubAPIResponseForDepA, Code: http.StatusOK},
		rawDownloadPathDepA: {
			Body: depAContent,
			Code: http.StatusOK,
		},
	}

	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		requestPathWithQuery := r.URL.Path
		if r.URL.RawQuery != "" {
			requestPathWithQuery += "?" + r.URL.RawQuery
		}

		if r.Method == http.MethodGet && (r.URL.Path == rawDownloadPathDepA || requestPathWithQuery == rawDownloadPathDepA) {
			downloadEndpointCalled = true
		}

		for path, response := range pathResps {
			if r.Method == http.MethodGet && (r.URL.Path == path || requestPathWithQuery == path) {
				w.WriteHeader(response.Code)
				_, err := w.Write([]byte(response.Body))
				assert.NoError(t, err, "Mock server failed to write response body for path: %s", path)
				return
			}
		}
		t.Logf("Mock server: unexpected request: Method %s, Path %s, Query %s", r.Method, r.URL.Path, r.URL.RawQuery)
		http.NotFound(w, r)
	}))
	t.Cleanup(server.Close)
	mockServerURL := server.URL

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServerURL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir, "--force", depAName)
	require.NoError(t, err, "almd install --force %s command failed", depAName)

	assert.True(t, downloadEndpointCalled, "Download endpoint for depA was not called despite --force")

	depAFilePath := filepath.Join(tempDir, depAPath)
	currentContentBytes, readErr := os.ReadFile(depAFilePath)
	require.NoError(t, readErr, "Failed to read depA file: %s", depAFilePath)
	assert.Equal(t, depAContent, string(currentContentBytes), "depA file content should be (re-)written")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	updatedLockCfg := readAlmdLockToml(t, lockFilePath)

	require.NotNil(t, updatedLockCfg.Package, "Packages map in almd-lock.toml is nil after force install")
	depALockEntry, ok := updatedLockCfg.Package[depAName]
	require.True(t, ok, "depA entry not found in almd-lock.toml after force install")

	expectedLockSourceURL := mockServerURL + rawDownloadPathDepA
	assert.Equal(t, expectedLockSourceURL, depALockEntry.Source, "depA lockfile source URL mismatch after force")
	assert.Equal(t, depAPath, depALockEntry.Path, "depA lockfile path mismatch after force")
	assert.Equal(t, "commit:"+depACommitCurrentSHA, depALockEntry.Hash, "depA lockfile hash mismatch after force")

	projTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	currentProjCfg := readProjectToml(t, projTomlPath)
	originalProjCfg := project.Project{}
	errUnmarshalProj := toml.Unmarshal([]byte(initialProjectToml), &originalProjCfg)
	require.NoError(t, errUnmarshalProj, "Failed to unmarshal original project.toml content for comparison")
	assert.Equal(t, originalProjCfg, currentProjCfg, "project.toml should be unchanged after force install")
}

// TestInstallCommand_NonExistentDependencySpecified verifies that attempting to
// install a non-existent dependency results in a warning message without modifying
// any files or the lockfile.
func TestInstallCommand_NonExistentDependencySpecified(t *testing.T) {
	// Test setup and assertions for non-existent dependency scenario
	nonExistentDepName := "nonExistentDep"

	initialProjectToml := `
[package]
name = "test-nonexistent-dep-project"
version = "0.1.0"
`

	initialLockfileContent := `
api_version = "1"
[package]
`

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfileContent, nil)

	err := runInstallCommand(t, tempDir, nonExistentDepName)
	require.NoError(t, err, "almd install %s command failed unexpectedly (expected warning, not fatal error)", nonExistentDepName)

	projTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	currentProjCfg := readProjectToml(t, projTomlPath)
	originalProjCfg := project.Project{}
	errUnmarshalProj := toml.Unmarshal([]byte(initialProjectToml), &originalProjCfg)
	require.NoError(t, errUnmarshalProj, "Failed to unmarshal original project.toml content for comparison")
	assert.Equal(t, originalProjCfg, currentProjCfg, "project.toml should be unchanged")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	currentLockCfg := readAlmdLockToml(t, lockFilePath)
	originalLockCfg := lockfile.Lockfile{}
	errUnmarshalLock := toml.Unmarshal([]byte(initialLockfileContent), &originalLockCfg)
	require.NoError(t, errUnmarshalLock, "Failed to unmarshal original lockfile content for comparison")
	assert.Equal(t, originalLockCfg, currentLockCfg, "almd-lock.toml should be unchanged")

	libsDir := filepath.Join(tempDir, "libs")
	_, errStatLibs := os.Stat(libsDir)
	assert.True(t, os.IsNotExist(errStatLibs), "libs directory should not have been created")

	vendorDir := filepath.Join(tempDir, "vendor")
	_, errStatVendor := os.Stat(vendorDir)
	assert.True(t, os.IsNotExist(errStatVendor), "vendor directory should not have been created")

	nonExistentDepFilePath := filepath.Join(tempDir, nonExistentDepName)
	_, errStatDepFile := os.Stat(nonExistentDepFilePath)
	assert.True(t, os.IsNotExist(errStatDepFile), "File for nonExistentDep should not have been created")
}

// TestInstallCommand_ErrorDuringDownload verifies that download failures are
// handled gracefully, leaving files and lockfile in their original state.
func TestInstallCommand_ErrorDuringDownload(t *testing.T) {
	// Test setup and assertions for download error scenario
	depName := "depWithError"
	depPath := "libs/depWithError.lua"
	depOriginalContent := "local depWithError_v1 = true"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-download-error-project"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/testrepo/%s@main"
path = "%s"
`, depName, depPath, depPath)

	initialLockfile := fmt.Sprintf(`
api_version = "1"

[package.%s]
source = "https://raw.githubusercontent.com/testowner/testrepo/commit1_sha_dlerror/%s"
path = "%s"
hash = "commit:commit1_sha_dlerror"
`, depName, depPath, depPath)

	mockFiles := map[string]string{
		depPath: depOriginalContent,
	}

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfile, mockFiles)

	commitToDownloadSHA := "commit2_sha_dlerror_target"
	githubAPIPathForDep := fmt.Sprintf("/repos/testowner/testrepo/commits?path=%s&sha=main&per_page=1", depPath)
	githubAPIResponseForDep := fmt.Sprintf(`[{"sha": "%s"}]`, commitToDownloadSHA)

	rawDownloadPathDep := fmt.Sprintf("/testowner/testrepo/%s/%s", commitToDownloadSHA, depPath)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDep: {Body: githubAPIResponseForDep, Code: http.StatusOK},
		rawDownloadPathDep:  {Body: "Simulated server error", Code: http.StatusInternalServerError},
	}
	mockServer := startMockHTTPServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir)
	require.Error(t, err, "almd install command should have failed due to download error")

	depFilePath := filepath.Join(tempDir, depPath)
	currentContentBytes, readErr := os.ReadFile(depFilePath)
	require.NoError(t, readErr, "Failed to read depWithError file: %s", depFilePath)
	assert.Equal(t, depOriginalContent, string(currentContentBytes), "depWithError file content should be unchanged after failed download")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	currentLockCfg := readAlmdLockToml(t, lockFilePath)
	originalLockCfg := lockfile.Lockfile{}
	errUnmarshal := toml.Unmarshal([]byte(initialLockfile), &originalLockCfg)
	require.NoError(t, errUnmarshal, "Failed to unmarshal original lockfile content for comparison")
	assert.Equal(t, originalLockCfg, currentLockCfg, "almd-lock.toml should be unchanged after failed download")

	projTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	currentProjCfg := readProjectToml(t, projTomlPath)
	originalProjCfg := project.Project{}
	errUnmarshalProj := toml.Unmarshal([]byte(initialProjectToml), &originalProjCfg)
	require.NoError(t, errUnmarshalProj, "Failed to unmarshal original project.toml content for comparison")
	assert.Equal(t, originalProjCfg, currentProjCfg, "project.toml should be unchanged")
}

// TestInstallCommand_ErrorDuringSourceResolution verifies that source resolution
// failures (e.g., non-existent branch) are handled gracefully without creating
// incomplete or corrupted dependency files.
func TestInstallCommand_ErrorDuringSourceResolution(t *testing.T) {
	// Test setup and assertions for source resolution error scenario
	depName := "depBadBranch"
	depPath := "libs/depBadBranch.lua"
	nonExistentBranch := "nonexistent_branch_for_sure"

	initialProjectToml := fmt.Sprintf(`
[package]
name = "test-source-resolution-error-project"
version = "0.1.0"

[dependencies.%s]
source = "github:testowner/testrepo/%s@%s"
path = "%s"
`, depName, depPath, nonExistentBranch, depPath)

	initialLockfile := `
api_version = "1"
[package]
`

	tempDir := setupInstallTestEnvironment(t, initialProjectToml, initialLockfile, nil)

	githubAPIPathForDep := fmt.Sprintf("/repos/testowner/testrepo/commits?path=%s&sha=%s&per_page=1", depPath, nonExistentBranch)
	githubAPIResponseForDep_NotFound := `[]`

	rawDownloadPathDep := fmt.Sprintf("/testowner/testrepo/some_sha_never_reached/%s", depPath)

	pathResps := map[string]struct {
		Body string
		Code int
	}{
		githubAPIPathForDep: {Body: githubAPIResponseForDep_NotFound, Code: http.StatusOK},
		rawDownloadPathDep:  {Body: "SHOULD NOT BE DOWNLOADED", Code: http.StatusOK},
	}
	mockServer := startMockHTTPServer(t, pathResps)

	originalGHAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = mockServer.URL
	defer func() { source.GithubAPIBaseURL = originalGHAPIBaseURL }()

	err := runInstallCommand(t, tempDir, depName)
	require.Error(t, err, "almd install command should have failed due to source resolution error")

	depFilePath := filepath.Join(tempDir, depPath)
	_, statErr := os.Stat(depFilePath)
	assert.True(t, os.IsNotExist(statErr), "depBadBranch file should not have been created")

	lockFilePath := filepath.Join(tempDir, lockfile.LockfileName)
	currentLockCfg := readAlmdLockToml(t, lockFilePath)
	originalLockCfg := lockfile.Lockfile{}
	errUnmarshal := toml.Unmarshal([]byte(initialLockfile), &originalLockCfg)
	require.NoError(t, errUnmarshal, "Failed to unmarshal original lockfile content for comparison")
	assert.Equal(t, originalLockCfg, currentLockCfg, "almd-lock.toml should be unchanged after source resolution error")

	projTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	currentProjCfg := readProjectToml(t, projTomlPath)
	originalProjCfg := project.Project{}
	errUnmarshalProj := toml.Unmarshal([]byte(initialProjectToml), &originalProjCfg)
	require.NoError(t, errUnmarshalProj, "Failed to unmarshal original project.toml content for comparison")
	assert.Equal(t, originalProjCfg, currentProjCfg, "project.toml should be unchanged")
}

// TestInstallCommand_ProjectTomlNotFound verifies that the install command fails
// with an appropriate error message when project.toml is missing from the current
// directory.
func TestInstallCommand_ProjectTomlNotFound(t *testing.T) {
	// Test setup and assertions for missing project.toml scenario
	tempDir := setupInstallTestEnvironment(t, "", "", nil)

	err := runInstallCommand(t, tempDir)

	require.Error(t, err, "almd install should return an error when project.toml is not found")
	assert.Contains(t, err.Error(), config.ProjectTomlName, "Error message should mention project.toml")
	assert.Contains(t, err.Error(), "not found in the current directory", "Error message should indicate file not found in current directory")
}



================================================
File: internal/cli/list/list.go
================================================
// Package list implements the 'list' command for displaying project dependencies and their status.
package list

import (
	"fmt"
	"os"

	"github.com/fatih/color"
	"github.com/urfave/cli/v2"

	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/lockfile"
)

// dependencyDisplayInfo aggregates dependency information for display formatting.
type dependencyDisplayInfo struct {
	Name           string // From project.toml
	ProjectSource  string // From project.toml
	ProjectPath    string // From project.toml
	LockedSource   string // From lockfile
	LockedHash     string // From lockfile
	FileExists     bool
	IsLocked       bool
	FileStatusInfo string // Human-readable status
}

// ListCmd returns a cli.Command that displays all project dependencies and their status.
func ListCmd() *cli.Command {
	return &cli.Command{
		Name:    "list",
		Aliases: []string{"ls"},
		Usage:   "Displays project dependencies and their status.",
		Action: func(c *cli.Context) error {
			projectTomlPath := "project.toml"

			proj, err := config.LoadProjectToml(".")
			if err != nil {
				if os.IsNotExist(err) {
					return cli.Exit(fmt.Sprintf("Error: %s not found. No project configuration loaded.", projectTomlPath), 1)
				}
				return cli.Exit(fmt.Sprintf("Error loading %s: %v", projectTomlPath, err), 1)
			}

			lf, err := lockfile.Load(".")
			if err != nil {
				return cli.Exit(fmt.Sprintf("Error loading %s: %v", lockfile.LockfileName, err), 1)
			}
			if lf == nil {
				lf = lockfile.New()
			}

			var displayDeps []dependencyDisplayInfo

			wd, err := os.Getwd()
			if err != nil {
				wd = "."
			}

			// Colors chosen for consistency with common terminal themes and accessibility:
			// - Magenta for project metadata (distinctive but not alarming)
			// - Yellow for hashes (conventional for references)
			// - White/Gray for general content (good readability)
			projectNameColor := color.New(color.FgMagenta, color.Bold, color.Underline).SprintFunc()
			projectVersionColor := color.New(color.FgMagenta).SprintFunc()
			projectPathColor := color.New(color.FgHiBlack, color.Bold, color.Underline).SprintFunc()
			dependenciesHeaderColor := color.New(color.FgCyan, color.Bold).SprintFunc()
			depNameColor := color.New(color.FgWhite).SprintFunc()
			depHashColor := color.New(color.FgYellow).SprintFunc()
			depPathColor := color.New(color.FgHiBlack).SprintFunc()

			fmt.Printf("%s@%s %s\n\n", projectNameColor(proj.Package.Name),
				projectVersionColor(proj.Package.Version),
				projectPathColor(wd))

			if len(proj.Dependencies) == 0 {
				fmt.Println(dependenciesHeaderColor("dependencies:"))
				fmt.Println("No dependencies found in project.toml.")
				return nil
			}

			fmt.Println(dependenciesHeaderColor("dependencies:"))
			for name, depDetails := range proj.Dependencies {
				info := dependencyDisplayInfo{
					Name:          name,
					ProjectSource: depDetails.Source,
					ProjectPath:   depDetails.Path,
				}

				if lockEntry, ok := lf.Package[name]; ok {
					info.IsLocked = true
					info.LockedSource = lockEntry.Source
					info.LockedHash = lockEntry.Hash
				} else {
					info.IsLocked = false
					info.FileStatusInfo = "not locked"
				}

				if _, err := os.Stat(depDetails.Path); err == nil {
					info.FileExists = true
				} else if os.IsNotExist(err) {
					// Accumulate status messages to show all relevant issues at once
					info.FileExists = false
					if info.FileStatusInfo != "" {
						info.FileStatusInfo += ", missing"
					} else {
						info.FileStatusInfo = "missing"
					}
				} else {
					// Handle unexpected filesystem errors while preserving existing status
					info.FileExists = false
					if info.FileStatusInfo != "" {
						info.FileStatusInfo += ", error checking file"
					} else {
						info.FileStatusInfo = "error checking file"
					}
					fmt.Fprintf(os.Stderr, "Warning: could not check status of %s: %v\n", depDetails.Path, err)
				}
				displayDeps = append(displayDeps, info)
			}

			for _, dep := range displayDeps {
				// Three states for hash display:
				// - "not locked": Dependency missing from lockfile
				// - hash value: Normal case with locked dependency
				// - "locked (no hash)": Edge case where dependency is locked but hash is empty
				lockedHash := "not locked"
				if dep.IsLocked && dep.LockedHash != "" {
					lockedHash = dep.LockedHash
				} else if dep.IsLocked && dep.LockedHash == "" {
					lockedHash = "locked (no hash)"
				}

				fmt.Printf("%s %s %s\n", depNameColor(dep.Name), depHashColor(lockedHash), depPathColor(dep.ProjectPath))
			}
			return nil
		},
	}
}



================================================
File: internal/cli/list/list_test.go
================================================
package list

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"github.com/urfave/cli/v2"
)

// setupListTestEnvironment creates an isolated test environment with configurable project files.
// The environment includes project.toml, almd-lock.toml, and any additional dependency files.
// Returns the path to the temporary directory.
func setupListTestEnvironment(t *testing.T, projectTomlContent string, lockfileContent string, depFiles map[string]string) string {
	t.Helper()
	tempDir := t.TempDir()

	if projectTomlContent != "" {
		projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
		err := os.WriteFile(projectTomlPath, []byte(projectTomlContent), 0644)
		require.NoError(t, err, "Failed to write project.toml")
	}

	if lockfileContent != "" {
		lockfilePath := filepath.Join(tempDir, config.LockfileName)
		err := os.WriteFile(lockfilePath, []byte(lockfileContent), 0644)
		require.NoError(t, err, "Failed to write almd-lock.toml")
	}

	for relPath, content := range depFiles {
		absPath := filepath.Join(tempDir, relPath)
		err := os.MkdirAll(filepath.Dir(absPath), 0755)
		require.NoError(t, err, "Failed to create parent directory for dep file")
		err = os.WriteFile(absPath, []byte(content), 0644)
		require.NoError(t, err, "Failed to write dependency file")
	}

	return tempDir
}

// runListCommand executes the list command in a test environment with captured output.
// Important: This function temporarily changes CWD and redirects stdout, but restores both
// even if the command fails. This allows for testing error cases without side effects.
func runListCommand(t *testing.T, testDir string, appArgs ...string) (string, error) {
	t.Helper()

	// Save original stdout and working directory for restoration
	originalStdout := os.Stdout
	originalWD, err := os.Getwd()
	require.NoError(t, err, "Failed to get current working directory")

	// Setup stdout capture
	r, w, _ := os.Pipe()
	os.Stdout = w

	err = os.Chdir(testDir)
	require.NoError(t, err, "Failed to change working directory to testDir")

	defer func() {
		os.Stdout = originalStdout
		err := os.Chdir(originalWD)
		if err != nil {
			fmt.Fprintf(os.Stderr, "Error changing back to original directory: %v\n", err)
		}
		_ = r.Close()
		_ = w.Close()
	}()

	app := &cli.App{
		Commands: []*cli.Command{
			ListCmd(),
		},
		// ExitErrHandler prevents os.Exit during tests while still capturing errors
		ExitErrHandler: func(context *cli.Context, err error) {
			if err != nil {
				fmt.Fprintf(os.Stderr, "Note: cli.ExitErrHandler caught error (expected for tests): %v\n", err)
			}
		},
	}
	fullArgs := []string{"almd"}
	fullArgs = append(fullArgs, appArgs...)

	t.Setenv("NO_COLOR", "1")

	cmdErr := app.Run(fullArgs)

	err = w.Close()
	if err != nil {
		fmt.Fprintf(os.Stderr, "Note: Error closing pipe writer (often expected on app error): %v\n", err)
	}

	var outBuf bytes.Buffer
	_, readErr := outBuf.ReadFrom(r)
	if readErr != nil && readErr.Error() != "io: read/write on closed pipe" {
		require.NoError(t, readErr, "Failed to read from stdout pipe")
	}

	return outBuf.String(), cmdErr
}

// Tests for various states of project.toml without dependencies
func TestListCommand_NoDependencies(t *testing.T) {
	t.Run("project.toml exists but is empty", func(t *testing.T) {
		projectTomlContent := `
[package]
name = "test-project"
version = "0.1.0"
description = "A test project."
license = "MIT"
`
		tempDir := setupListTestEnvironment(t, projectTomlContent, "", nil)
		output, err := runListCommand(t, tempDir, "list")

		require.NoError(t, err)
		assert.Contains(t, output, "test-project@0.1.0")
		assert.Contains(t, output, tempDir) // Project path
		assert.Contains(t, output, "dependencies:")
		// Check that there are no dependency lines after "dependencies:"
		lines := strings.Split(strings.TrimSpace(output), "\n")
		depHeaderIndex := -1
		for i, line := range lines {
			if strings.Contains(line, "dependencies:") {
				depHeaderIndex = i
				break
			}
		}
		require.NotEqual(t, -1, depHeaderIndex, "Dependencies header not found")
		assert.Contains(t, output, "No dependencies found in project.toml.", "Expected 'No dependencies found' message")
	})

	t.Run("project.toml with empty dependencies table", func(t *testing.T) {
		projectTomlContent := `
[package]
name = "test-project-empty-deps"
version = "0.1.0"
description = "A test project."
license = "MIT"

[dependencies]
`
		tempDir := setupListTestEnvironment(t, projectTomlContent, "", nil)
		output, err := runListCommand(t, tempDir, "list")

		require.NoError(t, err)
		assert.Contains(t, output, "test-project-empty-deps@0.1.0")
		assert.Contains(t, output, tempDir)
		assert.Contains(t, output, "dependencies:")
		assert.Contains(t, output, "No dependencies found in project.toml.")
	})

	t.Run("project.toml with no dependencies table", func(t *testing.T) {
		projectTomlContent := `
[package]
name = "test-project-no-deps-table"
version = "0.1.0"
`
		tempDir := setupListTestEnvironment(t, projectTomlContent, "", nil)
		output, err := runListCommand(t, tempDir, "list")

		require.NoError(t, err)
		assert.Contains(t, output, "test-project-no-deps-table@0.1.0")
		assert.Contains(t, output, tempDir)
		assert.Contains(t, output, "dependencies:")
		assert.Contains(t, output, "No dependencies found in project.toml.")
	})
}

// Tests list command when project.toml is missing
func TestListCommand_ProjectTomlNotFound(t *testing.T) {
	tempDir := t.TempDir()

	t.Setenv("NO_COLOR", "1")

	_, err := runListCommand(t, tempDir, "list")

	require.Error(t, err, "Expected an error when project.toml is not found")
	require.NotNil(t, err)
	assert.Contains(t, err.Error(), "Error: project.toml not found. No project configuration loaded.")
}

// Tests list command with a single dependency that is fully installed and properly locked
func TestListCommand_SingleDependencyFullyInstalledAndLocked(t *testing.T) {
	projectName := "my-lib-project"
	projectVersion := "1.2.3"
	depName := "cool-lib"
	depSource := "github:user/repo/cool-lib.lua@v1.0.0"
	depPath := "libs/cool-lib.lua"
	depContent := "-- cool lib content"
	depHash := "sha256:0567f79f438dda700c93759f193096199983806187765462085899533180c07e"

	projectTomlContent := fmt.Sprintf(`
[package]
name = "%s"
version = "%s"
description = "A test project with one lib."
license = "MIT"

[dependencies.%s]
source = "%s"
path = "%s"
`, projectName, projectVersion, depName, depSource, depPath)

	lockfileContent := fmt.Sprintf(`
api_version = "1"
[package.%s]
source = "https://raw.githubusercontent.com/user/repo/v1.0.0/cool-lib.lua"
path = "%s"
hash = "%s"
`, depName, depPath, depHash)

	depFiles := map[string]string{
		depPath: depContent,
	}

	tempDir := setupListTestEnvironment(t, projectTomlContent, lockfileContent, depFiles)
	resolvedTempDir, err := filepath.EvalSymlinks(tempDir)
	require.NoError(t, err, "Failed to evaluate symlinks for tempDir")

	expectedOutput := fmt.Sprintf("%s@%s %s\n\ndependencies:\n%s %s %s\n",
		projectName, projectVersion, resolvedTempDir,
		depName, depHash, depPath,
	)

	output, err := runListCommand(t, tempDir, "list")

	require.NoError(t, err)
	assert.Equal(t, strings.TrimSpace(expectedOutput), strings.TrimSpace(output))
}

// Tests list command with multiple dependencies in various states:
// - Fully installed and locked
// - In manifest but not locked
// - In manifest and locked but file missing
func TestListCommand_MultipleDependenciesVariedStates(t *testing.T) {
	projectName := "multi-dep-project"
	projectVersion := "0.5.0"

	depAName := "depA"
	depASourceToml := "github:user/repo/depA.lua@v1"
	depAPath := "libs/depA.lua"
	depAContent := "contentA"
	depAHashLock := "sha256:87428fc522803d31065e7bce3cf03fe475096631e5e07bbd7a0fde60c4cf25c7"
	depARawURLLock := "https://raw.githubusercontent.com/user/repo/v1/depA.lua"

	depBName := "depB"
	depBSourceToml := "github:user/repo/depB.lua@main"
	depBPath := "libs/depB.lua"
	depBContent := "contentB"

	depCName := "depC"
	depCSourceToml := "github:user/repo/depC.lua@v2"
	depCPath := "libs/depC.lua"
	depCHashLock := "sha256:2475709fe8a3c28964798420ddd7de39cd9d1930e91035030966877040150863"
	depCRawURLLock := "https://raw.githubusercontent.com/user/repo/v2/depC.lua"

	projectTomlContent := fmt.Sprintf(`
[package]
name = "%s"
version = "%s"

[dependencies.%s]
source = "%s"
path = "%s"

[dependencies.%s]
source = "%s"
path = "%s"

[dependencies.%s]
source = "%s"
path = "%s"
`, projectName, projectVersion,
		depAName, depASourceToml, depAPath,
		depBName, depBSourceToml, depBPath,
		depCName, depCSourceToml, depCPath)

	lockfileContent := fmt.Sprintf(`
api_version = "1"
[package.%s]
source = "%s"
path = "%s"
hash = "%s"

[package.%s]
source = "%s"
path = "%s"
hash = "%s"
`, depAName, depARawURLLock, depAPath, depAHashLock,
		depCName, depCRawURLLock, depCPath, depCHashLock)

	depFiles := map[string]string{
		depAPath: depAContent,
		depBPath: depBContent,
	}

	tempDir := setupListTestEnvironment(t, projectTomlContent, lockfileContent, depFiles)
	resolvedTempDir, err := filepath.EvalSymlinks(tempDir)
	require.NoError(t, err, "Failed to evaluate symlinks for tempDir")

	output, err := runListCommand(t, tempDir, "list")
	require.NoError(t, err)

	outputLines := strings.Split(strings.TrimSpace(output), "\n")
	require.GreaterOrEqual(t, len(outputLines), 5, "Output should have at least 5 lines")

	expectedHeader := fmt.Sprintf("%s@%s %s", projectName, projectVersion, resolvedTempDir)
	assert.Equal(t, expectedHeader, outputLines[0], "Project header should match")

	assert.Equal(t, "dependencies:", outputLines[2], "Dependencies label should match")

	expectedDeps := map[string]bool{
		fmt.Sprintf("%s %s %s", depAName, depAHashLock, depAPath): true,
		fmt.Sprintf("%s %s %s", depBName, "not locked", depBPath): true,
		fmt.Sprintf("%s %s %s", depCName, depCHashLock, depCPath): true,
	}

	for _, line := range outputLines[3:] {
		assert.True(t, expectedDeps[line], fmt.Sprintf("Unexpected dependency entry: %s", line))
	}

	assert.Equal(t, 3, len(outputLines)-3, "Should have exactly 3 dependency entries")
}

// Tests that 'ls' works as an alias for 'list'
func TestListCommand_AliasLs(t *testing.T) {
	projectName := "alias-test-project"
	projectVersion := "1.0.0"
	depName := "lib-for-ls"
	depSource := "github:user/repo/lib-for-ls.lua@v0.1"
	depPath := "modules/lib-for-ls.lua"
	depContent := "function lib_for_ls() return 'ls alias test' end"
	depHash := "sha256:b0d9a380789173d734093af007772d31790ead09999b891d180099160e27f9a0"

	projectTomlContent := fmt.Sprintf(`
[package]
name = "%s"
version = "%s"
[dependencies.%s]
source = "%s"
path = "%s"
`, projectName, projectVersion, depName, depSource, depPath)

	lockfileContent := fmt.Sprintf(`
api_version = "1"
[package.%s]
source = "https://raw.githubusercontent.com/user/repo/v0.1/lib-for-ls.lua"
path = "%s"
hash = "%s"
`, depName, depPath, depHash)

	depFiles := map[string]string{
		depPath: depContent,
	}

	tempDir := setupListTestEnvironment(t, projectTomlContent, lockfileContent, depFiles)
	resolvedTempDir, err := filepath.EvalSymlinks(tempDir)
	require.NoError(t, err, "Failed to evaluate symlinks for tempDir")

	expectedOutput := fmt.Sprintf("%s@%s %s\n\ndependencies:\n%s %s %s\n",
		projectName, projectVersion, resolvedTempDir,
		depName, depHash, depPath,
	)

	output, err := runListCommand(t, tempDir, "ls")

	require.NoError(t, err)
	assert.Equal(t, strings.TrimSpace(expectedOutput), strings.TrimSpace(output), "Output of 'almd ls' should match expected 'almd list' output")
}



================================================
File: internal/cli/remove/remove.go
================================================
// Package remove handles project dependency removal operations
package remove

import (
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/fatih/color"
	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/lockfile"
	"github.com/nightconcept/almandine/internal/core/source"
	"github.com/urfave/cli/v2"
)

func isDirEmpty(path string) (bool, error) {
	entries, err := os.ReadDir(path)
	if err != nil {
		return false, fmt.Errorf("failed to read directory %s: %w", path, err)
	}
	return len(entries) == 0, nil
}

// RemoveCmd handles the 'remove' subcommand
func RemoveCmd() *cli.Command {
	return &cli.Command{
		Name:      "remove",
		Usage:     "Remove a dependency from the project",
		ArgsUsage: "DEPENDENCY",
		Action: func(c *cli.Context) error {
			startTime := time.Now()
			if !c.Args().Present() {
				return cli.Exit("Error: Dependency name argument is required.", 1)
			}

			depName := c.Args().First()

			proj, err := config.LoadProjectToml(".")
			if err != nil {
				return cli.Exit(fmt.Sprintf("Error: Failed to load %s: %v", config.ProjectTomlName, err), 1)
			}

			if len(proj.Dependencies) == 0 {
				return cli.Exit(fmt.Sprintf("Error: No dependencies found in %s.", config.ProjectTomlName), 1)
			}

			dep, ok := proj.Dependencies[depName]
			if !ok {
				return cli.Exit(fmt.Sprintf("Error: Dependency '%s' not found in %s.", depName, config.ProjectTomlName), 1)
			}

			dependencyPath := dep.Path
			dependencySource := dep.Source
			delete(proj.Dependencies, depName)

			if err := config.WriteProjectToml(".", proj); err != nil {
				return cli.Exit(fmt.Sprintf("Error: Failed to update %s: %v", config.ProjectTomlName, err), 1)
			}

			fileDeleted := false
			if err := os.Remove(dependencyPath); err != nil {
				if !os.IsNotExist(err) {
					_, _ = fmt.Fprintf(c.App.ErrWriter, "Warning: Failed to delete dependency file '%s': %v. Manifest updated.\n", dependencyPath, err)
				}
			} else {
				fileDeleted = true
				currentDir := filepath.Dir(dependencyPath)
				projectRootAbs, errAbs := filepath.Abs(".")
				if errAbs != nil {
					_, _ = fmt.Fprintf(c.App.ErrWriter, "Warning: Could not determine project root absolute path: %v. Skipping directory cleanup.\n", errAbs)
				} else {
					// Recursively clean up empty parent directories up to project root
					for {
						absCurrentDir, errLoopAbs := filepath.Abs(currentDir)
						if errLoopAbs != nil {
							_, _ = fmt.Fprintf(c.App.ErrWriter, "Warning: Could not get absolute path for '%s': %v. Stopping directory cleanup.\n", currentDir, errLoopAbs)
							break
						}
						if absCurrentDir == projectRootAbs || filepath.Dir(absCurrentDir) == absCurrentDir || currentDir == "." {
							break
						}
						empty, errEmpty := isDirEmpty(currentDir)
						if errEmpty != nil {
							_, _ = fmt.Fprintf(c.App.ErrWriter, "Warning: Could not check if directory '%s' is empty: %v. Stopping directory cleanup.\n", currentDir, errEmpty)
							break
						}
						if !empty {
							break
						}
						if errRemoveDir := os.Remove(currentDir); errRemoveDir != nil {
							_, _ = fmt.Fprintf(c.App.ErrWriter, "Warning: Failed to remove empty directory '%s': %v. Stopping directory cleanup.\n", currentDir, errRemoveDir)
							break
						}
						currentDir = filepath.Dir(currentDir)
					}
				}
			}

			lf, errLock := lockfile.Load(".")
			lockfileUpdated := false
			if errLock != nil {
				_, _ = fmt.Fprintf(c.App.ErrWriter, "Warning: Failed to load %s: %v. Manifest and file processed.\n", lockfile.LockfileName, errLock)
			} else {
				if lf.Package != nil {
					if _, depInLock := lf.Package[depName]; depInLock {
						delete(lf.Package, depName)
						if errSaveLock := lockfile.Save(".", lf); errSaveLock != nil {
							_, _ = fmt.Fprintf(c.App.ErrWriter, "Warning: Failed to update %s: %v. Manifest and file processed.\n", lockfile.LockfileName, errSaveLock)
						} else {
							lockfileUpdated = true
						}
					}
				}
			}

			fmt.Println("Progress: resolved 0, reused 0, downloaded 0, removed 1, done")
			fmt.Println()
			_, _ = color.New(color.FgWhite, color.Bold).Println("dependencies:")

			// Use "unknown" for version when ref is missing or invalid to maintain consistent output format
			versionStr := "unknown"
			parsedInfo, parseErr := source.ParseSourceURL(dependencySource)
			if parseErr == nil && parsedInfo != nil && parsedInfo.Ref != "" && !strings.HasPrefix(parsedInfo.Ref, "error:") {
				versionStr = parsedInfo.Ref
			}

			_, _ = color.New(color.FgRed).Printf("- %s %s\n", depName, versionStr)
			fmt.Println()
			duration := time.Since(startTime)
			fmt.Printf("Done in %.1fs\n", duration.Seconds())

			// Fallback to os.Stderr if App.ErrWriter is not configured
			var errWriter io.Writer = os.Stderr
			if c.App != nil && c.App.ErrWriter != nil {
				errWriter = c.App.ErrWriter
			}

			if !fileDeleted {
				_, _ = fmt.Fprintf(errWriter, "Note: Dependency file '%s' was not deleted (either not found or error during deletion).\n", dependencyPath)
			}
			if !lockfileUpdated && errLock == nil {
				_, _ = fmt.Fprintf(errWriter, "Note: Lockfile '%s' was not updated for '%s' (either not found in lockfile or error during save).\n", lockfile.LockfileName, depName)
			}

			return nil
		},
	}
}



================================================
File: internal/cli/remove/remove_test.go
================================================
// Package remove provides functionality to remove dependencies from Almandine projects.
package remove

import (
	"os"
	"path/filepath"
	"testing"

	"github.com/BurntSushi/toml"
	"github.com/nightconcept/almandine/internal/core/config"
	"github.com/nightconcept/almandine/internal/core/lockfile"
	"github.com/nightconcept/almandine/internal/core/project"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"github.com/urfave/cli/v2"
)

// TestRemoveCommand_SuccessfulRemoval verifies that a dependency can be completely
// removed from project.toml, almd-lock.toml, and the filesystem.
func TestRemoveCommand_SuccessfulRemoval(t *testing.T) {
	originalWd, err := os.Getwd()
	t.Logf("Test starting in directory: %s", originalWd)
	require.NoError(t, err, "Failed to get current working directory")
	defer func() {
		t.Logf("Test cleanup: restoring directory to %s", originalWd)
		require.NoError(t, os.Chdir(originalWd), "Failed to restore original working directory")
	}()

	projectToml := `
[package]
name = "test-project"
version = "0.1.0"

[dependencies]
testlib = { source = "github:user/repo/file.lua@abc123", path = "libs/testlib.lua" }
`

	lockToml := `
api_version = "1"

[package.testlib]
source = "https://raw.githubusercontent.com/user/repo/abc123/file.lua"
path = "libs/testlib.lua"
hash = "sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
`

	depFiles := map[string]string{
		"libs/testlib.lua": "-- Test dependency content",
	}

	tempDir := setupRemoveTestEnvironment(t, projectToml, lockToml, depFiles)

	if _, err := os.Stat(filepath.Join(tempDir, "project.toml")); err != nil {
		t.Logf("After setup - project.toml status: %v", err)
	} else {
		t.Log("After setup - project.toml exists")
	}

	err = os.Chdir(tempDir)
	t.Logf("Changed to temp directory: %s", tempDir)
	require.NoError(t, err, "Failed to change to temporary directory")

	err = runRemoveCommand(t, tempDir, "testlib")
	require.NoError(t, err)

	projContent, err := os.ReadFile(filepath.Join(tempDir, "project.toml"))
	require.NoError(t, err)
	assert.NotContains(t, string(projContent), "testlib")

	var proj struct {
		Dependencies map[string]interface{} `toml:"dependencies"`
	}
	err = toml.Unmarshal(projContent, &proj)
	require.NoError(t, err)
	assert.NotContains(t, proj.Dependencies, "testlib")

	lockContent, err := os.ReadFile(filepath.Join(tempDir, "almd-lock.toml"))
	require.NoError(t, err)
	assert.NotContains(t, string(lockContent), "testlib")

	var lock struct {
		Package map[string]interface{} `toml:"package"`
	}
	err = toml.Unmarshal(lockContent, &lock)
	require.NoError(t, err)
	assert.NotContains(t, lock.Package, "testlib")

	_, err = os.Stat(filepath.Join(tempDir, "libs", "testlib.lua"))
	assert.True(t, os.IsNotExist(err), "Dependency file should be deleted")

	_, err = os.Stat(filepath.Join(tempDir, "libs"))
	assert.True(t, os.IsNotExist(err), "Empty libs directory should be removed")
}

// TestRemove_DependencyNotFound verifies the command fails appropriately when
// attempting to remove a non-existent dependency, ensuring other dependencies
// remain untouched.
func TestRemove_DependencyNotFound(t *testing.T) {
	originalWd, err := os.Getwd()
	t.Logf("Test starting in directory: %s", originalWd)
	require.NoError(t, err, "Failed to get current working directory")
	defer func() {
		t.Logf("Test cleanup: restoring directory to %s", originalWd)
		require.NoError(t, os.Chdir(originalWd), "Failed to restore original working directory")
	}()

	tempDir := t.TempDir()

	projectToml := `
[package]
name = "test-project"
version = "0.1.0"

[dependencies]
existing-dep = { source = "github:user/repo/file.lua", path = "libs/existing-dep.lua" }
`
	err = os.WriteFile(filepath.Join(tempDir, "project.toml"), []byte(projectToml), 0644)
	require.NoError(t, err)

	lockfileToml := `
api_version = "1"

[package.existing-dep]
source = "https://raw.githubusercontent.com/user/repo/main/file.lua"
path = "libs/existing-dep.lua"
hash = "sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
`
	err = os.WriteFile(filepath.Join(tempDir, "almd-lock.toml"), []byte(lockfileToml), 0644)
	require.NoError(t, err)

	existingDepDir := filepath.Join(tempDir, "libs")
	err = os.MkdirAll(existingDepDir, 0755)
	require.NoError(t, err)
	err = os.WriteFile(filepath.Join(existingDepDir, "existing-dep.lua"), []byte("-- test content"), 0644)
	require.NoError(t, err)

	err = os.Chdir(tempDir)
	t.Logf("Changed to temp directory: %s", tempDir)
	require.NoError(t, err, "Failed to change to temporary directory")

	err = runRemoveCommand(t, tempDir, "non-existent-dep")

	assert.Error(t, err)
	assert.Equal(t, "Error: Dependency 'non-existent-dep' not found in project.toml.", err.Error())
	assert.Equal(t, 1, err.(cli.ExitCoder).ExitCode())

	currentProjectToml, err := os.ReadFile(filepath.Join(tempDir, "project.toml"))
	require.NoError(t, err)
	assert.Equal(t, string(projectToml), string(currentProjectToml))

	currentLockfileToml, err := os.ReadFile(filepath.Join(tempDir, "almd-lock.toml"))
	require.NoError(t, err)
	assert.Equal(t, string(lockfileToml), string(currentLockfileToml))

	_, err = os.Stat(filepath.Join(existingDepDir, "existing-dep.lua"))
	assert.NoError(t, err, "existing dependency file should not be deleted")
}

// TestRemoveCommand_DepFileMissing_StillUpdatesManifests verifies that removal
// succeeds and updates manifests even when the dependency file is missing from
// the filesystem, which can happen if files were manually deleted.
func TestRemoveCommand_DepFileMissing_StillUpdatesManifests(t *testing.T) {
	originalWd, err := os.Getwd()
	require.NoError(t, err)
	defer func() {
		require.NoError(t, os.Chdir(originalWd))
	}()

	projectTomlContent := `
[package]
name = "test-project-missing-file"
version = "0.1.0"

[dependencies]
missinglib = { source = "github:user/repo/missing.lua@def456", path = "libs/missinglib.lua" }
anotherlib = { source = "github:user/repo/another.lua@ghi789", path = "libs/anotherlib.lua" }
`
	lockTomlContent := `
api_version = "1"

[package.missinglib]
source = "https://raw.githubusercontent.com/user/repo/def456/missing.lua"
path = "libs/missinglib.lua"
hash = "sha256:123"

[package.anotherlib]
source = "https://raw.githubusercontent.com/user/repo/ghi789/another.lua"
path = "libs/anotherlib.lua"
hash = "sha256:456"
`
	// Setup environment: Create project.toml and almd-lock.toml
	// but DO NOT create the actual 'missinglib.lua' file.
	// Only create 'anotherlib.lua' to ensure other files are not affected.
	depFilesToCreate := map[string]string{
		"libs/anotherlib.lua": "-- another lib content",
	}
	tempDir := setupRemoveTestEnvironment(t, projectTomlContent, lockTomlContent, depFilesToCreate)

	err = os.Chdir(tempDir)
	require.NoError(t, err, "Failed to change to temporary directory")

	// Expect no fatal error, as remove.go should gracefully handle
	// os.IsNotExist when attempting to delete the already missing file.
	err = runRemoveCommand(t, tempDir, "missinglib")
	require.NoError(t, err, "runRemoveCommand should not return a fatal error when dep file is missing")

	var projData struct {
		Dependencies map[string]project.Dependency `toml:"dependencies"`
	}
	projBytes, err := os.ReadFile(filepath.Join(tempDir, config.ProjectTomlName))
	require.NoError(t, err)
	err = toml.Unmarshal(projBytes, &projData)
	require.NoError(t, err)
	assert.NotContains(t, projData.Dependencies, "missinglib", "missinglib should be removed from project.toml")
	assert.Contains(t, projData.Dependencies, "anotherlib", "anotherlib should still exist in project.toml")

	var lockData struct {
		Package map[string]lockfile.PackageEntry `toml:"package"`
	}
	lockBytes, err := os.ReadFile(filepath.Join(tempDir, lockfile.LockfileName))
	require.NoError(t, err)
	err = toml.Unmarshal(lockBytes, &lockData)
	require.NoError(t, err)
	assert.NotContains(t, lockData.Package, "missinglib", "missinglib should be removed from almd-lock.toml")
	assert.Contains(t, lockData.Package, "anotherlib", "anotherlib should still exist in almd-lock.toml")

	_, err = os.Stat(filepath.Join(tempDir, "libs", "anotherlib.lua"))
	assert.NoError(t, err, "anotherlib.lua should still exist")

	_, err = os.Stat(filepath.Join(tempDir, "libs", "missinglib.lua"))
	assert.True(t, os.IsNotExist(err), "missinglib.lua should not exist")
}

// TestRemoveCommand_ProjectTomlNotFound verifies the command fails appropriately
// when project.toml is missing from the working directory.
func TestRemoveCommand_ProjectTomlNotFound(t *testing.T) {
	originalWd, err := os.Getwd()
	require.NoError(t, err, "Failed to get current working directory")
	defer func() {
		require.NoError(t, os.Chdir(originalWd), "Failed to restore original working directory")
	}()

	tempDir := t.TempDir()

	// Change to temp directory (which has no project.toml)
	err = os.Chdir(tempDir)
	require.NoError(t, err, "Failed to change to temporary directory: %s", tempDir)

	err = runRemoveCommand(t, tempDir, "any-dependency-name")

	require.Error(t, err, "Expected an error when project.toml is not found")

	exitErr, ok := err.(cli.ExitCoder)
	require.True(t, ok, "Error should be a cli.ExitCoder")

	assert.Equal(t, 1, exitErr.ExitCode(), "Expected exit code 1")
	// Error message should now come from config.LoadProjectToml when project.toml is not found.
	assert.Contains(t, exitErr.Error(), "Error: Failed to load project.toml:", "Error message prefix mismatch")
	// Don't check for specific OS error message text which varies between platforms
}

// TestRemoveCommand_ManifestOnlyDependency verifies the command handles dependencies
// that exist only in project.toml but not in almd-lock.toml.
func TestRemoveCommand_ManifestOnlyDependency(t *testing.T) {
	originalWd, err := os.Getwd()
	require.NoError(t, err)
	defer func() {
		require.NoError(t, os.Chdir(originalWd))
	}()

	projectTomlContent := `
[package]
name = "test-project-manifest-only"
version = "0.1.0"

[dependencies]
manifestonlylib = { source = "github:user/repo/manifestonly.lua@jkl012", path = "libs/manifestonlylib.lua" }
anotherlib = { source = "github:user/repo/another.lua@mno345", path = "libs/anotherlib.lua" }
`
	// Lockfile is empty or does not contain 'manifestonlylib'
	// It might contain other unrelated dependencies.
	lockTomlContent := `
api_version = "1"

[package.anotherlib]
source = "https://raw.githubusercontent.com/user/repo/mno345/another.lua"
path = "libs/anotherlib.lua"
hash = "sha256:789"
`
	depFilesToCreate := map[string]string{
		"libs/manifestonlylib.lua": "-- manifest only lib content",
		"libs/anotherlib.lua":      "-- another lib content",
	}
	tempDir := setupRemoveTestEnvironment(t, projectTomlContent, lockTomlContent, depFilesToCreate)

	err = os.Chdir(tempDir)
	require.NoError(t, err, "Failed to change to temporary directory")

	err = runRemoveCommand(t, tempDir, "manifestonlylib")
	require.NoError(t, err, "runRemoveCommand should not return a fatal error for manifest-only dependency")

	var projData struct {
		Dependencies map[string]project.Dependency `toml:"dependencies"`
	}
	projBytes, err := os.ReadFile(filepath.Join(tempDir, config.ProjectTomlName))
	require.NoError(t, err)
	err = toml.Unmarshal(projBytes, &projData)
	require.NoError(t, err)
	assert.NotContains(t, projData.Dependencies, "manifestonlylib", "manifestonlylib should be removed from project.toml")
	assert.Contains(t, projData.Dependencies, "anotherlib", "anotherlib should still exist in project.toml")

	var lockData struct {
		Package map[string]lockfile.PackageEntry `toml:"package"`
	}
	lockBytes, err := os.ReadFile(filepath.Join(tempDir, lockfile.LockfileName))
	require.NoError(t, err)
	err = toml.Unmarshal(lockBytes, &lockData)
	require.NoError(t, err)
	assert.NotContains(t, lockData.Package, "manifestonlylib", "manifestonlylib should not be in almd-lock.toml")
	assert.Contains(t, lockData.Package, "anotherlib", "anotherlib should still exist in almd-lock.toml")

	_, err = os.Stat(filepath.Join(tempDir, "libs", "manifestonlylib.lua"))
	assert.True(t, os.IsNotExist(err), "manifestonlylib.lua should be deleted")

	_, err = os.Stat(filepath.Join(tempDir, "libs", "anotherlib.lua"))
	assert.NoError(t, err, "anotherlib.lua should still exist")

	// Verify 'libs' directory for 'manifestonlylib.lua' was removed if it became empty
	// (In this case, 'libs' dir will still contain 'anotherlib.lua', so it won't be removed)
	// If 'anotherlib.lua' was also removed in a different test, then 'libs' would be gone.
	// Here, we just ensure 'manifestonlylib.lua' is gone.
}

// TestRemoveCommand_EmptyProjectToml verifies the command fails appropriately
// when project.toml exists but contains no dependencies.
func TestRemoveCommand_EmptyProjectToml(t *testing.T) {
	originalWd, err := os.Getwd()
	require.NoError(t, err, "Failed to get current working directory")
	defer func() {
		require.NoError(t, os.Chdir(originalWd), "Failed to restore original working directory")
	}()

	tempDir := setupRemoveTestEnvironment(t, "", "", nil)

	err = os.Chdir(tempDir)
	require.NoError(t, err, "Failed to change to temporary directory")

	depNameToRemove := "any-dep"

	err = runRemoveCommand(t, tempDir, depNameToRemove)

	require.Error(t, err, "Expected an error when project.toml is empty")

	exitErr, ok := err.(cli.ExitCoder)
	require.True(t, ok, "Error should be a cli.ExitCoder")
	assert.Equal(t, 1, exitErr.ExitCode(), "Expected exit code 1")
	// With the changes in remove.go, if project.toml is empty (or has no [dependencies] table),
	// it should return "Error: No dependencies found in project.toml."
	assert.Equal(t, "Error: No dependencies found in project.toml.", exitErr.Error())

	projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	projectTomlBytes, err := os.ReadFile(projectTomlPath)
	require.NoError(t, err, "Failed to read project.toml after command")
	assert.Equal(t, "", string(projectTomlBytes), "project.toml should remain empty")

	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)
	lockfileBytes, err := os.ReadFile(lockfilePath)
	require.NoError(t, err, "Failed to read almd-lock.toml after command")
	assert.Equal(t, "", string(lockfileBytes), "almd-lock.toml should remain empty")
}

// setupRemoveTestEnvironment creates a temporary test environment with the specified
// initial content for project.toml and almd-lock.toml, and any dependency files.
// It returns the path to the temporary directory.
func setupRemoveTestEnvironment(t *testing.T, initialProjectTomlContent string, initialLockfileContent string, depFiles map[string]string) (tempDir string) {
	t.Helper()
	tempDir = t.TempDir()

	// Always create project.toml, using provided content (empty string means empty file)
	projectTomlPath := filepath.Join(tempDir, config.ProjectTomlName)
	err := os.WriteFile(projectTomlPath, []byte(initialProjectTomlContent), 0644)
	require.NoError(t, err, "Failed to write project.toml")

	// Always create almd-lock.toml, using provided content (empty string means empty file)
	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)
	err = os.WriteFile(lockfilePath, []byte(initialLockfileContent), 0644)
	require.NoError(t, err, "Failed to write almd-lock.toml")

	for relPath, content := range depFiles {
		absPath := filepath.Join(tempDir, relPath)
		err := os.MkdirAll(filepath.Dir(absPath), 0755)
		require.NoError(t, err, "Failed to create directory for dependency file: %s", filepath.Dir(absPath))
		err = os.WriteFile(absPath, []byte(content), 0644)
		require.NoError(t, err, "Failed to write dependency file: %s", absPath)
	}

	return tempDir
}

// runRemoveCommand executes the remove command with the given arguments in the specified
// working directory.
func runRemoveCommand(t *testing.T, workDir string, removeCmdArgs ...string) error {
	t.Helper()

	// Remove working directory handling from here since it's now handled in the test
	app := &cli.App{
		Name: "almd-test-remove",
		Commands: []*cli.Command{
			RemoveCmd(),
		},
		Writer:         os.Stderr,
		ErrWriter:      os.Stderr,
		ExitErrHandler: func(context *cli.Context, err error) {},
	}

	cliArgs := []string{"almd-test-remove", "remove"}
	cliArgs = append(cliArgs, removeCmdArgs...)

	return app.Run(cliArgs)
}



================================================
File: internal/cli/self/self.go
================================================
// Package self provides self-management functionality for the almd CLI application.
package self

import (
	"bufio"
	"fmt"
	"os"
	"strings"

	"github.com/Masterminds/semver/v3"
	"github.com/creativeprojects/go-selfupdate"
	"github.com/urfave/cli/v2"
)

// SelfCmd creates a command for managing the almd CLI application's lifecycle,
// currently supporting self-update functionality.
func SelfCmd() *cli.Command {
	return &cli.Command{
		Name:  "self",
		Usage: "Manage the almd CLI application itself",
		Subcommands: []*cli.Command{
			{
				Name:  "update",
				Usage: "Update almd to the latest version",
				Flags: []cli.Flag{
					&cli.BoolFlag{
						Name:    "yes",
						Aliases: []string{"y"},
						Usage:   "Automatically confirm the update",
					},
					&cli.BoolFlag{
						Name:  "check",
						Usage: "Check for available updates without installing",
					},
					&cli.StringFlag{
						Name:  "source",
						Usage: "Specify a custom GitHub update source as 'owner/repo' (e.g., 'nightconcept/almandine')",
					},
					&cli.BoolFlag{
						Name:  "verbose",
						Usage: "Enable verbose output",
					},
				},
				Action: updateAction,
			},
		},
	}
}

// updateAction handles the self-update process for the CLI application.
// It supports checking for and applying updates from GitHub releases.
// The function handles version comparison, user confirmation (unless --yes is specified),
// and supports custom GitHub repositories via the --source flag.
func updateAction(c *cli.Context) error {
	currentVersionStr := c.App.Version
	verbose := c.Bool("verbose")

	if verbose {
		fmt.Printf("almd current version: %s\n", currentVersionStr)
	}

	// Handle version strings both with and without 'v' prefix for compatibility
	currentSemVer, err := semver.NewVersion(strings.TrimPrefix(currentVersionStr, "v"))
	if err != nil {
		if !strings.HasPrefix(currentVersionStr, "v") {
			currentSemVer, err = semver.NewVersion(currentVersionStr)
		}
		if err != nil {
			return cli.Exit(fmt.Sprintf("Error parsing current version '%s': %v. Ensure version is like vX.Y.Z or X.Y.Z.", currentVersionStr, err), 1)
		}
	}
	if verbose {
		fmt.Printf("Parsed current semantic version: %s\n", currentSemVer.String())
	}

	sourceFlag := c.String("source")
	repoSlug := "nightconcept/almandine" // Default repository

	if sourceFlag != "" {
		parts := strings.Split(sourceFlag, "/")
		if len(parts) == 2 && parts[0] != "" && parts[1] != "" {
			repoSlug = sourceFlag
			if verbose {
				fmt.Printf("Using custom GitHub source: %s\n", repoSlug)
			}
		} else {
			return cli.Exit(fmt.Sprintf("Invalid --source format. Expected 'owner/repo', got: %s.", sourceFlag), 1)
		}
	} else {
		if verbose {
			fmt.Printf("Using default GitHub source: %s\n", repoSlug)
		}
	}

	ghSource, err := selfupdate.NewGitHubSource(selfupdate.GitHubConfig{})
	if err != nil {
		return cli.Exit(fmt.Sprintf("Error creating GitHub source: %v", err), 1)
	}

	updater, err := selfupdate.NewUpdater(selfupdate.Config{
		Source: ghSource,
	})
	if err != nil {
		return cli.Exit(fmt.Sprintf("Failed to initialize updater: %v", err), 1)
	}

	if verbose {
		fmt.Println("Checking for latest version...")
	}

	repository := selfupdate.ParseSlug(repoSlug)
	latestRelease, found, err := updater.DetectLatest(c.Context, repository)
	if err != nil {
		return cli.Exit(fmt.Sprintf("Error detecting latest version: %v", err), 1)
	}

	if !found {
		if verbose {
			fmt.Println("No update available (checked with source, no newer version found).")
		}
		fmt.Printf("Current version %s is already the latest.\n", currentVersionStr)
		return nil
	}

	if verbose {
		fmt.Printf("Latest version detected: %s (Release URL: %s)\n", latestRelease.Version(), latestRelease.URL)
		if latestRelease.AssetURL != "" {
			fmt.Printf("Asset URL: %s\n", latestRelease.AssetURL)
		}
		if latestRelease.ReleaseNotes != "" {
			fmt.Printf("Release Notes:\n%s\n", latestRelease.ReleaseNotes)
		}
	}

	if !latestRelease.GreaterThan(currentSemVer.String()) {
		fmt.Printf("Current version %s is already the latest or newer.\n", currentVersionStr)
		return nil
	}

	fmt.Printf("New version available: %s (current: %s)\n", latestRelease.Version(), currentVersionStr)

	if c.Bool("check") {
		return nil
	}

	if !c.Bool("yes") {
		fmt.Print("Do you want to update? (y/N): ")
		reader := bufio.NewReader(os.Stdin)
		input, _ := reader.ReadString('\n')
		if strings.TrimSpace(strings.ToLower(input)) != "y" {
			fmt.Println("Update cancelled.")
			return nil
		}
	}

	fmt.Printf("Updating to %s...\n", latestRelease.Version())
	execPath, err := os.Executable()
	if err != nil {
		return cli.Exit(fmt.Sprintf("Could not get executable path: %v", err), 1)
	}
	if verbose {
		fmt.Printf("Current executable path: %s\n", execPath)
	}

	err = updater.UpdateTo(c.Context, latestRelease, execPath)
	if err != nil {
		return cli.Exit(fmt.Sprintf("Failed to update: %v", err), 1)
	}

	fmt.Printf("Successfully updated to version %s.\n", latestRelease.Version())
	return nil
}



================================================
File: internal/core/config/config.go
================================================
package config

import (
	"bytes"
	"os"
	"path/filepath"

	"github.com/BurntSushi/toml"
	"github.com/nightconcept/almandine/internal/core/project"
)

const ProjectTomlName = "project.toml"
const LockfileName = "almd-lock.toml"

// LoadProjectToml reads the project.toml file from the given dirPath and unmarshals it.
func LoadProjectToml(dirPath string) (*project.Project, error) {
	fullPath := filepath.Join(dirPath, ProjectTomlName)
	data, err := os.ReadFile(fullPath)
	if err != nil {
		return nil, err
	}

	var proj project.Project
	if err := toml.Unmarshal(data, &proj); err != nil {
		return nil, err
	}
	return &proj, nil
}

// WriteProjectToml marshals the Project data and writes it to the specified dirPath.
// It will overwrite the file if it already exists.
func WriteProjectToml(dirPath string, data *project.Project) error {
	buf := new(bytes.Buffer)
	if err := toml.NewEncoder(buf).Encode(data); err != nil {
		return err
	}

	fullPath := filepath.Join(dirPath, ProjectTomlName)
	file, err := os.OpenFile(fullPath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0644)
	if err != nil {
		return err
	}
	defer func() { _ = file.Close() }()

	_, err = file.Write(buf.Bytes())
	return err
}



================================================
File: internal/core/config/config_test.go
================================================
package config

import (
	"os"
	"path/filepath"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"github.com/nightconcept/almandine/internal/core/project"
)

func TestLoadProjectToml_Valid(t *testing.T) {
	tempDir := t.TempDir()
	validTomlContent := `
[package]
name = "test-project"
version = "0.1.0"
license = "MIT"
description = "A test project"

[scripts]
start = "go run main.go"

[dependencies]
testdep = { source = "github.com/user/repo/file.lua", path = "libs/testdep.lua" }
`
	projectFilePath := filepath.Join(tempDir, ProjectTomlName)
	err := os.WriteFile(projectFilePath, []byte(validTomlContent), 0644)
	require.NoError(t, err)

	proj, err := LoadProjectToml(tempDir)
	require.NoError(t, err)
	require.NotNil(t, proj)

	assert.Equal(t, "test-project", proj.Package.Name)
	assert.Equal(t, "0.1.0", proj.Package.Version)
	assert.Equal(t, "MIT", proj.Package.License)
	assert.Equal(t, "A test project", proj.Package.Description)
	assert.Equal(t, "go run main.go", proj.Scripts["start"])
	assert.NotNil(t, proj.Dependencies["testdep"])
	assert.Equal(t, "github.com/user/repo/file.lua", proj.Dependencies["testdep"].Source)
	assert.Equal(t, "libs/testdep.lua", proj.Dependencies["testdep"].Path)
}

func TestLoadProjectToml_NotFound(t *testing.T) {
	tempDir := t.TempDir()
	_, err := LoadProjectToml(tempDir)
	assert.Error(t, err)
	assert.True(t, os.IsNotExist(err), "Error should be a 'file not found' type error")
}

func TestLoadProjectToml_InvalidFormat(t *testing.T) {
	tempDir := t.TempDir()
	invalidTomlContent := `
[package
name = "test-project"
version = "0.1.0"
`
	projectFilePath := filepath.Join(tempDir, ProjectTomlName)
	err := os.WriteFile(projectFilePath, []byte(invalidTomlContent), 0644)
	require.NoError(t, err)

	_, err = LoadProjectToml(tempDir)
	assert.Error(t, err)
}

func TestWriteProjectToml_NewFile(t *testing.T) {
	tempDir := t.TempDir()
	projData := &project.Project{
		Package: &project.PackageInfo{
			Name:        "new-project",
			Version:     "1.0.0",
			License:     "Apache-2.0",
			Description: "A brand new project",
		},
		Scripts: map[string]string{
			"build": "go build .",
		},
		Dependencies: map[string]project.Dependency{
			"dep1": {Source: "github.com/org/dep1/mod.lua", Path: "vendor/dep1.lua"},
		},
	}

	err := WriteProjectToml(tempDir, projData)
	require.NoError(t, err)

	loadedProj, err := LoadProjectToml(tempDir)
	require.NoError(t, err)
	require.NotNil(t, loadedProj)

	assert.Equal(t, "new-project", loadedProj.Package.Name)
	assert.Equal(t, "1.0.0", loadedProj.Package.Version)
	assert.Equal(t, "Apache-2.0", loadedProj.Package.License)
	assert.Equal(t, "A brand new project", loadedProj.Package.Description)
	assert.Equal(t, "go build .", loadedProj.Scripts["build"])
	assert.NotNil(t, loadedProj.Dependencies["dep1"])
	assert.Equal(t, "github.com/org/dep1/mod.lua", loadedProj.Dependencies["dep1"].Source)
	assert.Equal(t, "vendor/dep1.lua", loadedProj.Dependencies["dep1"].Path)
}

func TestWriteProjectToml_OverwriteFile(t *testing.T) {
	tempDir := t.TempDir()
	initialTomlContent := `
[package]
name = "old-project"
version = "0.0.1"
`
	projectFilePath := filepath.Join(tempDir, ProjectTomlName)
	err := os.WriteFile(projectFilePath, []byte(initialTomlContent), 0644)
	require.NoError(t, err)

	projData := &project.Project{
		Package: &project.PackageInfo{
			Name:    "updated-project",
			Version: "2.0.0",
		},
	}

	err = WriteProjectToml(tempDir, projData)
	require.NoError(t, err)

	loadedProj, err := LoadProjectToml(tempDir)
	require.NoError(t, err)
	require.NotNil(t, loadedProj)

	assert.Equal(t, "updated-project", loadedProj.Package.Name)
	assert.Equal(t, "2.0.0", loadedProj.Package.Version)
	assert.Nil(t, loadedProj.Scripts)
	assert.Nil(t, loadedProj.Dependencies)
}



================================================
File: internal/core/downloader/downloader.go
================================================
// Package downloader provides functionality to download files from URLs.
package downloader

import (
	"fmt"
	"io"
	"net/http"
)

// DownloadFile fetches the content from the given URL.
// It returns the content as a byte slice or an error if the download fails
// or if the HTTP status code is not 200 OK.
func DownloadFile(url string) ([]byte, error) {
	resp, err := http.Get(url)
	if err != nil {
		return nil, fmt.Errorf("failed to perform GET request to %s: %w", url, err)
	}
	defer func() { _ = resp.Body.Close() }()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("failed to download from %s: received status code %d", url, resp.StatusCode)
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response body from %s: %w", url, err)
	}

	return body, nil
}



================================================
File: internal/core/downloader/downloader_test.go
================================================
// Package downloader_test contains tests for the downloader package.
package downloader_test

import (
	"fmt"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"github.com/nightconcept/almandine/internal/core/downloader"
)

func TestDownloadFile_Success(t *testing.T) {
	t.Parallel()
	expectedContent := "Hello, Almandine!"
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
		_, err := w.Write([]byte(expectedContent))
		require.NoError(t, err, "Failed to write response in mock server")
	}))
	defer server.Close()

	content, err := downloader.DownloadFile(server.URL)
	require.NoError(t, err, "DownloadFile returned an unexpected error")
	assert.Equal(t, []byte(expectedContent), content, "Downloaded content does not match expected content")
}

func TestDownloadFile_HTTPErrorNotFound(t *testing.T) {
	t.Parallel()
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusNotFound)
	}))
	defer server.Close()

	_, err := downloader.DownloadFile(server.URL)
	require.Error(t, err, "DownloadFile should have returned an error for 404")
	assert.Contains(t, err.Error(), "failed to download from", "Error message mismatch")
	assert.Contains(t, err.Error(), "received status code 404", "Error message mismatch for status code")
}

func TestDownloadFile_HTTPErrorInternalServer(t *testing.T) {
	t.Parallel()
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusInternalServerError)
	}))
	defer server.Close()

	_, err := downloader.DownloadFile(server.URL)
	require.Error(t, err, "DownloadFile should have returned an error for 500")
	assert.Contains(t, err.Error(), "failed to download from", "Error message mismatch")
	assert.Contains(t, err.Error(), "received status code 500", "Error message mismatch for status code")
}

func TestDownloadFile_NetworkError_InvalidURL(t *testing.T) {
	t.Parallel()
	invalidURL := "http://invalid-url-that-should-not-exist-for-testing.localdomain"

	_, err := downloader.DownloadFile(invalidURL)
	require.Error(t, err, "DownloadFile should have returned an error for an invalid/unreachable URL")
	assert.Contains(t, err.Error(), fmt.Sprintf("failed to perform GET request to %s", invalidURL), "Error message mismatch for network error")
}

func TestDownloadFile_ReadBodyError(t *testing.T) {
	t.Parallel()
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Length", "100")
		w.WriteHeader(http.StatusOK)
		hj, ok := w.(http.Hijacker)
		if !ok {
			t.Fatal("webserver doesn't support hijacking")
		}
		conn, _, err := hj.Hijack()
		if err != nil {
			t.Fatalf("failed to hijack connection: %v", err)
		}
		_, _ = conn.Write([]byte("HTTP/1.1 200 OK\r\nContent-Length: 100\r\n\r\npartial data"))
		_ = conn.Close()
	}))
	defer server.Close()

	_, err := downloader.DownloadFile(server.URL)
	require.Error(t, err, "DownloadFile should have returned an error when reading the body fails")
	assert.Contains(t, err.Error(), fmt.Sprintf("failed to read response body from %s", server.URL), "Error message mismatch for read body error")
}



================================================
File: internal/core/hasher/hasher.go
================================================
package hasher

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
)

// CalculateSHA256 computes the SHA256 hash of the given content
// and returns it in the format "sha256:<hex_hash>".
func CalculateSHA256(content []byte) (string, error) {
	hasher := sha256.New()
	_, err := hasher.Write(content)
	if err != nil {
		return "", fmt.Errorf("failed to write content to hasher: %w", err)
	}
	hashBytes := hasher.Sum(nil)
	hashString := hex.EncodeToString(hashBytes)
	return fmt.Sprintf("sha256:%s", hashString), nil
}



================================================
File: internal/core/hasher/hasher_test.go
================================================
// Package hasher_test contains tests for the hasher package.
package hasher_test

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"github.com/nightconcept/almandine/internal/core/hasher"
)

func TestCalculateSHA256_KnownString(t *testing.T) {
	t.Parallel()
	content := []byte("Hello, Almandine!")
	expectedHash := "sha256:94115f449b029dd58934f8f40187377d739c16b9e26231fb8478b57774674d27"

	actualHash, err := hasher.CalculateSHA256(content)
	require.NoError(t, err, "CalculateSHA256 returned an unexpected error")
	assert.Equal(t, expectedHash, actualHash, "Calculated hash does not match expected hash")
}

func TestCalculateSHA256_EmptyContent(t *testing.T) {
	t.Parallel()
	content := []byte{}
	expectedHash := "sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"

	actualHash, err := hasher.CalculateSHA256(content)
	require.NoError(t, err, "CalculateSHA256 returned an unexpected error for empty content")
	assert.Equal(t, expectedHash, actualHash, "Calculated hash for empty content does not match expected hash")
}

func TestCalculateSHA256_DifferentContent(t *testing.T) {
	t.Parallel()
	content1 := []byte("almandine-rocks")
	expectedHash1 := "sha256:8685fcd978852c8ec54ea79145a0c6b1cd9f7192729cf452e6e6ef56fabe9182"

	content2 := []byte("almandine-rules")
	expectedHash2 := "sha256:8a1cfdc5f0615a18d7438fe1f103faf06554262178d76ee3d453335502d2cfd1"

	actualHash1, err1 := hasher.CalculateSHA256(content1)
	require.NoError(t, err1)
	assert.Equal(t, expectedHash1, actualHash1)

	actualHash2, err2 := hasher.CalculateSHA256(content2)
	require.NoError(t, err2)
	assert.Equal(t, expectedHash2, actualHash2)

	assert.NotEqual(t, actualHash1, actualHash2, "Hashes for different content should not be the same")
}



================================================
File: internal/core/lockfile/lockfile.go
================================================
package lockfile

import (
	"fmt"
	"os"
	"path/filepath"

	"github.com/BurntSushi/toml"
)

const LockfileName = "almd-lock.toml"
const APIVersion = "1"

// PackageEntry represents a single package entry in the lockfile.
type PackageEntry struct {
	Source string `toml:"source"`
	Path   string `toml:"path"`
	Hash   string `toml:"hash"`
}

// Lockfile represents the structure of the almd-lock.toml file.
type Lockfile struct {
	ApiVersion string                  `toml:"api_version"`
	Package    map[string]PackageEntry `toml:"package"`
}

// New creates a new Lockfile instance with default values.
func New() *Lockfile {
	return &Lockfile{
		ApiVersion: APIVersion,
		Package:    make(map[string]PackageEntry),
	}
}

// Load loads the lockfile from the given project root path.
// If the lockfile doesn't exist, it returns a new Lockfile instance.
func Load(projectRoot string) (*Lockfile, error) {
	lockfilePath := filepath.Join(projectRoot, LockfileName)
	lf := New()

	if _, err := os.Stat(lockfilePath); os.IsNotExist(err) {
		return lf, nil
	} else if err != nil {
		return nil, fmt.Errorf("failed to stat lockfile %s: %w", lockfilePath, err)
	}

	if _, err := toml.DecodeFile(lockfilePath, &lf); err != nil {
		return nil, fmt.Errorf("failed to decode lockfile %s: %w", lockfilePath, err)
	}
	if lf.ApiVersion == "" {
		lf.ApiVersion = APIVersion
	}
	if lf.Package == nil {
		lf.Package = make(map[string]PackageEntry)
	}
	return lf, nil
}

// Save saves the lockfile to the given project root path.
func Save(projectRoot string, lf *Lockfile) error {
	lockfilePath := filepath.Join(projectRoot, LockfileName)
	file, err := os.Create(lockfilePath)
	if err != nil {
		return fmt.Errorf("failed to create/truncate lockfile %s: %w", lockfilePath, err)
	}
	defer func() { _ = file.Close() }()

	encoder := toml.NewEncoder(file)
	if err := encoder.Encode(lf); err != nil {
		return fmt.Errorf("failed to encode lockfile %s: %w", lockfilePath, err)
	}
	return nil
}

// AddOrUpdatePackage adds or updates a package entry in the lockfile.
func (lf *Lockfile) AddOrUpdatePackage(name, rawURL, relativePath, integrityHash string) {
	if lf.Package == nil {
		lf.Package = make(map[string]PackageEntry)
	}
	lf.Package[name] = PackageEntry{
		Source: rawURL,
		Path:   relativePath,
		Hash:   integrityHash,
	}
}



================================================
File: internal/core/lockfile/lockfile_test.go
================================================
// Package lockfile_test contains tests for the lockfile package.
package lockfile_test

import (
	"os"
	"path/filepath"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"github.com/nightconcept/almandine/internal/core/lockfile"
)

func TestNewLockfile(t *testing.T) {
	t.Parallel()
	lf := lockfile.New()
	assert.NotNil(t, lf, "New lockfile should not be nil")
	assert.Equal(t, lockfile.APIVersion, lf.ApiVersion, "API version mismatch")
	assert.NotNil(t, lf.Package, "Packages map should be initialized")
	assert.Empty(t, lf.Package, "Packages map should be empty initially")
}

func TestLoadLockfile_NotFound(t *testing.T) {
	t.Parallel()
	tempDir := t.TempDir()

	lf, err := lockfile.Load(tempDir)
	require.NoError(t, err, "Load should not return error if lockfile not found")
	assert.NotNil(t, lf, "Loaded lockfile should not be nil even if not found")
	assert.Equal(t, lockfile.APIVersion, lf.ApiVersion, "API version mismatch for new lockfile")
	assert.Empty(t, lf.Package, "Packages map should be empty for new lockfile")
}

func TestLoadLockfile_Valid(t *testing.T) {
	t.Parallel()
	tempDir := t.TempDir()
	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)

	content := `
api_version = "1"
[package.mylib]
  source = "http://example.com/mylib.lua"
  path = "libs/mylib.lua"
  hash = "sha256:abcdef123456"
`
	err := os.WriteFile(lockfilePath, []byte(content), 0600)
	require.NoError(t, err, "Failed to write mock lockfile")

	lf, err := lockfile.Load(tempDir)
	require.NoError(t, err, "Load returned an unexpected error for valid lockfile")
	assert.NotNil(t, lf)
	assert.Equal(t, "1", lf.ApiVersion)
	require.Contains(t, lf.Package, "mylib")
	assert.Equal(t, "http://example.com/mylib.lua", lf.Package["mylib"].Source)
	assert.Equal(t, "libs/mylib.lua", lf.Package["mylib"].Path)
	assert.Equal(t, "sha256:abcdef123456", lf.Package["mylib"].Hash)
}

func TestLoadLockfile_InvalidToml(t *testing.T) {
	t.Parallel()
	tempDir := t.TempDir()
	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)

	content := `api_version = "1" this is invalid toml`
	err := os.WriteFile(lockfilePath, []byte(content), 0600)
	require.NoError(t, err, "Failed to write mock invalid lockfile")

	_, err = lockfile.Load(tempDir)
	require.Error(t, err, "Load should return an error for invalid TOML")
	assert.Contains(t, err.Error(), "failed to decode lockfile", "Error message mismatch")
}

func TestLoadLockfile_EmptyFile(t *testing.T) {
	t.Parallel()
	tempDir := t.TempDir()
	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)

	err := os.WriteFile(lockfilePath, []byte(""), 0600)
	require.NoError(t, err, "Failed to write empty mock lockfile")

	lf, err := lockfile.Load(tempDir)
	require.NoError(t, err, "Load should not error on an empty file")
	assert.NotNil(t, lf)
	assert.Equal(t, lockfile.APIVersion, lf.ApiVersion, "API version should default for empty file")
	assert.NotNil(t, lf.Package)
	assert.Empty(t, lf.Package, "Packages should be empty for empty file")
}

func TestLoadLockfile_MissingApiVersion(t *testing.T) {
	t.Parallel()
	tempDir := t.TempDir()
	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)
	content := `
[package.mylib]
  source = "http://example.com/mylib.lua"
  path = "libs/mylib.lua"
  hash = "sha256:abcdef123456"
`
	err := os.WriteFile(lockfilePath, []byte(content), 0600)
	require.NoError(t, err, "Failed to write mock lockfile without api_version")

	lf, err := lockfile.Load(tempDir)
	require.NoError(t, err, "Load should not error if api_version is missing")
	assert.Equal(t, lockfile.APIVersion, lf.ApiVersion, "API version should default if missing")
	require.Contains(t, lf.Package, "mylib")
}

func TestSaveLockfile_New(t *testing.T) {
	t.Parallel()
	tempDir := t.TempDir()
	lf := lockfile.New()
	lf.Package["dep1"] = lockfile.PackageEntry{
		Source: "http://example.com/dep1.zip",
		Path:   "vendor/dep1",
		Hash:   "sha256:123",
	}

	err := lockfile.Save(tempDir, lf)
	require.NoError(t, err, "Save returned an unexpected error")

	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)
	_, err = os.Stat(lockfilePath)
	require.NoError(t, err, "Lockfile was not created")

	loadedLf, err := lockfile.Load(tempDir)
	require.NoError(t, err, "Failed to load saved lockfile")
	assert.Equal(t, lf, loadedLf, "Saved and loaded lockfiles do not match")
}

func TestSaveLockfile_Overwrite(t *testing.T) {
	t.Parallel()
	tempDir := t.TempDir()
	lockfilePath := filepath.Join(tempDir, lockfile.LockfileName)

	initialContent := `api_version = "0.5"`
	err := os.WriteFile(lockfilePath, []byte(initialContent), 0600)
	require.NoError(t, err, "Failed to write initial mock lockfile")

	lfToSave := lockfile.New()
	lfToSave.Package["newdep"] = lockfile.PackageEntry{
		Source: "http://example.com/newdep.tar.gz",
		Path:   "deps/newdep",
		Hash:   "sha256:abc",
	}

	err = lockfile.Save(tempDir, lfToSave)
	require.NoError(t, err, "Save returned an unexpected error when overwriting")

	loadedLf, err := lockfile.Load(tempDir)
	require.NoError(t, err, "Failed to load overwritten lockfile")
	assert.Equal(t, lfToSave.ApiVersion, loadedLf.ApiVersion)
	assert.Equal(t, lfToSave.Package["newdep"], loadedLf.Package["newdep"])
}

func TestAddOrUpdatePackage(t *testing.T) {
	t.Parallel()
	lf := lockfile.New()

	lf.AddOrUpdatePackage("libA", "urlA", "pathA", "hashA")
	require.Contains(t, lf.Package, "libA")
	assert.Equal(t, "urlA", lf.Package["libA"].Source)
	assert.Equal(t, "pathA", lf.Package["libA"].Path)
	assert.Equal(t, "hashA", lf.Package["libA"].Hash)

	lf.AddOrUpdatePackage("libA", "urlA_updated", "pathA_updated", "hashA_updated")
	require.Contains(t, lf.Package, "libA")
	assert.Equal(t, "urlA_updated", lf.Package["libA"].Source)
	assert.Equal(t, "pathA_updated", lf.Package["libA"].Path)
	assert.Equal(t, "hashA_updated", lf.Package["libA"].Hash)

	lf.AddOrUpdatePackage("libB", "urlB", "pathB", "hashB")
	require.Contains(t, lf.Package, "libB")
	assert.Equal(t, "urlB", lf.Package["libB"].Source)
	assert.Len(t, lf.Package, 2, "Incorrect number of packages after adding multiple")
}

func TestAddOrUpdatePackage_NilMap(t *testing.T) {
	t.Parallel()
	lf := &lockfile.Lockfile{ApiVersion: "1", Package: nil}

	lf.AddOrUpdatePackage("libC", "urlC", "pathC", "hashC")
	require.NotNil(t, lf.Package, "Package map should be initialized by AddOrUpdatePackage")
	require.Contains(t, lf.Package, "libC")
	assert.Equal(t, "urlC", lf.Package["libC"].Source)
}



================================================
File: internal/core/project/project.go
================================================
package project

// Project represents the overall structure of the project.toml file.
type Project struct {
	Package      *PackageInfo          `toml:"package"`
	Scripts      map[string]string     `toml:"scripts,omitempty"`
	Dependencies map[string]Dependency `toml:"dependencies,omitempty"`
}

// PackageInfo holds metadata for the project.
type PackageInfo struct {
	Name        string `toml:"name"`
	Version     string `toml:"version"`
	License     string `toml:"license,omitempty"`
	Description string `toml:"description,omitempty"`
}

// Dependency represents a single dependency in the project.toml file.
type Dependency struct {
	Source string `toml:"source"`
	Path   string `toml:"path"`
}

// LockFile represents the structure of the almd-lock.toml file.
type LockFile struct {
	APIVersion string                       `toml:"api_version"`
	Package    map[string]LockPackageDetail `toml:"package"`
}

// LockPackageDetail represents a single package entry in the almd-lock.toml file.
type LockPackageDetail struct {
	Source string `toml:"source"`
	Path   string `toml:"path"`
	Hash   string `toml:"hash"`
}

// NewProject creates and returns a new Project instance with initialized maps.
func NewProject() *Project {
	return &Project{
		Package:      &PackageInfo{},
		Scripts:      make(map[string]string),
		Dependencies: make(map[string]Dependency),
	}
}



================================================
File: internal/core/project/project_test.go
================================================
// Package project_test contains tests for the project package.
package project_test

import (
	"testing"

	"github.com/stretchr/testify/assert"

	"github.com/nightconcept/almandine/internal/core/project"
)

func TestNewProject(t *testing.T) {
	t.Parallel()
	p := project.NewProject()

	assert.NotNil(t, p, "NewProject should return a non-nil Project instance")
	assert.NotNil(t, p.Package, "Project.Package should be initialized")
	assert.NotNil(t, p.Scripts, "Project.Scripts map should be initialized")
	assert.Empty(t, p.Scripts, "Project.Scripts map should be empty initially")
	assert.NotNil(t, p.Dependencies, "Project.Dependencies map should be initialized")
	assert.Empty(t, p.Dependencies, "Project.Dependencies map should be empty initially")

	assert.Equal(t, "", p.Package.Name, "Package.Name should be empty initially")
	assert.Equal(t, "", p.Package.Version, "Package.Version should be empty initially")
	assert.Equal(t, "", p.Package.License, "Package.License should be empty initially")
	assert.Equal(t, "", p.Package.Description, "Package.Description should be empty initially")
}



================================================
File: internal/core/source/github_api.go
================================================
package source

import (
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sync"
	"time"
)

// GithubAPIBaseURL allows overriding for tests. It is an exported variable.
var GithubAPIBaseURL = "https://api.github.com"
var GithubAPIBaseURLMutex sync.Mutex // Mutex for GithubAPIBaseURL (Exported)

// GitHubCommitInfo minimal structure to parse the commit SHA.
type GitHubCommitInfo struct {
	SHA    string `json:"sha"`
	Commit struct {
		Committer struct {
			Date time.Time `json:"date"`
		} `json:"committer"`
	} `json:"commit"`
	// We only need the SHA, but including date for potential future use/sorting.
}

// GetLatestCommitSHAForFile fetches the latest commit SHA for a specific file on a given branch/ref from GitHub.
// owner: repository owner
// repo: repository name
// pathInRepo: path to the file within the repository
// ref: branch name, tag name, or commit SHA
func GetLatestCommitSHAForFile(owner, repo, pathInRepo, ref string) (string, error) {
	// See: https://docs.github.com/en/rest/commits/commits#list-commits
	// We ask for commits for a specific file on a specific branch/ref. The first result is the latest.
	GithubAPIBaseURLMutex.Lock()
	currentGithubAPIBaseURL := GithubAPIBaseURL
	GithubAPIBaseURLMutex.Unlock()
	apiURL := fmt.Sprintf("%s/repos/%s/%s/commits?path=%s&sha=%s&per_page=1", currentGithubAPIBaseURL, owner, repo, pathInRepo, ref)

	httpClient := &http.Client{Timeout: 10 * time.Second}
	req, err := http.NewRequest("GET", apiURL, nil)
	if err != nil {
		return "", fmt.Errorf("failed to create request to GitHub API: %w", err)
	}
	// GitHub API recommends setting an Accept header.
	req.Header.Set("Accept", "application/vnd.github.v3+json")
	// TODO: Consider adding a User-Agent header (e.g., "almandine-cli") for more robust GitHub API requests.

	resp, err := httpClient.Do(req)
	if err != nil {
		return "", fmt.Errorf("failed to call GitHub API (%s): %w", apiURL, err)
	}
	defer func() { _ = resp.Body.Close() }()

	if resp.StatusCode != http.StatusOK {
		bodyBytes, _ := io.ReadAll(resp.Body)
		return "", fmt.Errorf("GitHub API request failed with status %s (%s): %s", resp.Status, apiURL, string(bodyBytes))
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("failed to read response body from GitHub API (%s): %w", apiURL, err)
	}

	var commits []GitHubCommitInfo
	if err := json.Unmarshal(body, &commits); err != nil {
		return "", fmt.Errorf("failed to unmarshal GitHub API response (%s): %w. Body: %s", apiURL, err, string(body))
	}

	if len(commits) == 0 {
		// This can happen if the path is incorrect for the given ref, or the ref itself doesn't exist.
		// Or if the ref *is* a commit SHA, and the file wasn't modified in that specific commit (the API returns history).
		// If ref is already a SHA, we should ideally use it directly. This function assumes ref might be a branch.
		// If no commits are returned for a file on a branch, it implies the file might not exist on that branch or path is wrong.
		return "", fmt.Errorf("no commits found for path '%s' at ref '%s' in repo '%s/%s'. The file might not exist at this path/ref, or the ref might be a specific commit SHA where this file was not modified", pathInRepo, ref, owner, repo)
	}

	return commits[0].SHA, nil
}



================================================
File: internal/core/source/github_api_test.go
================================================
// Package source_test contains tests for the source package, specifically GitHub API interactions.
package source_test

import (
	"encoding/json"
	"fmt"
	"net/http"
	"net/http/httptest"
	"sync"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"github.com/nightconcept/almandine/internal/core/source"
)

var githubAPITestMutex sync.Mutex // Mutex to serialize tests modifying global source state

func TestGetLatestCommitSHAForFile_Success(t *testing.T) {
	githubAPITestMutex.Lock()
	defer githubAPITestMutex.Unlock()

	expectedSHA := "abcdef1234567890"
	mockResponse := []source.GitHubCommitInfo{
		{SHA: expectedSHA},
		{SHA: "oldersha789"},
	}
	responseBody, err := json.Marshal(mockResponse)
	require.NoError(t, err)

	_, cleanup := setupSourceTest(t, func(w http.ResponseWriter, r *http.Request) {
		assert.Equal(t, "/repos/owner/repo/commits", r.URL.Path, "Request path mismatch")
		assert.Equal(t, "path/to/file.txt", r.URL.Query().Get("path"), "Query param 'path' mismatch")
		assert.Equal(t, "main", r.URL.Query().Get("sha"), "Query param 'sha' mismatch")
		assert.Equal(t, "1", r.URL.Query().Get("per_page"), "Query param 'per_page' mismatch")
		w.Header().Set("Content-Type", "application/json")
		w.WriteHeader(http.StatusOK)
		_, _ = w.Write(responseBody)
	})
	defer cleanup()

	sha, err := source.GetLatestCommitSHAForFile("owner", "repo", "path/to/file.txt", "main")
	require.NoError(t, err)
	assert.Equal(t, expectedSHA, sha)
}

func TestGetLatestCommitSHAForFile_EmptyResponse(t *testing.T) {
	githubAPITestMutex.Lock()
	defer githubAPITestMutex.Unlock()

	mockResponse := []source.GitHubCommitInfo{}
	responseBody, err := json.Marshal(mockResponse)
	require.NoError(t, err)

	_, cleanup := setupSourceTest(t, func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Type", "application/json")
		w.WriteHeader(http.StatusOK)
		_, _ = w.Write(responseBody)
	})
	defer cleanup()

	_, err = source.GetLatestCommitSHAForFile("owner", "repo", "nonexistent/file.txt", "main")
	require.Error(t, err)
	assert.Contains(t, err.Error(), "no commits found for path")
}

func TestGetLatestCommitSHAForFile_GitHubAPIError(t *testing.T) {
	githubAPITestMutex.Lock()
	defer githubAPITestMutex.Unlock()

	_, cleanup := setupSourceTest(t, func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Type", "application/json")
		w.WriteHeader(http.StatusNotFound)
		_, _ = w.Write([]byte(`{"message": "Not Found"}`))
	})
	defer cleanup()

	_, err := source.GetLatestCommitSHAForFile("owner", "repo", "file.txt", "main")
	require.Error(t, err)
	assert.Contains(t, err.Error(), "GitHub API request failed with status 404 Not Found")
}

func TestGetLatestCommitSHAForFile_MalformedJSONResponse(t *testing.T) {
	githubAPITestMutex.Lock()
	defer githubAPITestMutex.Unlock()

	_, cleanup := setupSourceTest(t, func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Type", "application/json")
		w.WriteHeader(http.StatusOK)
		_, _ = w.Write([]byte(`this is not valid json`))
	})
	defer cleanup()

	_, err := source.GetLatestCommitSHAForFile("owner", "repo", "file.txt", "main")
	require.Error(t, err)
	assert.Contains(t, err.Error(), "failed to unmarshal GitHub API response")
}

func TestGetLatestCommitSHAForFile_NetworkError(t *testing.T) {
	githubAPITestMutex.Lock()
	defer githubAPITestMutex.Unlock()

	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		hj, ok := w.(http.Hijacker)
		if !ok {
			http.Error(w, "webserver doesn't support hijacking", http.StatusInternalServerError)
			return
		}
		conn, _, err := hj.Hijack()
		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
		_ = conn.Close()
	}))
	// No defer server.Close() here as we close it within the test logic for this specific case.

	source.GithubAPIBaseURLMutex.Lock()
	originalAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = server.URL
	source.GithubAPIBaseURLMutex.Unlock()
	source.SetTestModeBypassHostValidation(true) // This function handles its own locking

	server.Close()

	_, err := source.GetLatestCommitSHAForFile("owner", "repo", "file.txt", "main")

	source.GithubAPIBaseURLMutex.Lock()
	source.GithubAPIBaseURL = originalAPIBaseURL
	source.GithubAPIBaseURLMutex.Unlock()
	source.SetTestModeBypassHostValidation(false) // This function handles its own locking

	require.Error(t, err)
	assert.Contains(t, err.Error(), "failed to call GitHub API")
}

// MockGitHubCommit is a helper to create GitHubCommitInfo for tests
func MockGitHubCommit(sha string, date time.Time) source.GitHubCommitInfo {
	return source.GitHubCommitInfo{
		SHA: sha,
		Commit: struct {
			Committer struct {
				Date time.Time `json:"date"`
			} `json:"committer"`
		}{
			Committer: struct {
				Date time.Time `json:"date"`
			}{
				Date: date,
			},
		},
	}
}

func TestGetLatestCommitSHAForFile_UsesCorrectURLParameters(t *testing.T) {
	githubAPITestMutex.Lock()
	defer githubAPITestMutex.Unlock()

	owner, repo, pathInRepo, ref := "test-owner", "test-repo", "src/main.go", "develop"
	expectedSHA := "commitsha123"

	mockResponse := []source.GitHubCommitInfo{MockGitHubCommit(expectedSHA, time.Now())}
	responseBody, _ := json.Marshal(mockResponse)

	_, cleanup := setupSourceTest(t, func(w http.ResponseWriter, r *http.Request) {
		expectedPath := fmt.Sprintf("/repos/%s/%s/commits", owner, repo)
		assert.Equal(t, expectedPath, r.URL.Path)
		assert.Equal(t, pathInRepo, r.URL.Query().Get("path"))
		assert.Equal(t, ref, r.URL.Query().Get("sha"))
		assert.Equal(t, "1", r.URL.Query().Get("per_page"))
		w.WriteHeader(http.StatusOK)
		_, _ = w.Write(responseBody)
	})
	defer cleanup()

	sha, err := source.GetLatestCommitSHAForFile(owner, repo, pathInRepo, ref)
	require.NoError(t, err)
	assert.Equal(t, expectedSHA, sha)
}



================================================
File: internal/core/source/source.go
================================================
package source

import (
	"fmt"
	"net/url"
	"strings"
	"sync"
)

// testModeBypassHostValidation is an internal flag for testing to bypass hostname checks.
// WARNING: This should only be set to true in test environments.
var testModeBypassHostValidation = false
var TestModeBypassHostValidationMutex sync.Mutex // Mutex for testModeBypassHostValidation (Exported)

// SetTestModeBypassHostValidation enables or disables the hostname validation bypass for testing.
// This function is intended to be called only from test packages.
func SetTestModeBypassHostValidation(enable bool) {
	TestModeBypassHostValidationMutex.Lock()
	testModeBypassHostValidation = enable
	TestModeBypassHostValidationMutex.Unlock()
}

// ParsedSourceInfo holds the details extracted from a source URL.
type ParsedSourceInfo struct {
	RawURL            string
	CanonicalURL      string
	Ref               string
	Provider          string
	Owner             string
	Repo              string
	PathInRepo        string
	SuggestedFilename string
}

// ParseSourceURL analyzes the input source URL string and returns structured information.
// It currently prioritizes GitHub URLs.
func ParseSourceURL(sourceURL string) (*ParsedSourceInfo, error) {
	if strings.HasPrefix(sourceURL, "github:") {
		return parseGitHubShorthandURL(sourceURL)
	}

	u, err := url.Parse(sourceURL)
	if err != nil {
		return nil, fmt.Errorf("failed to parse source URL '%s': %w", sourceURL, err)
	}

	TestModeBypassHostValidationMutex.Lock()
	currentTestModeBypass := testModeBypassHostValidation
	TestModeBypassHostValidationMutex.Unlock()

	if currentTestModeBypass {
		// If test mode bypass is active, attempt to parse it as a test mode URL.
		// This function will error if the path doesn't match the expected test structure.
		return parseTestModeURL(u)
	}

	// Standard URL parsing
	hostname := strings.ToLower(u.Hostname())
	switch hostname {
	case "raw.githubusercontent.com":
		return parseRawGitHubUserContentURL(u)
	case "github.com":
		return parseGitHubFullURL(u)
	default:
		return nil, fmt.Errorf("unsupported source URL host: %s. Only GitHub URLs are currently supported", u.Hostname())
	}
}

// parseGitHubShorthandURL handles URLs like "github:owner/repo/path/to/file@ref"
func parseGitHubShorthandURL(sourceURL string) (*ParsedSourceInfo, error) {
	content := strings.TrimPrefix(sourceURL, "github:")

	lastAt := strings.LastIndex(content, "@")
	if lastAt == -1 {
		return nil, fmt.Errorf("invalid github shorthand source '%s': missing @ref (e.g., @main or @commitsha)", sourceURL)
	}
	if lastAt == len(content)-1 {
		return nil, fmt.Errorf("invalid github shorthand source '%s': ref part is empty after @", sourceURL)
	}

	repoAndPathPart := content[:lastAt]
	ref := content[lastAt+1:]

	pathComponents := strings.Split(repoAndPathPart, "/")
	if len(pathComponents) < 3 {
		return nil, fmt.Errorf("invalid github shorthand source '%s': expected format owner/repo/path/to/file, got '%s'", sourceURL, repoAndPathPart)
	}

	owner := pathComponents[0]
	repo := pathComponents[1]
	pathInRepo := strings.Join(pathComponents[2:], "/")
	suggestedFilename := pathComponents[len(pathComponents)-1]

	if owner == "" || repo == "" || pathInRepo == "" || suggestedFilename == "" {
		return nil, fmt.Errorf("invalid github shorthand source '%s': owner, repo, or path/filename cannot be empty", sourceURL)
	}

	var rawURL string
	TestModeBypassHostValidationMutex.Lock()
	currentTestModeBypassLocal := testModeBypassHostValidation // Use a local var to avoid holding lock too long
	TestModeBypassHostValidationMutex.Unlock()

	if currentTestModeBypassLocal {
		GithubAPIBaseURLMutex.Lock()
		currentGithubAPIBaseURL := GithubAPIBaseURL
		GithubAPIBaseURLMutex.Unlock()
		rawURL = fmt.Sprintf("%s/%s/%s/%s/%s", currentGithubAPIBaseURL, owner, repo, ref, pathInRepo)
	} else {
		rawURL = fmt.Sprintf("https://raw.githubusercontent.com/%s/%s/%s/%s", owner, repo, ref, pathInRepo)
	}

	return &ParsedSourceInfo{
		RawURL:            rawURL,
		CanonicalURL:      sourceURL, // For shorthand, the sourceURL is the canonical form
		Ref:               ref,
		Provider:          "github",
		Owner:             owner,
		Repo:              repo,
		PathInRepo:        pathInRepo,
		SuggestedFilename: suggestedFilename,
	}, nil
}

// parseTestModeURL handles generic URLs when testModeBypassHostValidation is true,
// attempting to parse them with a GitHub-like raw content path structure.
func parseTestModeURL(u *url.URL) (*ParsedSourceInfo, error) {
	// Path structure expected: /<owner>/<repo>/<ref>/<path_to_file...>
	pathParts := strings.Split(strings.Trim(u.Path, "/"), "/")
	if len(pathParts) < 4 {
		return nil, fmt.Errorf("test mode URL path '%s' not in expected format /<owner>/<repo>/<ref>/<file...> PpathParts was: %v", u.Path, pathParts)
	}

	owner := pathParts[0]
	repo := pathParts[1]
	ref := pathParts[2]
	filePathInRepo := strings.Join(pathParts[3:], "/")
	filename := pathParts[len(pathParts)-1]

	if filename == "" && filePathInRepo == "" {
		return nil, fmt.Errorf("test mode URL path '%s' seems to point to a directory, not a file", u.Path)
	}
	if filename == "" && len(pathParts) == 4 { // e.g. /owner/repo/ref/file
		filename = pathParts[3]
	}

	return &ParsedSourceInfo{
		RawURL:            u.String(), // The original URL is the raw URL in this test mode context
		CanonicalURL:      fmt.Sprintf("github:%s/%s/%s@%s", owner, repo, filePathInRepo, ref),
		Ref:               ref,
		Provider:          "github", // Assumed GitHub provider in test mode parsing
		Owner:             owner,
		Repo:              repo,
		PathInRepo:        filePathInRepo,
		SuggestedFilename: filename,
	}, nil
}

// parseRawGitHubUserContentURL handles URLs from "raw.githubusercontent.com".
func parseRawGitHubUserContentURL(u *url.URL) (*ParsedSourceInfo, error) {
	pathParts := strings.Split(strings.Trim(u.Path, "/"), "/")
	if len(pathParts) < 4 {
		return nil, fmt.Errorf("invalid GitHub raw content URL path: %s. Expected format: /<owner>/<repo>/<ref>/<path_to_file>", u.Path)
	}
	owner := pathParts[0]
	repo := pathParts[1]
	ref := pathParts[2]
	filePathInRepo := strings.Join(pathParts[3:], "/")
	filename := pathParts[len(pathParts)-1]

	if owner == "" || repo == "" || ref == "" || filePathInRepo == "" || filename == "" {
		return nil, fmt.Errorf("invalid GitHub raw content URL '%s': one or more components (owner, repo, ref, path, filename) are empty", u.String())
	}

	canonicalURL := fmt.Sprintf("github:%s/%s/%s@%s", owner, repo, filePathInRepo, ref)
	return &ParsedSourceInfo{
		RawURL:            u.String(),
		CanonicalURL:      canonicalURL,
		Ref:               ref,
		Provider:          "github",
		Owner:             owner,
		Repo:              repo,
		PathInRepo:        filePathInRepo,
		SuggestedFilename: filename,
	}, nil
}

// parseGitHubFullURL handles standard "github.com" URLs (blob, tree, raw, or path with @ref).
func parseGitHubFullURL(u *url.URL) (*ParsedSourceInfo, error) {
	pathParts := strings.Split(strings.Trim(u.Path, "/"), "/")
	if len(pathParts) < 2 {
		return nil, fmt.Errorf("invalid GitHub URL path: %s. Expected at least /<owner>/<repo>", u.Path)
	}

	owner := pathParts[0]
	repo := pathParts[1]
	var ref, filePathInRepo, rawURL, filename string

	if len(pathParts) >= 4 && (pathParts[2] == "blob" || pathParts[2] == "tree" || pathParts[2] == "raw") {
		// Handles /<owner>/<repo>/<type>/<ref>/<path_to_file>
		if len(pathParts) < 5 {
			return nil, fmt.Errorf("incomplete GitHub URL path: %s. Expected /<owner>/<repo>/<type>/<ref>/<path_to_file>", u.Path)
		}
		refType := pathParts[2]
		ref = pathParts[3]
		filePathInRepo = strings.Join(pathParts[4:], "/")
		filename = pathParts[len(pathParts)-1]

		if refType == "tree" {
			return nil, fmt.Errorf("direct links to GitHub trees are not supported for adding single files: %s", u.String())
		}
		if owner == "" || repo == "" || ref == "" || filePathInRepo == "" || filename == "" {
			return nil, fmt.Errorf("invalid GitHub '%s' URL '%s': one or more components (owner, repo, ref, path, filename) are empty", refType, u.String())
		}
		rawURL = fmt.Sprintf("https://raw.githubusercontent.com/%s/%s/%s/%s", owner, repo, ref, filePathInRepo)
	} else {
		// Handles /<owner>/<repo>/<path_to_file>@<ref>
		if len(pathParts) < 3 { // Need at least owner/repo/fileish@ref
			return nil, fmt.Errorf("ambiguous GitHub URL path: %s. Expected /owner/repo/path@ref or a full /blob/ or /raw/ URL", u.Path)
		}
		potentialPathWithRef := strings.Join(pathParts[2:], "/")
		atSymbolIndex := strings.LastIndex(potentialPathWithRef, "@")

		if atSymbolIndex != -1 && atSymbolIndex < len(potentialPathWithRef)-1 && atSymbolIndex > 0 {
			filePathInRepo = potentialPathWithRef[:atSymbolIndex]
			ref = potentialPathWithRef[atSymbolIndex+1:]
			pathElements := strings.Split(filePathInRepo, "/")
			if len(pathElements) > 0 {
				filename = pathElements[len(pathElements)-1]
			} else { // Should not happen if atSymbolIndex > 0
				return nil, fmt.Errorf("could not determine filename from path '%s' in URL '%s'", filePathInRepo, u.String())
			}
		} else {
			return nil, fmt.Errorf("ambiguous GitHub URL: %s. Specify a branch/tag/commit via '@' (e.g., file.txt@main) or use a full /blob/ or /raw/ URL", u.String())
		}

		if owner == "" || repo == "" || ref == "" || filePathInRepo == "" || filename == "" {
			return nil, fmt.Errorf("invalid GitHub URL with '@ref' syntax '%s': one or more components (owner, repo, ref, path, filename) are empty", u.String())
		}
		rawURL = fmt.Sprintf("https://raw.githubusercontent.com/%s/%s/%s/%s", owner, repo, ref, filePathInRepo)
	}

	if filePathInRepo == "" { // Should be caught by earlier checks
		return nil, fmt.Errorf("file path in repository could not be determined from URL: %s", u.String())
	}
	if ref == "" { // Should be caught by earlier checks
		return nil, fmt.Errorf("ref (branch, tag, commit) could not be determined from URL: %s. Please specify it", u.String())
	}
	if filename == "" {
		return nil, fmt.Errorf("filename could not be determined from URL: %s", u.String())
	}

	canonicalURL := fmt.Sprintf("github:%s/%s/%s@%s", owner, repo, filePathInRepo, ref)

	return &ParsedSourceInfo{
		RawURL:            rawURL,
		CanonicalURL:      canonicalURL,
		Ref:               ref,
		Provider:          "github",
		Owner:             owner,
		Repo:              repo,
		PathInRepo:        filePathInRepo,
		SuggestedFilename: filename,
	}, nil
}



================================================
File: internal/core/source/source_test.go
================================================
// Package source_test contains tests for the source package.
package source_test

import (
	"fmt"
	"net/http"
	"net/http/httptest"
	"strings"
	"sync"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"github.com/nightconcept/almandine/internal/core/source"
)

// Global mutex to synchronize all tests that modify global state in source package
var sourceTestMutex sync.Mutex

// setupSourceTest sets up a mock server and configures the source package for testing.
// It returns the mock server's URL and a cleanup function.
func setupSourceTest(t *testing.T, handler http.HandlerFunc) (string, func()) {
	t.Helper()
	server := httptest.NewServer(handler)
	source.GithubAPIBaseURLMutex.Lock()
	originalAPIBaseURL := source.GithubAPIBaseURL
	source.GithubAPIBaseURL = server.URL
	source.GithubAPIBaseURLMutex.Unlock()

	source.SetTestModeBypassHostValidation(true) // This function handles its own locking

	cleanup := func() {
		server.Close()
		source.GithubAPIBaseURLMutex.Lock()
		source.GithubAPIBaseURL = originalAPIBaseURL
		source.GithubAPIBaseURLMutex.Unlock()

		source.SetTestModeBypassHostValidation(false) // This function handles its own locking
	}
	return server.URL, cleanup
}

func TestParseSourceURL_GitHubShorthand(t *testing.T) {
	sourceTestMutex.Lock()
	defer sourceTestMutex.Unlock()

	tests := []struct {
		name          string
		url           string
		mockServerURL string
		want          *source.ParsedSourceInfo
		wantErr       bool
		errContains   string
	}{
		{
			name: "valid shorthand main branch",
			url:  "github:owner/repo/path/to/file.txt@main",
			want: &source.ParsedSourceInfo{
				RawURL:            "https://raw.githubusercontent.com/owner/repo/main/path/to/file.txt",
				CanonicalURL:      "github:owner/repo/path/to/file.txt@main",
				Ref:               "main",
				Provider:          "github",
				Owner:             "owner",
				Repo:              "repo",
				PathInRepo:        "path/to/file.txt",
				SuggestedFilename: "file.txt",
			},
		},
		{
			name: "valid shorthand commit sha",
			url:  "github:owner/repo/file.lua@abcdef1234567890",
			want: &source.ParsedSourceInfo{
				RawURL:            "https://raw.githubusercontent.com/owner/repo/abcdef1234567890/file.lua",
				CanonicalURL:      "github:owner/repo/file.lua@abcdef1234567890",
				Ref:               "abcdef1234567890",
				Provider:          "github",
				Owner:             "owner",
				Repo:              "repo",
				PathInRepo:        "file.lua",
				SuggestedFilename: "file.lua",
			},
		},
		{
			name:        "invalid shorthand missing @ref",
			url:         "github:owner/repo/path/to/file.txt",
			wantErr:     true,
			errContains: "missing @ref",
		},
		{
			name:        "invalid shorthand empty ref",
			url:         "github:owner/repo/path/to/file.txt@",
			wantErr:     true,
			errContains: "ref part is empty after @",
		},
		{
			name:        "invalid shorthand not enough path components",
			url:         "github:owner/repo@main",
			wantErr:     true,
			errContains: "expected format owner/repo/path/to/file",
		},
		{
			name:        "invalid shorthand empty owner",
			url:         "github:/repo/file.txt@main",
			wantErr:     true,
			errContains: "owner, repo, or path/filename cannot be empty",
		},
		{
			name: "valid shorthand with test mode bypass for raw URL",
			url:  "github:testowner/testrepo/test/file.sh@testref",
			want: &source.ParsedSourceInfo{
				CanonicalURL:      "github:testowner/testrepo/test/file.sh@testref",
				Ref:               "testref",
				Provider:          "github",
				Owner:             "testowner",
				Repo:              "testrepo",
				PathInRepo:        "test/file.sh",
				SuggestedFilename: "file.sh",
			},
		},
	}

	for _, tt := range tests {
		tt := tt // capture range variable
		t.Run(tt.name, func(t *testing.T) {
			var mockURL string
			var cleanup func()

			if strings.Contains(tt.name, "test mode bypass") {
				mockURL, cleanup = setupSourceTest(t, func(w http.ResponseWriter, r *http.Request) {
					w.WriteHeader(http.StatusOK)
				})
				defer cleanup()
				tt.want.RawURL = fmt.Sprintf("%s/testowner/testrepo/testref/test/file.sh", mockURL)
			}

			got, err := source.ParseSourceURL(tt.url)

			if tt.wantErr {
				require.Error(t, err)
				if tt.errContains != "" {
					assert.Contains(t, err.Error(), tt.errContains)
				}
			} else {
				require.NoError(t, err)
				assert.Equal(t, tt.want, got)
			}
		})
	}
}

func TestParseSourceURL_FullGitHubURLs(t *testing.T) {
	sourceTestMutex.Lock()
	defer sourceTestMutex.Unlock()

	tests := []struct {
		name        string
		url         string
		want        *source.ParsedSourceInfo
		wantErr     bool
		errContains string
	}{
		{
			name: "github.com blob url",
			url:  "https://github.com/owner/repo/blob/main/path/to/script.sh",
			want: &source.ParsedSourceInfo{
				RawURL:            "https://raw.githubusercontent.com/owner/repo/main/path/to/script.sh",
				CanonicalURL:      "github:owner/repo/path/to/script.sh@main",
				Ref:               "main",
				Provider:          "github",
				Owner:             "owner",
				Repo:              "repo",
				PathInRepo:        "path/to/script.sh",
				SuggestedFilename: "script.sh",
			},
		},
		{
			name: "github.com raw url",
			url:  "https://github.com/owner/repo/raw/develop/another/file.lua",
			want: &source.ParsedSourceInfo{
				RawURL:            "https://raw.githubusercontent.com/owner/repo/develop/another/file.lua",
				CanonicalURL:      "github:owner/repo/another/file.lua@develop",
				Ref:               "develop",
				Provider:          "github",
				Owner:             "owner",
				Repo:              "repo",
				PathInRepo:        "another/file.lua",
				SuggestedFilename: "file.lua",
			},
		},
		{
			name: "raw.githubusercontent.com url",
			url:  "https://raw.githubusercontent.com/user/project/v1.0/src/main.go",
			want: &source.ParsedSourceInfo{
				RawURL:            "https://raw.githubusercontent.com/user/project/v1.0/src/main.go",
				CanonicalURL:      "github:user/project/src/main.go@v1.0",
				Ref:               "v1.0",
				Provider:          "github",
				Owner:             "user",
				Repo:              "project",
				PathInRepo:        "src/main.go",
				SuggestedFilename: "main.go",
			},
		},
		{
			name: "github.com url with @ref in path",
			url:  "https://github.com/owner/repo/some/file.py@feature-branch",
			want: &source.ParsedSourceInfo{
				RawURL:            "https://raw.githubusercontent.com/owner/repo/feature-branch/some/file.py",
				CanonicalURL:      "github:owner/repo/some/file.py@feature-branch",
				Ref:               "feature-branch",
				Provider:          "github",
				Owner:             "owner",
				Repo:              "repo",
				PathInRepo:        "some/file.py",
				SuggestedFilename: "file.py",
			},
		},
		{
			name:        "github.com tree url",
			url:         "https://github.com/owner/repo/tree/main/path/to/dir",
			wantErr:     true,
			errContains: "direct links to GitHub trees are not supported",
		},
		{
			name:        "invalid raw.githubusercontent.com url short path",
			url:         "https://raw.githubusercontent.com/owner/repo/main",
			wantErr:     true,
			errContains: "invalid GitHub raw content URL path",
		},
		{
			name:        "ambiguous github.com url (no ref, no blob/raw)",
			url:         "https://github.com/owner/repo/path/file.txt",
			wantErr:     true,
			errContains: "ambiguous GitHub URL",
		},
		{
			name:        "incomplete github.com blob url",
			url:         "https://github.com/owner/repo/blob/main",
			wantErr:     true,
			errContains: "incomplete GitHub URL path",
		},
	}

	for _, tt := range tests {
		tt := tt // capture range variable
		t.Run(tt.name, func(t *testing.T) {
			got, err := source.ParseSourceURL(tt.url)
			if tt.wantErr {
				require.Error(t, err)
				if tt.errContains != "" {
					assert.Contains(t, err.Error(), tt.errContains)
				}
			} else {
				require.NoError(t, err)
				assert.Equal(t, tt.want, got)
			}
		})
	}
}

func TestParseSourceURL_WithTestModeBypass_FullMockURL(t *testing.T) {
	sourceTestMutex.Lock()
	defer sourceTestMutex.Unlock()

	mockServerURL, cleanup := setupSourceTest(t, func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
	})
	defer cleanup()

	tests := []struct {
		name        string
		url         string
		want        *source.ParsedSourceInfo
		wantErr     bool
		errContains string
	}{
		{
			name: "mock server full URL resembling raw content path",
			url:  fmt.Sprintf("%s/mockowner/mockrepo/mockref/path/to/mockfile.txt", mockServerURL),
			want: &source.ParsedSourceInfo{
				RawURL:            fmt.Sprintf("%s/mockowner/mockrepo/mockref/path/to/mockfile.txt", mockServerURL),
				CanonicalURL:      "github:mockowner/mockrepo/path/to/mockfile.txt@mockref",
				Ref:               "mockref",
				Provider:          "github",
				Owner:             "mockowner",
				Repo:              "mockrepo",
				PathInRepo:        "path/to/mockfile.txt",
				SuggestedFilename: "mockfile.txt",
			},
		},
		{
			name: "mock server full URL, file at repo root",
			url:  fmt.Sprintf("%s/anotherowner/anotherrepo/anotherref/file.lua", mockServerURL),
			want: &source.ParsedSourceInfo{
				RawURL:            fmt.Sprintf("%s/anotherowner/anotherrepo/anotherref/file.lua", mockServerURL),
				CanonicalURL:      "github:anotherowner/anotherrepo/file.lua@anotherref",
				Ref:               "anotherref",
				Provider:          "github",
				Owner:             "anotherowner",
				Repo:              "anotherrepo",
				PathInRepo:        "file.lua",
				SuggestedFilename: "file.lua",
			},
		},
		{
			name:        "mock server full URL, path too short",
			url:         fmt.Sprintf("%s/owner/repo/ref", mockServerURL),
			wantErr:     true,
			errContains: "test mode URL path",
		},
		{
			name:        "mock server full URL, path indicates directory",
			url:         fmt.Sprintf("%s/owner/repo/ref/", mockServerURL),
			wantErr:     true,
			errContains: "test mode URL path",
		},
	}

	for _, tt := range tests {
		tt := tt // capture range variable
		t.Run(tt.name, func(t *testing.T) {
			got, err := source.ParseSourceURL(tt.url)
			if tt.wantErr {
				require.Error(t, err)
				if tt.errContains != "" {
					assert.Contains(t, err.Error(), tt.errContains)
				}
			} else {
				require.NoError(t, err)
				assert.Equal(t, tt.want, got)
			}
		})
	}
}

func TestParseSourceURL_NonGitHubURLs(t *testing.T) {
	sourceTestMutex.Lock()
	defer sourceTestMutex.Unlock()

	tests := []struct {
		name        string
		url         string
		wantErr     bool
		errContains string
	}{
		{
			name:        "unsupported http url",
			url:         "http://example.com/somefile.txt",
			wantErr:     true,
			errContains: "unsupported source URL host: example.com",
		},
		{
			name:        "unsupported gitlab url",
			url:         "https://gitlab.com/user/project/raw/main/file.lua",
			wantErr:     true,
			errContains: "unsupported source URL host: gitlab.com",
		},
		{
			name:        "invalid url format",
			url:         ":not_a_url",
			wantErr:     true,
			errContains: "failed to parse source URL",
		},
	}

	for _, tt := range tests {
		tt := tt // capture range variable
		t.Run(tt.name, func(t *testing.T) {
			_, err := source.ParseSourceURL(tt.url)
			require.Error(t, err)
			if tt.errContains != "" {
				assert.Contains(t, err.Error(), tt.errContains)
			}
		})
	}
}



================================================
File: project/PRD.md
================================================
# Almandine Package Manager (Go Version) - PRD

## 1. Introduction

Almandine (`almd` as the CLI command) is a lightweight package manager for Go projects, migrating the core concepts from the original Lua version. It enables simple, direct management of single-file dependencies (initially from GitHub), project scripts, and project metadata. Almandine is designed for projects that want to pin specific versions or commits of files without managing complex dependency trees, leveraging Go's strengths and the `urfave/cli` framework.

## 2. Core Features

-   **Single-file Downloads:** Fetch individual files (initially Lua, but adaptable) from remote repositories (e.g., GitHub), pinning by git commit hash or potentially tags/versions later.
-   **No Dependency Tree Management:** Only downloads files explicitly listed in the project; does not resolve or manage full dependency trees.
-   **Project Metadata:** Maintains project name, type, version, license, and package description in `project.toml` (using TOML format).
-   **Script Runner:** Provides a central point for running project scripts defined in `project.toml`.
-   **Lockfile:** Tracks exact versions or commit hashes of all downloaded files for reproducible builds (`almd-lock.toml`, using TOML format).
-   **License & Description:** Exposes license and package description fields in `project.toml`.
-   **Cross-Platform:** Built as a standard Go binary, naturally cross-platform (Linux, macOS, Windows).

### 2.1. Core Commands (Initial Focus using `urfave/cli`)

-   **`init` command:**
    -   **Goal:** Interactively initialize a new Almandine project by creating a `project.toml` manifest file in the current directory.
    -   **Implementation:** Implemented as a `urfave/cli` command (in `internal/cli/init/init.go`).
    -   **Functionality:**
        -   **Interactive Prompts:** Prompts the user for core project metadata:
            -   `package` name (defaults to `my-go-project` or derived from current dir).
            -   `version` (defaults to `0.1.0`).
            -   `license` (defaults to `MIT`).
            -   `description` (defaults to `A sample Go project using Almandine.`).
            -   Optionally prompts for `language` details (e.g., name `go`, version `>= 1.21`).
        -   **Script Definition:** Interactively prompts the user to add scripts ([`scripts`] table).
            -   Prompts for script `name` and `command`.
            -   Continues prompting until an empty name is entered.
            -   **Default `run` script:** If no `run` script is provided by the user, adds a default (e.g., `go run ./cmd/almd` or a user-project specific default like `go run .`).
        -   **Dependency Placeholders (Simplified):** Interactively prompts the user to add initial dependencies ([`dependencies`] table).
            -   Prompts for dependency `name` and a simple `source/version` string.
            -   Continues prompting until an empty name is entered.
            -   **Note:** `init` creates basic dependency entries. The `add` command is responsible for fleshing these out into the full structure (`source` identifier, `path`).
        -   **Manifest Creation/Overwrite:** Creates `project.toml` in the current directory with the collected information. If `project.toml` already exists, it **overwrites** the existing file.
        -   **Output:** Prints confirmation message upon successful creation/overwrite. Reports errors clearly via `urfave/cli` if file writing fails.
    -   **Arguments & Flags (`urfave/cli`):**
        -   Typically run without arguments or flags, relying purely on interactive input.

-   **`add` command:**
    -   **Goal:** Adds a single-file dependency from a supported source (initially GitHub URLs) to the project.
    -   **Implementation:** Implemented as a `urfave/cli` command (defined in `internal/cli/add/add.go`).
    -   **Functionality:**
        -   Parses the provided URL using Go's `net/url`.
        -   **GitHub URL Processing:** Handles various GitHub URL formats (blob, raw, potentially commit/tag specific). Normalizes the input URL to the **raw content download URL**. Extracts the commit hash if present in the URL. Creates a **canonical source identifier** (e.g., `github:user/repo/path/to/file@commit_hash_or_ref`) for storage in `project.toml`. This logic is encapsulated in `internal/source`.
        -   Downloads the specified file using Go's `net/http` client from the resolved raw content URL (logic in `internal/downloader`).
        -   **Target Directory/Path Handling:** Determines the final destination path for the downloaded file based on the `-d` and `-n` flags. Ensures the target directory exists, creating it if necessary using `os.MkdirAll`.
        -   Saves the downloaded file to the determined target path using `os` and `io` packages.
        -   **Manifest Update (`project.toml`):** Updates the `project.toml` file (using a Go TOML library like `github.com/BurntSushi/toml` and logic in `internal/core/config`). Adds or modifies the dependency entry under the `[dependencies]` table. The key is the derived or specified dependency name (`-n` flag). The value **must be a sub-table** containing:
            -   `source`: The **canonical source identifier** derived from the input URL.
            -   `path`: The relative path (using forward slashes) from the project root to the downloaded file.
        -   **Lockfile Update (`almd-lock.toml`):** Updates the `almd-lock.toml` file (using a TOML library and logic in `internal/core/lockfile`). Adds or updates the entry for the dependency under the `[package]` table. This entry stores:
            -   `source`: The **exact raw download URL** used to fetch the file.
            -   `path`: The relative path (using forward slashes) matching the manifest.
            -   `hash`: A string representing the file's integrity. Format: `commit:<commit_hash>` if a commit was extracted from the URL, otherwise `sha256:<sha256_hash>` calculated from the downloaded content using `crypto/sha256` (logic in `internal/hasher`). Defines how hash calculation errors are represented (e.g., `hash_error:<reason>`).
        -   **Error Handling & Atomicity:** Implement robust error handling. If the process fails after download but before saving manifest/lockfile, attempts to clean up the downloaded file. Reports errors clearly via `urfave/cli` (e.g., using `cli.Exit`).
    -   **Arguments & Flags (`urfave/cli`):**
        -   `<source_url>`: Argument accessed from `*cli.Context` for the source URL of the file (required).
        -   `-d, --directory string`: Flag definition (`cli.StringFlag`) for specifying the target directory. If the path ends in a separator or points to an existing directory, the file is saved inside that directory using the name derived from the `-n` flag or the URL. Otherwise, the flag value is treated as the full relative path for the saved file. Defaults to saving within the `libs/` directory (or `src/lib/` if specified).
        -   `-n, --name string`: Flag definition (`cli.StringFlag`) for specifying the logical name of the dependency (used as the key in `project.toml` and `almd-lock.toml`) and the base filename. If omitted, the name is inferred from the URL's filename component.
        -   `--verbose`: Optional flag (`cli.BoolFlag`) to enable detailed output during execution.

-   **`remove` command:**
    -   **Goal:** Removes a specified dependency from the project manifest (`project.toml`) and lockfile (`almd-lock.toml`), and deletes the corresponding downloaded file.
    -   **Implementation:** Implemented as a `urfave/cli` command (e.g., `commands/remove.go`).
    -   **Functionality:**
        -   **Argument Parsing:** Takes the `<dependency_name>` as a required argument from `*cli.Context`.
        -   **Manifest Loading:** Loads the `project.toml` file (using `internal/config`).
        -   **Dependency Check:** Verifies if the specified `<dependency_name>` exists under the `[dependencies]` table in the manifest.
        -   **Path Retrieval:** Retrieves the relative `path` associated with the dependency from the manifest entry.
        -   **Manifest Update:** Removes the entry corresponding to `<dependency_name>` from the `[dependencies]` table.
        -   **Manifest Saving:** Saves the modified manifest back to `project.toml`.
        -   **File Deletion:** Deletes the file specified by the retrieved `path` using `os.Remove`. Handles potential errors gracefully (e.g., file not found, permissions).
        -   **Lockfile Update:** Loads the `almd-lock.toml` file (using `internal/lockfile`), removes the corresponding entry under the `[package]` table, and saves the updated lockfile.
        -   **Output:** Prints confirmation messages for successful removal from manifest, file deletion (or warnings if deletion fails), and lockfile update. Reports errors clearly via `urfave/cli`.
    -   **Arguments & Flags (`urfave/cli`):**
        -   `<dependency_name>`: Argument accessed from `*cli.Context` for the logical name of the dependency to remove (required).
-   **`install` command:**
    -   **Goal:** Installs or updates specified dependencies to the versions dictated by `project.toml`, or refreshes all dependencies if no specific ones are named. It ensures that the local project state (downloaded files and `almd-lock.toml`) aligns with the desired state specified in `project.toml`.
    -   **Implementation:** To be implemented as a `urfave/cli` command (e.g., in `internal/cli/install/install.go`).
    -   **Functionality:**
        -   **Argument Parsing:** Accepts an optional list of `<dependency_name>` arguments from `*cli.Context`. If no names are provided, it targets all dependencies listed in `project.toml`.
        -   **Manifest & Lockfile Loading:** Loads `project.toml` (using `internal/core/config`) and `almd-lock.toml` (using `internal/core/lockfile`).
        -   **Dependency Iteration:** For each targeted dependency:
            1.  **Retrieve Project Configuration:** Fetches the dependency's configuration (its canonical `source` identifier and `path`) from the `[dependencies]` table in `project.toml`. If a specified dependency name is not found in `project.toml`, it will be skipped with a warning.
            2.  **Resolve Target Version/Source:** The `source` string from `project.toml` (e.g., `github:user/repo/file.lua@main` or `github:user/repo/file.lua@v1.2.3`) defines the desired state. This source identifier is resolved to a concrete, downloadable raw URL and a definitive commit hash or version identifier (e.g., the latest commit hash on the `main` branch, or the commit hash corresponding to tag `v1.2.3`). This resolution logic resides in `internal/source`.
            3.  **Retrieve Current Lockfile State:** Fetches the current locked state for this dependency from `almd-lock.toml`, if an entry exists. This includes the exact raw `source` URL previously used for download and the integrity `hash` (e.g., `commit:<hash>` or `sha256:<hash>`).
            4.  **Comparison and Decision Logic:**
                -   An install/update is required if:
                    -   The resolved target commit hash (from step 2) differs from the commit hash recorded in `almd-lock.toml` (from step 3).
                    -   The dependency is present in `project.toml` but missing from `almd-lock.toml`.
                    -   The local file at the dependency's `path` is missing, even if hashes might otherwise match.
                    -   A `--force` flag is used by the user.
                -   If the resolved target commit hash matches the one in `almd-lock.toml` and the local file exists, the dependency is considered up-to-date with its `project.toml` specification, and no action is taken unless forced.
            5.  **Perform Install/Update (if required):**
                -   The file is downloaded from the resolved target raw URL (using `internal/downloader`).
                -   The integrity hash is calculated for the downloaded content (commit hash is preferred if available from the source URL, otherwise SHA256 via `internal/hasher`).
                -   The downloaded file is saved to its designated `path` (from `project.toml`), ensuring that any necessary parent directories are created.
                -   The `almd-lock.toml` file is updated: the entry for the dependency will store the exact raw download URL used, the `path`, and the new integrity `hash`.
                -   **Note on `project.toml`:** The `source` field in `project.toml` typically remains as specified by the user (e.g., it can continue to point to a branch like `main`). The `almd-lock.toml` file is always updated to store the pinned, concrete version details (specific commit hash and exact download URL).
        -   **Output:** Provides clear feedback, indicating which dependencies were checked, which were installed/updated, and which were already up-to-date. Errors encountered during the process are reported clearly via `urfave/cli`.
    -   **Arguments & Flags (`urfave/cli`):**
        -   `[dependency_names...]`: Optional argument(s) accessed from `*cli.Context` specifying the logical names of the dependencies to install/update. If omitted, all dependencies defined in `project.toml` are targeted.
        -   `--force`, `-f`: Optional flag (`cli.BoolFlag`) to compel re-downloading of files and updating of lockfile entries, even if the resolved version appears to be identical to the currently locked version.
        -   `--verbose`: Optional flag (`cli.BoolFlag`) to enable more detailed logging output during execution.

-   **`list` command (aliased as `ls`):**
    -   **Goal:** Displays a list of project dependencies, showing their configured sources from `project.toml`, their local paths, and their locked versions or hashes from `almd-lock.toml`.
    -   **Implementation:** To be implemented as a `urfave/cli` command (e.g., in `internal/cli/list/list.go`).
    -   **Functionality:**
        -   **Manifest & Lockfile Loading:** Loads `project.toml` (via `internal/core/config`) and `almd-lock.toml` (via `internal/core/lockfile`).
        -   **Dependency Traversal:** Iterates through the dependencies defined in the `[dependencies]` table of `project.toml`. For each dependency:
            -   Retrieves its logical name, the configured `source` identifier, and its relative `path` from `project.toml`.
            -   Attempts to retrieve its corresponding entry from `almd-lock.toml` to get the locked raw `source` URL and the integrity `hash`.
        -   **Output Formatting:** Displays information in a format similar to `pnpm list`. It will use the `fatih/color` library for terminal coloring, respecting the `NO_COLOR` environment variable.
            -   **Project Information Line:**
                -   Format: `ProjectName@Version /path/to/project/root`
                -   Colors:
                    -   Project Name: Magenta (`color.FgMagenta`)
                    -   `@`: Standard terminal color
                    -   Version: Magenta (`color.FgMagenta`)
                    -   Path: Dim Gray (`color.FgHiBlack`)
            -   An empty line follows the project information.
            -   **"dependencies:" Header:**
                -   Text: `dependencies:`
                -   Color: Cyan and Bold (`color.FgCyan`, `color.Bold`)
            -   **Dependency Lines:**
                -   Format: `DependencyName LockedHash RelativePath`
                -   Colors:
                    -   Dependency Name: White (`color.FgWhite`)
                    -   Locked Hash: Yellow (`color.FgYellow`) (e.g., `commit:<hash>` or `sha256:<hash>`, or "not locked" in standard color if applicable)
                    -   Relative Path: Dim Gray (`color.FgHiBlack`)
            -   If no dependencies, after the "dependencies:" header, "(none)" will be printed in standard color.
        -   **Extended Information (e.g., with a `--long` or `-l` flag):**
            -   The full locked raw `source` URL from `almd-lock.toml`.
            -   Status indication, e.g., "INSTALLED" (if local file at `path` exists and optionally matches hash), "MISSING" (if local file at `path` does not exist), "NOT_LOCKED".
            -   (Future/Advanced) Potentially indicate if a newer version is available if the `project.toml` source is a "floating" reference (like a branch name) and it resolves to a newer commit than what's in the lockfile. This would require resolving the `project.toml` source during the list operation.
        -   **No Dependencies:** If `project.toml` contains no dependencies, the "dependencies:" header is still printed, followed by "(none)".
    -   **Arguments & Flags (`urfave/cli`):**
        -   `--long`, `-l`: Optional flag (`cli.BoolFlag`) to display more detailed information for each listed dependency.
        -   `--json`: Optional flag (`cli.BoolFlag`) to output the dependency list in JSON format, suitable for machine parsing.
        -   `--porcelain`: Optional flag (`cli.BoolFlag`) for a simple, scriptable output format (e.g., `name@version_hash path`).

-   **`self` command:**
    -   **Goal:** Provides commands related to the Almandine tool itself, such as self-updating.
    -   **Subcommands:**
        -   **`update` subcommand:**
            -   **Goal:** Allows the `almd` tool to update itself to the latest version from its release source (initially GitHub).
            -   **Full Command:** `almd self update`
            -   **Implementation:** To be implemented as a `urfave/cli` subcommand. It will utilize a library like `github.com/creativeprojects/go-selfupdate` (which supports various sources including GitHub) or a similar robust self-update library.
            -   **Functionality:**
                -   Checks the configured release source (e.g., the official `almandine` GitHub repository) for the latest release.
                -   Compares the latest available version with the version of the currently running `almd` executable. The current version of `almd` **must** be embedded into the binary at build time (e.g., using Go's `-ldflags "-X main.version=vX.Y.Z"`).
                -   If a newer version is found, it can prompt the user for confirmation before proceeding or update directly if a force/yes flag is used.
                -   Downloads the binary asset appropriate for the user's operating system and architecture from the release source.
                -   Verifies the integrity of the downloaded binary (e.g., via checksums if provided by the release).
                -   Safely replaces the current `almd` executable with the downloaded version.
                -   Provides clear feedback to the user regarding the update process (e.g., "Checking for updates...", "Updating to vX.Y.Z...", "Update successful.", "Almandine is already up-to-date.").
            -   **Arguments & Flags (`urfave/cli` for `almd self update`):**
                -   `--yes` / `-y` (optional `cli.BoolFlag`): Skips confirmation and proceeds with the update automatically if a new version is found.
                -   `--check` (optional `cli.BoolFlag`): Only checks for available updates and reports the status without performing the update.
                -   `--source <url>` (optional `cli.StringFlag`): Potentially allows specifying an alternative update source URL (though typically this would be hardcoded or configured for the official build).
                -   `--verbose` (optional `cli.BoolFlag`): Enables detailed output during the update check and process.


## 3. Almandine Tool Project Structure (Go Implementation)

Standard Go project layout combined with Almandine specifics:

-   `project.toml`       # Default project manifest filename for projects using Almandine
-   `almd-lock.toml`     # Default lockfile filename for projects using Almandine
-   `go.mod`               # Go module definition for Almandine tool
-   `go.sum`               # Go module checksums for Almandine tool
-   `README.md`            # Project README for Almandine development
-   `.github/`             # GitHub-specific files (workflows, issue templates, etc.)
-   `cmd/`                 # Main applications for the project
    -   `almd/`            # The Almandine CLI application (assuming CLI command is 'almd')
        -   `main.go`      # Main entry point, CLI argument parsing, command dispatch
-   `internal/`            # Private application and library code (not for external import)
    -   `cli/`             # CLI command logic and definitions
        -   `add/`         # Logic for the 'add' command
            -   `add.go`
            -   `add_test.go`
        -   `init/`     # Logic for the 'init' command
            -   `init.go`
            -   `init_test.go`
        -   `remove/`      # Logic for the 'remove' command
            -   `remove.go`
        -   `...`          # Other command packages/modules
    -   `core/`            # Core application logic (business logic)
        -   `config/`      # Loading, parsing, and updating `project.toml`
            -   `config.go`
            -   `config_test.go`
        -   `lockfile/`    # Loading, parsing, and updating `almd-lock.toml`
            -   `lockfile.go`
            -   `lockfile_test.go`
        -   `downloader/`  # File downloading logic
            -   `downloader.go`
            -   `downloader_test.go`
        -   `hasher/`      # Content hashing logic (e.g., SHA256)
            -   `hasher.go`
            -   `hasher_test.go`
        -   `project/`     # Go structs representing project/lockfile data models
            -   `project.go`
        -   `source/`      # Handling source URL parsing, normalization, identifier creation
            -   `source.go`
            -   `source_test.go`
    -   `util/`            # General utility functions shared across internal packages
-   `pkg/`                 # Public library code, reusable by other projects (if any - initially empty)
    -   `...`              # Example: `pkg/somepublicapi/`
-   `scripts/`             # Scripts for building, installing, analyzing the Almandine tool itself (e.g., `build.sh`, `install.sh`)
-   `configs/`             # Configuration files for the Almandine tool (e.g., for different environments - placeholder)
-   `docs/`                # Almandine tool's own documentation (user guides, design documents, PRD, etc.)
-   `test/`                # Additional tests (e.g., E2E, integration) and test data
    -   `e2e/`             # End-to-end tests
    -   `data/`            # Test data, fixtures (optional)

The directory `lib/` (mentioned in the previous structure) is not part of the Almandine tool's own source code structure. It typically refers to the default output directory within a *user's project* where Almandine might download dependencies (e.g., `src/lib/` or a user-configured path).

Unit tests (e.g., `foo_test.go`) should be co-located with the Go source files they test (e.g., in the same package/directory like `internal/core/config/config_test.go`). The top-level `test/` directory is for tests that span multiple packages or require specific data/environments (e.g., end-to-end tests).

## 3.1 Example Lua Project Structure (Using Almandine)

This shows a typical layout for a Lua project managed by the Almandine tool:

-   `project.toml`       # Defines project metadata, scripts, and dependencies for Almandine
-   `almd-lock.toml`  # Stores locked dependency versions/hashes generated by Almandine

-   `src/`                 # Lua project source code
    -   `main.lua`         # Example entry point for the Lua project
    -   `my_module.lua`
    -   `lib/`                 # Default directory where Almandine downloads dependencies (user-configurable)
        -   `some_dependency.lua` # Example file downloaded by Almandine
        -   `another_lib/`        # Example library downloaded by Almandine
        -   `module.lua`
-   `scripts/`             # Optional directory for Lua scripts runnable via `almd run <script_name>`
    -   `build.lua`

## 4. File Descriptions

### `project.toml`

Project manifest in TOML format. Example structure based on user input:

```toml
# Example project.toml
package = "sample-project"
version = "0.1.0"
license = "MIT"
description = "A sample Go project using Almandine."
# language = { name = "go", version = ">=1.21" } # Example if language details are added

# Optional: Define primary source if needed for context
# [source]
# url = "https://github.com/nvim-neorocks/luarocks-stub" # Example purpose

# Dependencies section
[dependencies]
# Name inferred from URL (e.g., 'lua-cjson')
# [dependencies."lua-cjson"] # Name can be explicitly set with -n
#   source = "github:user/repo/lua-cjson.lua@tag-2.1.0" # Canonical identifier
#   path = "src/lib/lua-cjson.lua" # Relative path in project

# Dependency added with -n flag and custom path via -d
[dependencies."plenary"] # Specified via -n plenary
  source = "github:nvim-lua/plenary.nvim/some/file.lua@v0.1.4"
  path = "src/vendor/plenary.lua" # Specified via -d src/vendor/plenary.lua
  # Could potentially add other metadata like 'pin = true' if needed later

# Optional: Build or script definitions
[build]
type = "builtin" # Example build type

# Example scripts section (similar to npm scripts)
[scripts]
game = "love src/"
debug = "love src/ --console"
test = "love src/ --console --test"

```
-   Handles project metadata (name, version, etc.).
-   Defines dependencies under `[dependencies]`. Each dependency is a key (the logical name) mapping to a **sub-table** containing `source` (canonical identifier) and `path` (relative location).
-   Defines project scripts under `[scripts]`.

### `almd-lock.toml`

Tracks resolved dependencies for reproducible installs in TOML format. Example structure:

```toml
# Example almd-lock.toml
# Lockfile format version (increment if structure changes significantly)
api_version = "1"

# Package table holds all locked dependencies
[package]

# Entry for a dependency 'mylib', locked from project.toml entry
[package.mylib]
  # The *exact* raw download URL used to fetch this version
  source = "https://raw.githubusercontent.com/user/repo/v1.0.0/path/to/file.ext"
  # Relative path within the project (forward slashes)
  path = "vendor/custom/mylib" # Example, matches project.toml path
  # Integrity hash: commit hash if available from source URL, otherwise sha256 of content
  hash = "sha256:deadbeef..." # Example sha256 hash
  # Example of a commit hash from URL:
  # hash = "commit:abcdef123..."

# Entry for 'anotherdep', locked from project.toml entry
[package."anotherdep"]
  source = "https://raw.githubusercontent.com/another/repo/main/lib.lua"
  path = "libs/lib.lua" # Example, default path
  hash = "commit:abcdef123" # Example if pinned to a specific commit hash
  # Example of a hash error state:
  # hash = "hash_error:tool_not_found" # Or "hash_error:calculation_failed"

```
-   Stores the exact resolved `source` (raw download URL), `path`, and `hash` (content or commit or error state) for each dependency under the `[package]` table.
-   The `api_version` helps manage potential future format changes.

### `go.mod` & `go.sum`

Standard Go module files defining the project module path and managing Go dependencies.

### `main.go`

Main entry point for the `almd` CLI. This file initializes and configures the primary `cli.App` instance from the `urfave/cli` library. It defines global application metadata (like name, usage, version), global flags, registers all command definitions (e.g., from the `commands/` package or defined directly), and then executes the application logic by calling `app.Run(os.Args)`, which parses arguments and routes execution to the appropriate command's `Action` function.

commands/ (Go Project Command Packages)

Contains Go packages, each implementing a specific CLI command (e.g., add, init, remove). The add package would contain the Go logic for the add command.
cmd/almd/main.go (Go Project Entrypoint)

    Main entry point for the almd CLI executable.
    Responsible for:
        Parsing CLI arguments using a Go library (e.g., standard flag, cobra, urfave/cli).
        Dispatching execution to the appropriate command package in cmd/almd/commands/.
        Handling standard command aliases (e.g., install/in/ins, remove/rm/uninstall/un, update/up/upgrade, add/i, etc.) within the CLI library configuration.
        All usage/help output, documentation, and examples must use almd as the CLI tool name (never almandine).
        Updates here are required when adding/modifying commands or aliases.

Build & Distribution (Go Context)

    The install/ directory (containing Lua bootstrap scripts) is removed.
    Distribution involves building the Go project (go build ./cmd/almd) to produce a native executable (almd or almd.exe) for each target platform (Linux, macOS, Windows).
    Standard Go cross-compilation techniques will be used. Users simply download and place the appropriate binary in their PATH.

5. Conclusion

Almandine, implemented in Go, aims to provide a simple, robust, and reproducible workflow for Lua projects needing lightweight dependency management and script automation, without the complexity of full dependency trees. It leverages Go's strengths for building reliable, cross-platform CLI tools while managing Lua project structures and manifests.
Tech Stack

    Implementation Language: Go (e.g., 1.21 or later)
    Target Project Language: Lua 5.1â€“5.4 / LuaJIT 2.1 (though Almandine itself is Go, it can manage files for any language)
    Platform (Tool): Cross-platform executable (Linux, macOS, Windows) via Go compilation.
    Key Go Libraries (Potential):
        Standard Library: net/http, os, os/exec, path/filepath, crypto/sha256, flag or similar for CLI.
        External Go Modules:
            A TOML parser/generator library (e.g., `github.com/BurntSushi/toml`).
            A robust CLI framework (e.g., `github.com/urfave/cli/v2`).
            An assertion library for testing (e.g., `github.com/stretchr/testify/assert`).
            A terminal color library (e.g., `github.com/fatih/color`) for enhanced CLI output.
            Possibly a Git client library (e.g., go-git/go-git) if direct Git operations are needed beyond simple HTTP downloads (not currently planned for initial features).

## 5. Project-Specific Coding Rules (Go Implementation)

These rules supplement the mandatory Global AI Project Guidelines and define standards specific to this Go project.
### 5.1 Language, Environment & Dependencies

    Target Language: Go (specify version, e.g., Go 1.21+).
    Environment: Standard Go development environment.
    Dependencies:
        Leverage the Go Standard Library extensively.
        External Go modules should be carefully chosen and documented in go.mod. Justify non-standard library dependencies. Key required external dependency: a library for parsing/generating Lua table syntax accurately.
        The compiled almd tool must have no runtime dependencies (like needing a specific interpreter installed).

### 5.2 Go Coding Standards

These standards guide Go development within this project.

    Formatting: All Go code must be formatted using gofmt (or goimports). This is non-negotiable and should be enforced by CI.
    Style: Adhere to the principles outlined in Effective Go and the Go Code Review Comments guide.
        Naming: Use CamelCase for exported identifiers and camelCase for unexported identifiers. Package names should be short, concise, and lowercase.
        Simplicity: Prefer clear, simple code over overly complex or clever solutions.
    Error Handling: Use standard Go error handling practices (if err != nil { return ..., err }). Errors should be handled or propagated explicitly. Use errors.Is, errors.As, and error wrapping (fmt.Errorf("...: %w", err)) where appropriate.
    Concurrency: Use goroutines and channels only when concurrency genuinely simplifies the problem or improves performance, and do so carefully, considering race conditions and synchronization.
    Packages: Structure code into logical, well-defined packages with clear APIs. Minimize unnecessary coupling between packages. Utilize internal packages (internal/) for code not meant to be imported by other modules.
    Documentation:
        All exported identifiers (variables, constants, functions, types, methods) must have documentation comments (// style comments preceding the declaration).
        Package comments (// package mypackage ...) should provide an overview of the package's purpose.
        Comments should explain why something is done, not just what is being done, unless the code itself is unclear. Follow godoc conventions.

### 5.3 Testing & Behavior Specification (Prototype Phase - Go Context)

These rules specify how testing and behavior specification are implemented using Go's standard testing package during the prototype phase.

    Framework: Use Go's built-in `testing` package. Test assertions use `github.com/stretchr/testify/assert`.
    Specification Location:
        Unit/Integration tests: Place test files (`*_test.go`) alongside the Go code they are testing (e.g., `internal/core/config/config_test.go` tests `internal/core/config/config.go`). Command-specific unit tests (e.g., for `init`, `add`) are located in their respective packages (e.g., `internal/cli/add/add_test.go`).
        E2E Tests (Prototype Focus): Place E2E tests in a dedicated location, such as `cmd/almd/main_e2e_test.go` or a top-level `test/e2e/` directory. For the prototype, command-specific tests that execute the CLI (like those in `internal/cli/add/add_test.go` which run an `app.Run` instance) serve as focused E2E-like tests for command behavior.
    File Naming: Test files must end with `_test.go`. Test functions must start with `Test` (e.g., `TestAddCommand_HappyPath`).
    Test Type Focus (Prototype):
        Command Unit Tests: Test individual command actions (e.g., the `Action` func of an `urfave/cli.Command`). These tests mock external dependencies like network calls (`net/http/httptest`) and operate on a temporary file system.
        E2E Tests: Verify system behavior by executing the compiled `almd` binary (or a test `cli.App` instance) against temporary project structures. Simulate user interactions via CLI arguments.
    Test Sandboxing & Scaffolding: Tests must run in isolated, temporary directories.
        Use `t.TempDir()` (available in Go 1.15+) within test functions to create sandboxed directories.
        Develop Go helper functions (e.g., within test files or a shared test utility package) to:
            Set up temporary project structures (creating directories, minimal `project.toml`).
            Run the `almd` command or its action, capturing output and errors. For `add` command tests, this includes setting up mock HTTP servers (`net/http/httptest`).
            Provide functions for asserting file existence, file content (using `os.ReadFile`), and parsing/asserting the content of the resulting `project.toml` and `almd-lock.toml` files within the sandbox.
            Cleanup is handled automatically by `t.TempDir()` or explicit `defer os.RemoveAll()`.
    Scenario Coverage: Each test function or suite (`t.Run`) should cover specific scenarios:
        Expected Behavior: Successful flows (e.g., `almd add ...` works correctly, `almd init` creates files as expected).
        Boundary Conditions: Edge cases (e.g., adding the same file twice, invalid URLs, empty inputs for `init`).
        Undesired Situations: Error handling (e.g., non-existent URLs, file system permission errors, invalid `project.toml` format). Use helper functions to assert expected error messages or exit codes.
    Test Dependencies:
        Command unit tests mock external dependencies (network, file system interactions beyond the temp dir).
        E2E-style tests will naturally depend on the internal Go packages used for parsing/validation (e.g., `internal/core/config`, `internal/core/lockfile`).


================================================
File: project/TASKS.md
================================================
# Task Checklist: Almandine Go Implementation - `init` & `add` Commands

**Purpose:** Tracks tasks and milestones for implementing the core `init` and `add` commands for the Almandine Go CLI (`almd`), based on the specifications in `project/PRD.md`.

**Multiplatform Policy:** All implementations MUST be compatible with Linux, macOS, and Windows.

---

## Milestone 0: Initial Setup & `main.go` Entrypoint

**Goal:** Create the basic Go project structure and the main CLI entry point using `urfave/cli`.

-   [x] **Task 0.1: Initialize Go Module**
    -   [x] Run `go mod init <module_path>` (e.g., `go mod init github.com/your-user/almandine`). *User needs to determine the module path.*
    -   [x] Add `urfave/cli/v2` dependency (`go get github.com/urfave/cli/v2`).
    -   [x] Manual Verification: `go.mod` and `go.sum` are created/updated.

-   [x] **Task 0.2: Create `main.go`**
    -   [x] Create the `main.go` file at the project root.
    -   [x] Add the basic `main` function.
    -   [x] Manual Verification: File exists.

-   [x] **Task 0.3: Basic `urfave/cli` App Setup**
    -   [x] Import `urfave/cli/v2`.
    -   [x] Create a new `cli.App` instance in `main`.
    -   [x] Set the `Name` (`almd`), `Usage`, and `Version` for the app.
    -   [x] Implement the `app.Run(os.Args)` call.
    -   [x] Manual Verification: Run `go run main.go --version` and confirm the version is printed. Run `go run main.go --help` and confirm basic usage is shown.

-   [x] **Task 0.4: Define CLI Binary Name Convention**
    -   [x] Ensure the target executable name built by Go is `almd`.
    -   [x] *Note:* A separate wrapper script/alias named `almd` will be used by end-users to call `almd`. This task is about the Go build output name. (Build command might be `go build -o almd .`)
    -   [x] Manual Verification: Build the project (`go build -o almd .`) and confirm the output file is named `almd`.

---

## CLI Tool Name

-   The CLI executable is called `almd`.
-   All documentation, usage, and examples should refer to the CLI as `almd`.

---

## Milestone 1: `init` Command Implementation

**Goal:** Implement the `almd init` command to interactively create a `project.toml` manifest file.

-   [x] **Task 1.1: `urfave/cli` Command Setup**
    -   [x] Define the `init` command structure (`cli.Command`) within `commands/init.go`.
    -   [x] Add the command to the `urfave/cli` App in `main.go`.
    -   [x] Ensure basic command registration works (`almd init --help`).
    -   [x] Manual Verification: Run `almd init --help` and confirm the command is listed.

-   [x] **Task 1.2: Implement Interactive Prompts for Metadata**
    -   [x] Add logic within the `init` command's `Action` to prompt the user for:
        -   `package` name (with default).
        -   `version` (with default `0.1.0`).
        -   `license` (with default `MIT`).
        -   `description` (with default).
        -   Optional: `language` details (consider defaulting initially).
    -   [x] Manual Verification: Run `almd init` interactively and confirm prompts appear and capture input correctly.

-   [x] **Task 1.3: Implement Interactive Prompts for Scripts**
    -   [x] Add logic to loop, prompting for script `name` and `command`.
    -   [x] Store collected scripts (e.g., in a `map[string]string`).
    -   [x] Exit the loop when an empty script name is entered.
    -   [x] Implement logic to add a default `run` script (`lua src/main.lua`) if the user doesn't define one.
    -   [x] Manual Verification: Run `almd init` interactively, add a few scripts, skip adding `run`, and verify the default is included conceptually (actual file writing is next).

-   [x] **Task 1.4: Implement Interactive Prompts for Dependencies (Placeholders)**
    -   [x] Add logic to loop, prompting for dependency `name` and a simple `source/version` string (as per PRD).
    -   [x] Store collected dependency placeholders (e.g., in a `map[string]string` or `map[string]interface{}`).
    -   [x] Exit the loop when an empty dependency name is entered.
    -   [x] Manual Verification: Run `almd init` interactively, add a few placeholder dependencies.

-   [x] **Task 1.5: Implement `project.toml` Structure and Writing**
    -   [x] Define Go structs in `internal/project/` to represent the `project.toml` structure (package info, scripts, dependencies).
    -   [x] Create functions in `internal/config/` to marshal the collected data into the Go struct and write it to `project.toml` using a TOML library (`github.com/BurntSushi/toml`).
    -   [x] Ensure the function correctly handles overwriting an existing `project.toml`.
    -   [x] Integrate this writing logic into the `init` command's `Action`.
    -   [x] Add clear output messages (success, errors).
    -   [x] Manual Verification: Run `almd init`, provide input, and verify `project.toml` is created correctly with the specified data and defaults. Run again and verify it overwrites. Check error handling for write failures (e.g., permissions).

## Milestone 2: `add` Command Implementation

**Goal:** Implement the `almd add <source_url>` command to download a single-file dependency, update `project.toml`, and update `almd-lock.toml`.

-   [x] **Task 2.1: `urfave/cli` Command Setup & Argument/Flag Parsing**
    -   [x] Define the `add` command structure (`cli.Command`) in `commands/add.go`.
    -   [x] Define the required `<source_url>` argument.
    -   [x] Define the flags: `-d, --directory string`, `-n, --name string`, `--verbose bool`.
    -   [x] Add the command to the `urfave/cli` App in `main.go`.
    -   [x] Implement basic parsing logic within the `Action` to retrieve the argument and flag values.
    -   [x] Manual Verification: Run `almd add --help` and confirm the command, argument, and flags are listed correctly. Run `almd add some-url -n test -d testdir --verbose` and verify the values are accessible within the (currently empty) action.

-   [x] **Task 2.2: Implement Source URL Handling (`internal/source`)**
    -   [x] Create package `internal/source`.
    -   [x] Implement functions to parse the input `<source_url>` (`net/url`).
    -   [x] Implement logic specifically for GitHub URLs:
        -   Normalize various formats (blob, raw) to the raw content download URL.
        -   Extract commit hash/ref if present.
        -   Create the canonical source identifier string (e.g., `github:user/repo/path@hash`).
    -   [x] Define return structures or values for the raw URL, canonical identifier, and extracted commit hash.
    -   [x] Manual Verification: Test the parsing functions with various valid and invalid GitHub URL formats. (Code review of parsing logic done, specific unit tests are outside this immediate task but recommended next)

-   [x] **Task 2.3: Implement File Downloading (`internal/downloader`)**
    -   [x] Create package `internal/downloader`.
    -   [x] Implement a function that takes a URL (the raw download URL from Task 2.2) and fetches the content using `net/http`.
    -   [x] Handle potential HTTP errors (status codes, network issues).
    -   [x] Return the downloaded content (e.g., as `[]byte`).
    -   [x] Manual Verification: Test the download function with a known raw GitHub file URL. (Code implemented; manual test by user pending integration)

-   [x] **Task 2.4: Implement Target Path Logic & File Saving**
    -   [x] Add logic within the `add` command's `Action` to determine the final destination path based on the `-d` flag, `-n` flag (or inferred name), and the project root.
    -   [x] Use `os.MkdirAll` to create the target directory if it doesn't exist.
    -   [x] Use `os.WriteFile` to save the downloaded content (`[]byte` from Task 2.3) to the determined path.
    -   [x] Handle file writing errors.
    -   [x] Manual Verification: Run `almd add <url>` with different `-d` and `-n` combinations and verify the file is saved to the correct location with the correct name. Test directory creation.

-   [x] **Task 2.5: Implement Hashing (`internal/hasher`)**
    -   [x] Create package `internal/hasher`.
    -   [x] Implement a function to calculate the SHA256 hash of file content (`[]byte`) using `crypto/sha256`.
    -   [x] Format the output hash string as `sha256:<hex_hash>`.
    -   [x] Manual Verification: Test the hashing function with known content and verify the output hash.

-   [x] **Task 2.6: Define Data Structures (`internal/project`)**
    -   [x] Extend Go structs in `internal/project/` to represent the `dependencies` table structure in `project.toml` (sub-table with `source`, `path`).
    -   [x] Define Go structs for the `almd-lock.toml` structure (`api_version`, `[package]` table with entries containing `source`, `path`, `hash`).
    -   [x] Manual Verification: Code review confirms structs accurately model the TOML structures defined in `PRD.md`.

-   [x] **Task 2.7: Implement Manifest Update (`internal/config`)**
    -   [x] Add functions in `internal/config/` to:
        -   [x] Load an existing `project.toml`.
        -   [x] Add or update a dependency entry in the `[dependencies]` map using the dependency name (from `-n` or inferred), canonical source identifier (Task 2.2), and relative file path (Task 2.4).
        -   [x] Save the updated manifest back to `project.toml`.
    -   [x] Integrate this logic into the `add` command's `Action`.
    -   [x] Manual Verification: Run `almd add <url>`, then inspect `project.toml` to verify the dependency entry is added/updated correctly.

-   [x] **Task 2.8: Implement Lockfile Update (`internal/lockfile`)**
    -   [x] Create package `internal/lockfile`.
    -   [x] Add functions to:
        -   [x] Load `almd-lock.toml` (handling file not found initially).
        -   [x] Calculate the integrity hash string: `commit:<commit_hash>` (if available from Task 2.2) or `sha256:<hash>` (from Task 2.5). Handle potential hashing errors (`hash_error:<reason>`).
        -   [x] Add or update an entry in the `[package]` map using the dependency name, the *exact raw download URL* (Task 2.2), the relative file path (Task 2.4), and the calculated hash string.
        -   [x] Set/ensure `api_version = "1"`.
        -   [x] Save the updated lockfile back to `almd-lock.toml`.
    -   [x] Integrate this logic into the `add` command's `Action`.
    -   [x] Manual Verification: Run `almd add <url>`, then inspect `almd-lock.toml` to verify the entry is added/updated with the correct source URL, path, and hash format.

-   [x] **Task 2.9: Error Handling and Cleanup**
    -   [x] Review the `add` command's `Action` logic.
    -   [x] Implement error handling using `urfave/cli`'s error reporting (e.g., `cli.Exit`).
    -   [x] If an error occurs *after* downloading the file but *before* successfully updating both manifest and lockfile, attempt to delete the downloaded file to maintain consistency.
    -   [x] Ensure clear error messages are provided to the user.
    -   [x] Manual Verification: Test error scenarios: invalid URL, download failure, write permission errors for manifest/lockfile, simulate failures mid-process to check cleanup.

## Milestone 3: Initial Testing Setup

**Goal:** Establish the basic structure for tests for the `init` and `add` commands.

-   [x] **Task 3.1: Define Testing Strategy**
    -   [x] Framework: Standard Go `testing` package with `testify` for assertions.
    -   [x] `init` command: Unit tests directly invoking the command's `Action`, simulating user input (as in `commands/init_test.go`).
    -   [x] `add` command: Unit tests directly invoking the command's `Action` (via `app.Run` within the test).
        -   [x] Network calls for `add` will be mocked using `net/http/httptest`.
        -   [x] File system operations will occur in temporary directories created by tests.
    -   [x] Setup/Teardown: Tests will create temporary directories and necessary initial files (e.g., `project.toml`), and these will be cleaned up automatically by `t.TempDir()` or explicit `defer os.RemoveAll`.
    -   [x] Manual Verification: Review the chosen strategy for feasibility.

-   [x] **Task 3.2: Create Test File Structure**
    -   [x] Test file for `init` command: `commands/init_test.go` (exists).
    -   [x] Create test file for `add` command: `commands/add_test.go`.
    -   [x] Implement shared test helpers if applicable (e.g., for creating temp env, running command actions).
    -   [x] Manual Verification: Run `go test ./...` and confirm test files are picked up.

-   [ ] **Task 3.3: Implement `init` Command Test Cases (Existing)**
    -   [x] Basic `init` test case (as in `commands/init_test.go`).
    -   [x] `init` test case with defaults and empty inputs (as in `commands/init_test.go`).
    -   [x] **Sub-Task 3.3.1: Fix `TestInitCommand` failure "project.toml\project.toml: The system cannot find the path specified." (2025-05-08)**
        -   [x] Changed `config.WriteProjectToml("project.toml", ...)` to `config.WriteProjectToml(".", ...)` in `internal/cli/init/init.go` to correctly specify the current directory for `project.toml` creation.

-   [ ] **Task 3.4: Implement `add` Command Unit Test Cases**
    -   [x] **Sub-Task 3.4.1: Setup for `add` tests in `commands/add_test.go`**
        -   [x] Define `TestMain` if any global setup/teardown for `add` tests is needed.
        -   [x] Create helper: `setupAddTestEnvironment(t *testing.T, initialProjectTomlContent string) (tempDir string)` that creates a temp dir and a `project.toml`.
        -   [x] Create helper: `runAddCommand(t *testing.T, tempDir string, mockServerURL string, cliArgs ...string) error` to set up and run the `add` command's action using an `cli.App` instance.
        -   [x] Create helper: `startMockHTTPServer(t *testing.T, content string, expectedPath string, statusCode int) *httptest.Server`.
    -   [x] **Sub-Task 3.4.2: Test `almd add` - Successful Download and Update (Explicit Name, Custom Directory)**
        -   [x] Setup: Temp dir, basic `project.toml`, mock HTTP server serving test content.
        -   [x] Execute: `almd add <mock_url_to_file> -n mylib -d vendor/custom`.
        -   [x] Verify:
            -   `vendor/custom/mylib` created with correct content.
            -   `project.toml` updated with `[dependencies.mylib]` pointing to `source` and `path="vendor/custom/mylib"`.
            -   `almd-lock.toml` created/updated with `[package.mylib]` including `source`, `path`, and `hash="sha256:..."`.
    -   [x] **Sub-Task 3.4.3: Test `almd add` - Successful Download (Inferred Name, Default Directory)**
        -   [x] Execute: `almd add <mock_url_to_file.lua>`.
        -   [x] Verify:
            -   `libs/file.lua` (or project root, per PRD) created.
            -   Manifest and lockfile updated with inferred name `file.sh`.
    -   [x] **Sub-Task 3.4.4: Test `almd add` - GitHub URL with Commit Hash**
        -   [x] URL can include a commit hash segment (e.g., `file.lua@commitsha`) or a branch/tag name (e.g., `file.lua@main`).
        -   [x] Verify `almd-lock.toml` `hash` field reflects `commit:<actual_commit_sha>`. If original URL was a branch/tag, it's resolved to the latest commit SHA for that file on that branch/tag. If original URL was a commit SHA, that SHA is used.
        -   [x] If GitHub API call fails to resolve a branch/tag, or if not a GitHub URL, verify fallback to `sha256:<content_hash>`.
    -   [x] **Sub-Task 3.4.5: Test `almd add` - Error: Download Failure (HTTP Error)**
        -   [x] Mock server returns non-200 status.
        -   [x] Verify command returns an error.
        -   [x] Verify no dependency file is created.
        -   [x] Verify `project.toml` and `almd-lock.toml` are not modified (or created if they didn't exist).
    -   [x] **Sub-Task 3.4.6: Test `almd add` - Error: `project.toml` Not Found**
        -   [x] Run `add` in a temp dir without `project.toml`.
        -   [x] Verify command returns an appropriate error.
    -   [x] **Sub-Task 3.4.7: Test `almd add` - Cleanup on Failure (e.g., Lockfile Write Error)**
        -   [x] Difficult to precisely mock file system write errors without more DI.
        -   [x] Focus on: If download happens, but a subsequent step like TOML marshaling or lockfile writing fails, does the downloaded file get removed? (This might require a test where the mock HTTP server succeeds, but we introduce an error in a subsequent, controllable step if possible, or inspect code paths for this cleanup logic). Initially, can be a lower priority if hard to test cleanly.
    -   [x] **Sub-Task 3.4.8: Fix `TestAddCommand_ProjectTomlNotFound` (2025-05-07)**
        -   [x] Modified error message in `internal/cli/add/add.go` to include "no such file or directory" when `project.toml` is not found.
        -   [x] Refactored `Action` in `internal/cli/add/add.go` to use a named return error, ensuring the deferred cleanup logic correctly removes downloaded files when `project.toml` is missing and an error is returned.
        -   [x] Corrected variable types for `proj` (to `*project.Project`) and `lf` (to `*lockfile.Lockfile`) in `internal/cli/add/add.go` to resolve compiler errors.


## Milestone 4: `remove` Command Implementation

**Goal:** Implement the `almd remove <dependency_name>` command to remove a dependency from the project.

-   [x] **Task 4.1: `urfave/cli` Command Setup**
    -   [x] Define the `remove` command structure (`cli.Command`) in `commands/remove.go` (or `internal/cli/remove/remove.go` as per PRD folder structure).
    -   [x] Add the command to the `urfave/cli` App in `main.go`.
    -   [x] Define the required `<dependency_name>` argument.
    -   [x] Manual Verification: Run `almd remove --help` and confirm the command and argument are listed correctly. Run `almd remove some-dep` and verify the argument value is accessible within the (currently empty) action.

-   [x] **Task 4.2: Implement Manifest Loading and Dependency Path Retrieval**
    -   [x] Add logic within the `remove` command's `Action` to load `project.toml` (using `internal/config`).
    -   [x] Verify if the specified `<dependency_name>` exists in the `[dependencies]` table.
    -   [x] If it exists, retrieve the relative `path` of the dependency.
    -   [x] Handle errors if `project.toml` is not found or the dependency does not exist.
    -   [x] Manual Verification: Test with an existing `project.toml`. Try removing an existing and a non-existing dependency. Check error messages.

-   [x] **Task 4.3: Implement Manifest Update and File Deletion**
    -   [x] Remove the entry for `<dependency_name>` from the `[dependencies]` table in the loaded manifest data.
    -   [x] Save the updated manifest back to `project.toml`.
    -   [x] Delete the file specified by the retrieved `path` using `os.Remove`.
    -   [x] Handle potential errors during file saving and deletion (e.g., permissions, file not found for deletion).
    -   [x] Manual Verification: Add a dependency using `almd add`. Then use `almd remove <dep_name>`. Verify `project.toml` is updated and the file is deleted. Test error conditions like read-only `project.toml` or non-existent dependency file.

-   [x] **Task 4.4: Implement Lockfile Update**
    -   [x] Load `almd-lock.toml` (using `internal/lockfile`).
    -   [x] Remove the entry for `<dependency_name>` from the `[package]` table in the loaded lockfile data.
    -   [x] Save the updated lockfile back to `almd-lock.toml`.
    -   [x] Handle errors if `almd-lock.toml` is not found or during saving. Handle cases where the dependency might not be in the lockfile even if it was in the manifest.
    -   [x] Manual Verification: After successfully running `almd add`, run `almd remove <dep_name>`. Verify `almd-lock.toml` is updated. Test with missing or read-only `almd-lock.toml`.

-   [x] **Task 4.5: Error Handling and Output**
    -   [x] Ensure robust error handling for all operations using `urfave/cli`'s error reporting (e.g., `cli.Exit`).
    -   [x] Provide clear confirmation messages for successful removal (manifest, file, lockfile).
    -   [x] Provide clear error messages for different failure scenarios.
    -   [x] Manual Verification: Test various error paths (missing files, non-existent dependency, permission issues) and check for clear, user-friendly output.

-   [x] **Task 4.6: Implement Empty Directory Cleanup**
    -   [x] After successful file deletion in `remove` (Task 4.3), check if the parent directory of the deleted file is empty.
    -   [x] If the directory is empty, delete it.
    -   [x] Repeat this process, moving upwards to parent directories, deleting them if they become empty.
    -   [x] Stop if a directory is not empty, an error occurs, or a predefined boundary (e.g., project root, `libs/`, `vendor/`) is reached.
    -   [x] Ensure directory emptiness check is robust to prevent accidental deletion of non-empty directories.
    -   [x] Manual Verification: Test scenarios where single and multiple empty parent directories are cleaned up. Test scenarios where cleanup stops appropriately. (Note: Manual verification by user is pending actual use, code implements the logic).

## Milestone 5: `remove` Command Testing

**Goal:** Implement unit tests for the `remove` command.

-   [x] **Task 5.1: Create Test File Structure for `remove`**
    -   [x] Create test file: `internal/cli/remove/remove_test.go`.
    -   [x] Implement shared test helpers if applicable (e.g., for creating temp env with `project.toml`, `almd-lock.toml`, and dummy dependency files).

-   [ ] **Task 5.2: Implement `remove` Command Unit Test Cases**
    -   [x] **Sub-Task 5.2.1: Setup for `remove` tests**
        -   [x] Define `TestMain` if any global setup/teardown for `remove` tests is needed. (Skipped for now, can be added if specific global setup is identified)
        -   [x] Create helper: `setupRemoveTestEnvironment(t *testing.T, initialProjectTomlContent string, initialLockfileContent string, depFiles map[string]string) (tempDir string)` that creates a temp dir, `project.toml`, `almd-lock.toml`, and specified dependency files.
        -   [x] Create helper: `runRemoveCommand(t *testing.T, tempDir string, cliArgs ...string) error` to set up and run the `remove` command's action.
    -   [x] **Sub-Task 5.2.2: Test `almd remove` - Successful Removal**
        -   [x] Setup: Temp dir with `project.toml`, `almd-lock.toml`, and a dummy dependency file, all correctly linked.
        -   [x] Execute: `almd remove <dependency_name>`.
        -   [x] Verify:
            -   Dependency entry removed from `project.toml`.
            -   Dependency entry removed from `almd-lock.toml`.
            -   Dependency file deleted from the filesystem.
            -   Command returns no error.
    -   [x] **Sub-Task 5.2.3: Test `almd remove` - Error: Dependency Not Found in Manifest**
        -   [x] Setup: Temp dir with `project.toml` that does not contain the target dependency.
        -   [x] Execute: `almd remove <non_existent_dependency_name>`.
        -   [x] Verify:
            -   Command returns an appropriate error.
            -   `project.toml` and `almd-lock.toml` remain unchanged.
            -   No file deletion attempted for the non-existent dependency.
           -   [x] **Sub-Task 5.2.4: Test `almd remove` - Error: Dependency File Not Found for Deletion**
            -   [x] Setup: Temp dir with `project.toml` and `almd-lock.toml` listing a dependency, but the actual dependency file is missing.
            -   [x] Execute: `almd remove <dependency_name>`.
        -   [x] Verify:
        	-   Dependency entry removed from `project.toml`.
        	-   Dependency entry removed from `almd-lock.toml`.
        	-   Command may return a warning or error about file deletion failure, but manifest/lockfile changes should persist.
        	-   PRD: "Handles potential errors gracefully (e.g., file not found, permissions)."
       -   [x] **Sub-Task 5.2.5: Test `almd remove` - Error: `project.toml` Not Found (2025-05-08 - Refined fix for CWD handling)**
        -   [x] Setup: Run `remove` in a temp dir without `project.toml`.
        -   [x] Execute: `almd remove <dependency_name>`.
        -   [x] Verify: Command returns an appropriate error.
    -   [x] **Sub-Task 5.2.6: Test `almd remove` - Dependency in Manifest but not Lockfile**
        -   [x] Setup: Temp dir with `project.toml` listing a dependency, `almd-lock.toml` exists but doesn't list it, and the dependency file exists.
        -   [x] Execute: `almd remove <dependency_name>`.
        -   [x] Verify:
            -   Dependency entry removed from `project.toml`.
            -   `almd-lock.toml` is processed (attempt to remove, no error if not found).
            -   Dependency file deleted.
            -   Command completes successfully or with a notice about the lockfile state.
    -   [x] **Sub-Task 5.2.7: Test `almd remove` - Empty `project.toml` or `almd-lock.toml` (2025-05-08 - Empty project.toml case fixed)**
        -   [x] Setup: Temp dir with empty `project.toml` and/or `almd-lock.toml`.
        -   [x] Execute: `almd remove <dependency_name>`.
        -   [x] Verify: Command returns an error indicating dependency not found (for empty `project.toml`) or handles empty lockfile gracefully, and files remain empty or unchanged.

## Milestone 6: `install` Command Implementation

**Goal:** Implement the `almd install` command to refresh dependencies based on `project.toml` and update `almd-lock.toml`.

-   [x] **Task 6.1: `urfave/cli` Command Setup for `install`**
    -   [x] Define the `install` command structure (`cli.Command`) in `internal/cli/install/install.go`.
    -   [x] Add the command to the `urfave/cli` App in `main.go`.
    -   [x] Define optional `[dependency_names...]` argument.
    -   [x] Define flags: `--force, -f` (bool), `--verbose` (bool).
    -   [x] Manual Verification: Run `almd install --help` and confirm the command, argument, and flags are listed correctly.

-   [x] **Task 6.2: Argument Parsing and Initial Loading**
    -   [x] In the `install` command's `Action`, parse optional dependency names. If none, target all.
    -   [x] Load `project.toml` (using `internal/core/config`). Handle errors if not found.
    -   [x] Load `almd-lock.toml` (using `internal/core/lockfile`). Handle if not found (treat as all dependencies needing install/addition to lockfile).
    -   [x] Manual Verification: Test with and without dependency names. Check behavior with missing manifest/lockfile.

-   [x] **Task 6.3: Dependency Iteration and Configuration Retrieval**
    -   [x] Iterate through targeted dependencies (all from `project.toml` or specified names).
    -   [x] For each dependency:
        -   [x] Retrieve its configuration (canonical `source` identifier, `path`) from `project.toml`.
        -   [x] If a specified dependency name is not found in `project.toml`, skip with a warning.
    -   [x] Manual Verification: Code review logic for iteration and config fetching. Test with a mix of valid and invalid specified dependency names.

-   [x] **Task 6.4: Target Version Resolution and Lockfile State Retrieval**
    -   [x] For each dependency:
        -   [x] Resolve its `source` from `project.toml` to a concrete downloadable raw URL and a definitive commit hash/version identifier (using `internal/source`). This involves fetching latest commit for branches/tags if necessary.
        -   [x] Retrieve its current locked state (raw `source` URL, `hash`) from `almd-lock.toml`, if an entry exists.
        -   [x] **Sub-Task 6.4.1: Support `github:owner/repo/path/to/file@ref` shorthand in `internal/source` (2025-05-08)**
            -   [x] Modified `internal/core/source/source.go`'s `ParseSourceURL` function to correctly parse the shorthand, extract components, and build the raw download URL.
    -   [x] Manual Verification: Test source resolution for branches, tags, and specific commits. Check retrieval from lockfile. Test new shorthand format.

-   [x] **Task 6.5: Comparison Logic and Update Decision**
    -   [x] For each dependency, determine if an install is required based on PRD logic:
        -   [x] Resolved target commit hash (from `project.toml` source) differs from locked commit hash.
        -   [x] Dependency in `project.toml` but missing from `almd-lock.toml`.
        -   [x] Local file at `path` is missing.
        -   [x] `--force` flag is used.
    -   [x] If none of the above, the dependency is considered up-to-date.
    -   [x] Manual Verification: Code review decision logic against PRD.

-   [x] **Task 6.6: Perform Install (If Required)**
    -   [x] For each dependency needing an install:
        -   [x] Download the file from the resolved target raw URL (using `internal/downloader`).
        -   [x] Calculate integrity hash (commit hash preferred, else SHA256 via `internal/hasher`).
        -   [x] Save the downloaded file to its `path` (from `project.toml`), creating parent directories if needed.
        -   [x] Update `almd-lock.toml`: store the exact raw download URL used, `path`, and new integrity `hash`. The `source` in `project.toml` remains (e.g., can still be a branch).
    -   [x] Manual Verification: Test a scenario where an update is performed. Check downloaded file content, path, and `almd-lock.toml` changes.

-   [x] **Task 6.7: Output and Error Handling**
    -   [x] Provide clear feedback: which dependencies checked, updated, already up-to-date.
    -   [x] Report errors clearly (e.g., download failure, source resolution failure, file write failure) via `urfave/cli`.
    -   [x] Manual Verification: Observe output for various scenarios (updates, no updates, errors).

-   [x] **Task 6.8: Fix Lint Errors in `install.go` (2025-05-08)**
    -   [x] Corrected `lf.Packages` to `lf.Package` in `internal/cli/install/install.go`.
    -   [x] Corrected type `project.LockPackageDetail` to `lockfile.PackageEntry` for lockfile map values in `internal/cli/install/install.go`.

## Milestone 7: `install` Command Testing

**Goal:** Implement unit tests for the `install` command.

-   [x] **Task 7.1: Test File Structure and Helpers for `install` (2025-05-08)**
    -   [x] Create test file: `internal/cli/install/install_test.go`.
    -   [x] Develop test helpers:
        -   [x] `setupInstallTestEnvironment(...)`: Creates temp dir, `project.toml`, `almd-lock.toml`, mock dependency files.
        -   [x] `runInstallCommand(...)`: Executes the `install` command's action with specified args and context.
        -   [x] Mock HTTP server setup (similar to `add` command tests) for controlling download responses and simulating remote changes.

-   [ ] **Task 7.2: Implement `install` Command Unit Test Cases**
    -   [x] **Sub-Task 7.2.1: Test `almd install` - All dependencies, one needs install (commit hash change) (2025-05-08)**
        -   [x] Setup: `project.toml` specifies `depA@main`. `almd-lock.toml` has `depA` at `commit1`. Mock server resolves `main` for `depA` to `commit2` and serves new content.
        -   [x] Execute: `almd install`.
        -   [x] Verify: `depA` file updated, `almd-lock.toml` updated for `depA` to `commit2`. Other up-to-date deps untouched.
    -   [x] **Sub-Task 7.2.2: Test `almd install <dep_name>` - Specific dependency install**
        -   [x] Setup: Similar to 7.2.1, but also `depB` needs update.
        -   [x] Execute: `almd install depA`.
        -   [x] Verify: Only `depA` is updated. `depB` remains as per old lockfile.
    -   [x] **Sub-Task 7.2.3: Test `almd install` - All dependencies up-to-date**
        -   [x] Setup: `project.toml` sources resolve to same commits as in `almd-lock.toml`. Local files exist.
        -   [x] Execute: `almd install`.
        -   [x] Verify: No files downloaded, no changes to `almd-lock.toml`. Appropriate "up-to-date" messages.
    -   [x] **Sub-Task 7.2.4: Test `almd install` - Dependency in `project.toml` but missing from `almd-lock.toml` (2025-05-08)**
    -   [x] Setup: `depNew` in `project.toml`, but no entry in `almd-lock.toml`.
    -   [x] Execute: `almd install`.
    -   [x] Verify: `depNew` is downloaded, file saved, and entry added to `almd-lock.toml`.
    -   [x] **Sub-Task 7.2.5: Test `almd install` - Local dependency file missing (2025-05-08)**
    -   [x] Setup: `depA` in `project.toml` and `almd-lock.toml`, but its local file is deleted.
    -   [x] Execute: `almd install depA`.
    -   [x] Verify: `depA` is re-downloaded based on `almd-lock.toml`'s pinned version (or `project.toml` if it dictates a newer one). `almd-lock.toml` reflects the version downloaded.
    -   [x] **Sub-Task 7.2.6: Test `almd install --force` - Force install on an up-to-date dependency (2025-05-08)**
        -   [x] Setup: `depA` is up-to-date.
        -   [x] Execute: `almd install --force depA`.
        -   [x] Verify: `depA` is re-downloaded and `almd-lock.toml` entry is refreshed, even if commit hash was the same.
    -   [x] **Sub-Task 7.2.7: Test `almd install <non_existent_dep>` - Non-existent dependency specified (2025-05-08)**
        -   [x] Setup: `project.toml` does not contain `non_existent_dep`.
        -   [x] Execute: `almd install non_existent_dep`.
        -   [x] Verify: Warning message printed, no other actions taken for this dep. Other valid deps (if `install` was called without args but one was invalid) should process normally.
    -   [x] **Sub-Task 7.2.8: Test `almd install` - Error during download (2025-05-08)**
        -   [x] Setup: Mock server returns HTTP error for a dependency that needs update.
        -   [x] Execute: `almd install`.
        -   [x] Verify: Command reports error for that dependency. `almd-lock.toml` and local file for that dep remain unchanged or reflect pre-update state.
    -   [x] **Sub-Task 7.2.9: Test `almd install` - Error during source resolution (e.g., branch not found) (2025-05-08)**
        -   [x] Setup: `project.toml` points to `depA@nonexistent_branch`. Mock `internal/source` to simulate resolution failure.
        -   [x] Execute: `almd install depA`.
        -   [x] Verify: Command reports error for `depA`. No download attempt.
    -   [x] **Sub-Task 7.2.10: Test `almd install` - `project.toml` not found (2025-05-08)**
        -   [x] Setup: Run `install` in a temp dir without `project.toml`.
        -   [x] Execute: `almd install`.
        -   [x] Verify: Command returns an appropriate error.

## Milestone 8: `list` Command Implementation

**Goal:** Implement the `almd list` (and `ls`) command to display project dependencies.

-   [x] **Task 8.1: `urfave/cli` Command Setup for `list` (2025-05-08)**
    -   [x] Define the `list` command structure (`cli.Command`) in `internal/cli/list/list.go`.
    -   [x] Add `ls` as an alias for the `list` command.
    -   [x] Add the command to the `urfave/cli` App in `main.go`.
    -   [x] Manual Verification: Run `almd list --help` and `almd ls --help`. Confirm command, alias, and flags are listed.

-   [x] **Task 8.2: Manifest and Lockfile Loading for `list` (2025-05-08)**
    -   [x] In the `list` command's `Action`, load `project.toml` (using `internal/core/config`). Handle if not found (print "No dependencies..." or error).
    -   [x] Load `almd-lock.toml` (using `internal/core/lockfile`). Handle if not found (dependencies will show as "not locked").
    -   [x] Manual Verification: Test with missing manifest/lockfile.

-   [x] **Task 8.3: Dependency Traversal and Information Gathering (2025-05-08)**
    -   [x] Iterate through dependencies in `project.toml`'s `[dependencies]` table.
    -   [x] For each dependency, retrieve:
        -   [x] Logical name.
        -   [x] Configured `source` from `project.toml`.
        -   [x] Relative `path` from `project.toml`.
        -   [x] Locked raw `source` URL and `hash` from `almd-lock.toml` (if present).
        -   [x] Local file existence status at `path`.
    -   [x] Manual Verification: Code review data gathering logic.

-   [x] **Task 8.4: Default Output Formatting (2025-05-08)**
    -   [x] Implement the default output format as per PRD:
        -   [x] Logical dependency name.
        -   [x] Declared `source` from `project.toml`.
        -   [x] Locked `hash` from `almd-lock.toml` (or "not locked").
        -   [x] Relative `path`.
    -   [x] Manual Verification: Run `almd list` with a sample project and check output.

-   [x] **Task 8.5: Handling Projects with No Dependencies (2025-05-08)**
    -   [x] If `project.toml` has no `[dependencies]` table or it's empty, print an appropriate message (e.g., "No dependencies found in project.toml."). This should work for all output formats (default, long, json, porcelain - e.g. empty array for json).
    -   [x] Manual Verification: Test with an empty `project.toml` or one without dependencies.

## Milestone 9: `list` Command Testing

**Goal:** Implement unit tests for the `list` command.

-   [x] **Task 9.1: Test File Structure and Helpers for `list` (2025-05-08)**
    -   [x] Create test file: `internal/cli/list/list_test.go`.
    -   [x] Develop test helpers:
        -   [x] `setupListTestEnvironment(...)`: Creates temp dir, `project.toml`, `almd-lock.toml`, and optionally dummy dependency files.
        -   [x] `runListCommand(...)`: Executes the `list` command's action, capturing its stdout.

-   [ ] **Task 9.2: Implement `list` Command Unit Test Cases**
    -   [x] **Sub-Task 9.2.1: Test `almd list` - No dependencies (2025-05-08)**
        -   [x] Setup: Empty `project.toml` or no `[dependencies]` table.
        -   [x] Execute: `almd list`.
        -   [x] Verify: Output indicates no dependencies. For `--json`, verify empty array or appropriate null structure. (Note: JSON output not yet implemented, test verifies default behavior)
    -   [x] **Sub-Task 9.2.2: Test `almd list` - Single dependency (fully installed and locked) (2025-05-08)**
        -   [x] Setup: `project.toml` with one dep, `almd-lock.toml` with corresponding entry, local file exists.
        -   [x] Execute: `almd list`.
        -   [x] Verify: Correct default output for the dependency.
    -   [x] **Sub-Task 9.2.3: Test `almd list` - Multiple dependencies with varied states (2025-05-08)**
        -   [x] Setup: Mix of deps: one fully installed, one in manifest but not lockfile, one in manifest & lockfile but file missing.
        -   [x] Execute: `almd list`.
        -   [x] Verify: Correct default output for each, reflecting their state.
    -   [x] **Sub-Task 9.2.4: Test `almd ls` (alias) - Verify alias works (2025-05-08)**
        -   [x] Setup: Basic project with one dependency.
        -   [x] Execute: `almd ls`.
        -   [x] Verify: Output is identical to `almd list`.
    -   [x] **Sub-Task 9.2.5: Test `almd list` - `project.toml` not found (2025-05-08 - Covered by existing `TestListCommand_ProjectTomlNotFound`)**
        -   [x] Setup: Run `list` in a temp dir without `project.toml`.
        -   [x] Execute: `almd list`.
        -   [x] Verify: Command returns an appropriate error or "no dependencies" message as per PRD.

## Milestone 10: `list` Command Output Enhancement

**Goal:** Update the `almd list` command output to be more informative and visually similar to `pnpm list`, including terminal colors using `fatih/color`.

-   [x] **Task 10.1: Define `list` Output Structure and Color Scheme**
    -   [x] Define pnpm-like output structure: Project info, "dependencies:" header, then `name path hash` for each. (Covered by previous Task 10.2, updated 2025-05-08)
    -   [x] Specify color scheme using `fatih/color` (inspired by user-provided image):
        -   Project Name: Magenta, Bold, Underline (`color.FgMagenta`, `color.Bold`, `color.Underline`)
        -   `@`: Standard color
        -   Project Version: Magenta (`color.FgMagenta`) (Note: User did not specify bold/underline for version, keeping as is)
        -   Project Path: Dim Gray, Bold, Underline (`color.FgHiBlack`, `color.Bold`, `color.Underline`)
        -   `dependencies:` header: Cyan and Bold (`color.FgCyan`, `color.Bold`)
        -   Dependency Name: Yellow (`color.FgYellow`)
        -   Dependency Hash: Standard color (No specific color attribute, or `color.Reset`)
        -   Dependency Path: Green (`color.FgGreen`)
    -   [x] Ensure `NO_COLOR` environment variable is respected (typically handled by `fatih/color` automatically, but verify).

-   [x] **Task 10.2: Implement Output Changes in `internal/cli/list/list.go` (Initial pnpm-like format)**
    -   [x] Load project name and version.
    -   [x] Modify print statements to match the new pnpm-like format (without colors yet).

-   [x] **Task 10.3: Implement Color Output in `internal/cli/list/list.go`**
    -   [x] Add `github.com/fatih/color` as a project dependency.
    -   [x] Import `fatih/color` in `internal/cli/list/list.go`.
    -   [x] Update print statements to use the defined color scheme via `fatih/color` functions.

-   [ ] **Task 10.4: Update `list` Command Tests (Blocked by Task 9.1, 9.2)**
    -   [ ] Adjust existing tests in `internal/cli/list/list_test.go` to expect the new pnpm-like format (initially without asserting exact color codes, as this can be brittle). (File to be created in Task 9.1)
    -   [x] Consider adding a simple manual verification step for color output. (Decision: Manual verification will be needed)
    -   [ ] Add new test cases if necessary to cover different scenarios with the new format (e.g., project with name/version, project without). (To be done in Task 9.2)
## Milestone 11: `add` and `remove` Command Output Enhancement (pnpm style) (2025-05-08)

**Goal:** Update the `almd add` and `almd remove` command outputs to be more visually similar to `pnpm`, including terminal colors using `fatih/color`.

-   [x] **Task 11.1: Update `add` command output**
    -   [x] Modify `internal/cli/add/add.go` to print output similar to `pnpm add`.
    -   [x] Use green color for added dependency information.
    -   [x] Include a "Done in Xs" message.
-   [x] **Task 11.2: Update `remove` command output**
    -   [x] Modify `internal/cli/remove/remove.go` to print output similar to `pnpm remove`.
    -   [x] Use red color for removed dependency information.
    -   [x] Include a "Done in Xs" message.
-   [x] **Task 11.3: Add `fatih/color` dependency if not already present**
    -   [x] Ensure `github.com/fatih/color` is in `go.mod`. (Already added by list command changes)
-   [ ] **Task 11.4: Manual Verification**
    -   [ ] Run `almd add <url>` and verify the output matches the pnpm style.
    -   [ ] Run `almd remove <dep_name>` and verify the output matches the pnpm style.
## Milestone 12: `self update` Command Implementation

**Goal:** Implement the `almd self update` command to allow the Almandine tool to update itself.

-   [x] **Task 12.1: `urfave/cli` Command Setup for `self update`**
    -   [x] Define the `self` command structure (`cli.Command`) in a new file (e.g., `internal/cli/self/self.go`).
    -   [x] Define the `update` subcommand within the `self` command.
    -   [x] Add the `self` command (with its `update` subcommand) to the `urfave/cli` App in `cmd/almd/main.go`.
    -   [x] Define flags for `almd self update`: `--yes`/`-y` (bool), `--check` (bool), `--source <url>` (string), `--verbose` (bool).
    -   [x] Manual Verification: Run `almd self update --help` and confirm the command, subcommand, and flags are listed correctly.

-   [x] **Task 12.2: Add Self-Update Library**
    -   [x] Add `github.com/creativeprojects/go-selfupdate` as a project dependency (`go get github.com/creativeprojects/go-selfupdate`).
    -   [x] Manual Verification: `go.mod` and `go.sum` are updated.

-   [x] **Task 12.3: Implement Version Embedding (2025-05-08)**
    -   [x] Ensure the application version is embedded at build time. This typically involves:
        -   [x] Defining a `var version string` in the `main` package (`cmd/almd/main.go`).
        -   [x] Setting this variable during the build using ldflags: `go build -ldflags="-X main.version=vX.Y.Z" ./cmd/almd`.
        -   [x] The `cli.App` `Version` field should use this variable.
    -   [x] Manual Verification: Build the binary with a version, run `almd --version`, and confirm the embedded version is printed.

-   [x] **Task 12.4: Implement Core `self update` Logic (2025-05-08)**
    -   [x] In the `update` subcommand's `Action`:
        -   [x] Retrieve the current application version (embedded in Task 12.3).
        -   [x] Use `github.com/creativeprojects/go-selfupdate` to:
            -   [x] Configure the updater (e.g., for GitHub releases, using `selfupdate.NewGitHubSource` and `selfupdate.NewUpdater`).
            -   [x] If `--check` flag is used, detect the latest version and inform the user if an update is available, then exit.
            -   [x] Detect the latest available release version.
            -   [x] Compare with the current version. If no newer version, inform the user and exit.
            -   [x] If a newer version is available, prompt for confirmation unless `--yes` is used.
            -   [x] Perform the update (download, verify, replace).
        -   [x] Handle errors gracefully (e.g., network issues, no new version, update failure).
        -   [x] Provide clear output messages throughout the process.
    -   [x] Manual Verification:
        -   [x] Test `--check` flag when an update is available and when not.
        -   [x] Test update process: with and without `--yes`.
        -   [ ] Test with no new version available.
        -   [ ] Simulate network error if possible to check error handling.

-   [ ] **Task 12.5: Testing for `self update`**
    -   [ ] **Note:** Fully automated E2E testing for self-update is complex as it involves replacing the running binary. Initial testing will likely be manual or involve carefully crafted integration tests that mock parts of the update process.
    -   [ ] Define manual test scenarios:
        -   [ ] Update from an older version to a newer version.
        -   [ ] Attempt update when already on the latest version.
        -   [ ] Use `--check` flag.
        -   [ ] Use `--yes` flag.
    -   [ ] Consider creating a simple integration test that:
        -   [ ] Mocks the `github.com/creativeprojects/go-selfupdate` library's interactions (e.g., API calls, download).
        -   [ ] Verifies the command logic (flag parsing, conditional execution based on mocked updater responses).
        -   [ ] This would not test the actual binary replacement but would cover the command's flow.

---

## Milestone 13: Core Logic Unit Testing (`internal/core`)

**Goal:** Ensure comprehensive unit test coverage for all packages within `internal/core`.

-   [x] **Task 13.1: Define Testing Strategy for `internal/core`**
    -   [x] Framework: Standard Go `testing` package with `testify` for assertions.
    -   [x] Scope: Unit tests for public functions/methods in each `internal/core` package.
    -   [x] Mocks: Use mocks for external dependencies (e.g., network, filesystem) where appropriate.
    -   [x] Structure: Test files alongside source files (e.g., `config_test.go` for `config.go` within `internal/core/config/`).
    -   [x] Manual Verification: Review strategy for completeness.

-   [x] **Task 13.2: Implement Unit Tests for `internal/core/config`**
    -   [x] Create `internal/core/config/config_test.go`.
    -   [x] Test `LoadProjectToml` (valid, not found, invalid format).
    -   [x] Test `SaveProjectToml` (writing, overwriting).
    -   [x] Manual Verification: Run `go test ./internal/core/config/...`.

-   [x] **Task 13.3: Implement Unit Tests for `internal/core/downloader` (2025-05-08)**
    -   [x] Create `internal/core/downloader/downloader_test.go`.
    -   [x] Test `DownloadFile` (success, HTTP errors, network issues) using `httptest`.
    -   [ ] Manual Verification: Run `go test ./internal/core/downloader/...`.

-   [x] **Task 13.4: Implement Unit Tests for `internal/core/hasher` (2025-05-08)**
    -   [x] Create `internal/core/hasher/hasher_test.go`.
    -   [x] Test `CalculateSHA256` with known content.
    -   [ ] Manual Verification: Run `go test ./internal/core/hasher/...`.

-   [x] **Task 13.5: Implement Unit Tests for `internal/core/lockfile` (2025-05-08)**
    -   [x] Create `internal/core/lockfile/lockfile_test.go`.
    -   [x] Test `LoadLockfile` (valid, not found, invalid format).
    -   [x] Test `SaveLockfile` (writing, overwriting).
    -   [ ] Manual Verification: Run `go test ./internal/core/lockfile/...`.

-   [x] **Task 13.6: Implement Unit Tests for `internal/core/project` (2025-05-08)**
    -   [x] Create `internal/core/project/project_test.go`.
    -   [x] Test any helper functions or methods on the `Project`, `Dependency`, `Script`, etc. structs if they contain logic beyond simple data holding. (Tested `NewProject()` constructor; other structs are data holders).
    -   [ ] Manual Verification: Run `go test ./internal/core/project/...`.

-   [x] **Task 13.7: Implement Unit Tests for `internal/core/source` (2025-05-08)**
    -   [x] Create `internal/core/source/source_test.go`.
    -   [x] Test `ParseSourceURL` with various valid and invalid GitHub URL formats (raw, blob, tree, with/without ref, shorthand).
    -   [ ] Test `GetGitHubRawURLAndCommit` (mocking `FetchLatestCommitSHA` and `FetchFileCommitSHA`). *(Note: `GetGitHubRawURLAndCommit` function not found in current `source.go`)*.
    -   [x] Create `internal/core/source/github_api_test.go`.
    -   [x] Test `GetLatestCommitSHAForFile` (mocking HTTP calls to GitHub API). *(Note: Tested existing `GetLatestCommitSHAForFile` instead of non-existent `FetchLatestCommitSHA` / `FetchFileCommitSHA`)*.
    -   [ ] Manual Verification: Run `go test ./internal/core/source/...`.

---

## Milestone 14: Test Fixes (2025-05-08)

**Goal:** Address and fix failing tests reported by `go test -v ./... -race -coverprofile=coverage.out -covermode=atomic`.

-   [x] **Task 14.1: Fix `TestRemoveCommand_ProjectTomlNotFound` in `internal/cli/remove/remove_test.go` (2025-05-08)**
    -   [x] Investigated assertion failure: `"Error: Failed to load project.toml: open project.toml: no such file or directory" does not contain "cannot find the file specified"`.
    -   [x] Updated assertion to correctly match the expected error message ("no such file or directory").
-   [x] **Task 14.2: Fix Data Races in `internal/core/source` tests (2025-05-08)**
    -   [x] Investigated data races reported for `githubAPIURL` and `testModeBypassHostValidation` in `source_test.go`, `github_api_test.go`, and `source.go`.
    -   [x] Implemented synchronization using exported mutexes (`GithubAPIBaseURLMutex`, `TestModeBypassHostValidationMutex`) in the `source` package to protect shared global variables accessed by parallel tests. Updated `github_api.go`, `source.go`, and `source_test.go` to use these mutexes. (Attempt 1)
    -   [x] Added a package-level mutex (`githubAPITestMutex`) in `internal/core/source/github_api_test.go` to serialize test functions that call `setupSourceTest` or otherwise modify shared global state in the `source` package. Removed `t.Parallel()` from these specific test functions. (Attempt 2 - 2025-05-08)
-   [x] **Task 14.3: Fix Path Mismatch Failures in `internal/cli/list/list_test.go` (2025-05-08)**
    -   [x] Investigated failures in `TestListCommand_SingleDependencyFullyInstalledAndLocked`, `TestListCommand_MultipleDependenciesVariedStates`, and `TestListCommand_AliasLs` due to `/private/var` vs `/var` path differences on macOS.
    -   [x] Updated tests to use `filepath.EvalSymlinks` on the temporary directory path before constructing expected output strings, ensuring canonical paths are compared.
-   [x] **Task 14.4: Fix `TestCalculateSHA256_DifferentContent` in `internal/core/hasher/hasher_test.go` (2025-05-09)**
    -   [x] Investigated assertion failures where actual calculated SHA256 hashes did not match expected hashes.
    -   [x] Corrected the `expectedHash1` and `expectedHash2` values in `internal/core/hasher/hasher_test.go` to match the actual correct SHA256 hashes for the test strings "almandine-rocks" and "almandine-rules".
## Milestone 15: Dev Environment Configuration (2025-05-09)

**Goal:** Configure the development environment.

-   [x] **Task 15.1: Add `gitingest` to `devenv.nix` (2025-05-09)**
    -   [x] Added `languages.python` configuration to `devenv.nix`.
    -   [x] Enabled Python virtual environment (`venv.enable = true`).
    -   [x] Added `gitingest` to `venv.requirements`.
    -   [x] Manual Verification: Run `devenv shell` and confirm `gitingest` command is available.

-   [x] **Task 15.2: Fix `pre-commit-hooks` deprecated stage warning (2025-05-10)**
    -   [x] Ran `pre-commit autoupdate --repo https://github.com/pre-commit/pre-commit-hooks`.
    -   [x] Verified `.pre-commit-config.yaml` updated to `rev: v5.0.0` for `pre-commit-hooks`.
---

## Milestone 16: Code Standards Application (2025-05-09)

**Goal:** Ensure code comments adhere to defined project standards.

-   [x] **Task 16.1: Apply comment standards to `internal/cli/remove/remove_test.go` (2025-05-09)**
    -   [x] Reviewed comments in `internal/cli/remove/remove_test.go` against `project/COMMENT_STANDARDS.txt`.
    -   [x] Removed obvious "what" comments.
    -   [x] Retained godoc comments and comments explaining test setup or "why".
---

## Milestone 17: Refactoring and Cleanup (2025-05-09)

**Goal:** Improve code quality, maintainability, and reduce complexity in existing modules.

-   [x] **Task 17.1: Refactor `internal/cli/add/add.go` (2025-05-09)**
    -   [x] Break down the main `Action` function in `AddCmd` into smaller, focused helper functions (e.g., for arg parsing, URL handling, file operations, manifest updates, lockfile updates).
    -   [x] Simplify the error handling and cleanup logic, potentially by returning errors more consistently and centralizing cleanup.
    -   [x] Encapsulate filename determination logic (for manifest and disk) into a separate function.
    -   [x] Encapsulate integrity hash determination logic into a separate function.
    -   [x] Review and improve overall clarity and reduce nesting in the `Action` function.

-   [x] **Task 17.2: Refactor `internal/cli/install/install.go` (2025-05-09)**
    -   [x] Break down the main `Action` function in `InstallCmd` into smaller, manageable functions (e.g., for determining deps to process, resolving single dep state, deciding on action, performing install/update for a single dep).
    -   [x] Consider refactoring the management of `dependencyInstallState` into a dedicated helper or struct with methods. (Decision: Kept as local types for now, helper functions manage transitions).
    -   [x] Review and improve overall clarity and reduce nesting in the `Action` function.

-   [x] **Task 17.3: Refactor `internal/core/source/source.go` (2025-05-09)**
    -   [x] Break down the `ParseSourceURL` function into smaller helper functions for different URL types (e.g., `parseGitHubShorthandURL`, `parseGitHubFullURL`, `parseRawGitHubUserContentURL`).
    -   [x] Review the usage of `testModeBypassHostValidation` and its mutex for clarity and safety.

-   [ ] **Task 17.4: Consolidate CLI Test Helpers (2025-05-09)**
    -   [ ] Identify common test helper functions in `internal/cli/*/ *_test.go` files (e.g., `setup...TestEnvironment`, `run...Command`, `startMockServer`, `readProjectToml`, `readAlmdLockToml`).
    -   [ ] Create a shared internal test utility package (e.g., `internal/testutil` or `internal/cli/testhelper`).
    -   [ ] Move common helpers to this shared package and update tests to use them.

-   [x] **Task 17.5: Standardize Error Handling in CLI Commands (2025-05-09)**
    -   [x] Review error handling and cleanup strategies in `add.go`, `remove.go`, and `install.go`.
    -   [x] Define and apply a consistent approach for reporting errors to the user (via `cli.Exit` or other means).
    -   [x] Ensure that partial changes are appropriately handled (e.g., cleanup of downloaded files if subsequent manifest/lockfile updates fail).

-   [x] **Task 17.6: Review Installer Scripts (`install.ps1`, `install.sh`) (2025-05-09)**
    -   [x] Review `install.ps1` and `install.sh` for clarity, robustness, and potential areas for simplification.
        -   Both scripts are generally clear, robust, and maintainable.
        -   Key finding: Both scripts download the full source archive and extract the binary/necessary files.
        -   Recommendation: Standardize by downloading pre-compiled release assets from GitHub Releases for the target OS/architecture. This aligns with common practice and the `self-update` mechanism, simplifies scripts, and reduces download size.
        -   `install.ps1`: Downloads source, expects `almd.exe` in extracted root.
        -   `install.sh`: Downloads source, expects `install/almd` (executable) and `src/` (copied to `$APP_HOME`).
        -   The role and content of `$APP_HOME` should be consistent based on `almd`'s runtime needs. If `almd` is a self-contained binary, `$APP_HOME` might only be for user-generated config/data.
    -   [x] Document any shared logic or installation philosophy to ensure consistency if one script is updated.
        -   Shared philosophy: Install latest/specific version from GitHub or local build, place executable in PATH, use temp dirs, advise on PATH configuration.
    -   [x] Consider if any parts of the scripts could be made more maintainable.
        -   Current maintainability is good. Switching to release assets would be the main improvement.
        -   Minor: `ps1` could improve `curl/wget` exit code checks. `sh` could use `jq` for API parsing if available and improve `wget` error checks.

---

## Milestone 18: GitHub Actions Release Workflow (2025-05-10)

**Goal:** Create a GitHub Action workflow to automate the building and releasing of Almandine.

-   [x] **Task 18.1: Create GitHub Action for Releases**
    -   [x] Define workflow trigger (e.g., manual `workflow_dispatch`).
    -   [x] Implement versioning logic:
        -   [x] Start at `0.2.0-alpha.1`.
        -   [x] Fetch existing tags to determine the current latest version.
        -   [x] Auto-increment pre-release number (e.g., `0.2.0-alpha.1` -> `0.2.0-alpha.2`).
        -   [x] Handle promotion from alpha to beta, rc, and final release (e.g., `0.2.0-alpha.N` -> `0.2.0-beta.1` -> `0.2.0-rc.1` -> `0.2.0`).
    -   [x] Implement build steps for Windows, macOS, and Linux using Go cross-compilation.
        -   [x] Ensure `main.version` is correctly embedded using ldflags.
    -   [x] Create release artifacts (e.g., zipped binaries).
    -   [x] Create a Git tag for the new version.
    -   [x] Create a GitHub Release, attaching artifacts and generating basic release notes.
    -   [x] Document how to use the release workflow.
        -   **Usage Instructions:**
            1.  Navigate to the "Actions" tab in your GitHub repository.
            2.  Under "Workflows", find and select "Create Release".
            3.  Click the "Run workflow" button.
            4.  Choose the `bump_type` from the dropdown:
                *   `alpha`: Increments or starts an alpha version (e.g., `v0.2.0-alpha.1` -> `v0.2.0-alpha.2`, or `v0.2.0` -> `v0.2.0-alpha.1`). Use this for the very first release if no `v0.2.0-alpha.X` tags exist.
                *   `beta`: Increments or starts a beta version (e.g., `v0.2.0-alpha.2` -> `v0.2.0-beta.1`).
                *   `rc`: Increments or starts a release candidate (e.g., `v0.2.0-beta.1` -> `v0.2.0-rc.1`).
                *   `promote_to_final`: Promotes the latest pre-release to a final version (e.g., `v0.2.0-rc.1` -> `v0.2.0`).
                *   `patch`: Bumps the patch version of the latest final release (e.g., `v0.2.0` -> `v0.2.1`).
                *   `minor`: Bumps the minor version of the latest final release (e.g., `v0.2.1` -> `v0.3.0`).
                *   `major`: Bumps the major version of the latest final release (e.g., `v0.3.0` -> `v1.0.0`).
            5.  Decide if the release should be a `draft_release` (Yes/No).
            6.  Click "Run workflow".
            7.  The action will:
                *   Determine the next version based on existing tags and the chosen `bump_type`.
                *   Build binaries for Linux (amd64, arm64), macOS (amd64, arm64), and Windows (amd64).
                *   Create a new Git tag with the determined version.
                *   Create a GitHub Release with the new tag, attaching the built binaries.
            8.  **Important:** Ensure your `main.version` variable in `cmd/almd/main.go` is correctly set up to be populated by `ldflags` during the build process (e.g., `var version string` in the main package, and `cli.App{ Version: version, ...}`). The workflow uses `go build -ldflags="-X main.version=$VERSION"`.
            9.  The initial release, if no tags like `v0.2.0-alpha.X` exist, should be triggered with `bump_type: alpha`. This will create `v0.2.0-alpha.1`.
-   [x] **Task 18.2: Fix Release Workflow Build and Versioning (2025-05-11)**
    -   [x] **`go build` Linker Error:**
        -   Problem: Version string with spaces/special characters (e.g., `v0.2.0-('alpha', 1)`) caused `go build` linker error in `release.yml`.
        -   Solution: Added single quotes around `'main.version=$VERSION'` within the `-ldflags` argument in `.github/workflows/release.yml`.
    -   [x] **Version Increment/Format:**
        -   Problem: `.github/scripts/determine_next_version.py` produced incorrect version format like `v0.2.0-('alpha', 1)` and did not correctly increment pre-release numbers.
        -   Solution: Modified the script to use string-based prerelease identifiers (e.g., `prerelease='alpha.1'`) for `semver.VersionInfo`, ensuring correct format and increment behavior.

---

---

## Milestone 19: SLSA Provenance Generation (2025-05-11)

**Goal:** Implement SLSA Level 3+ provenance generation for Go binaries.

-   [ ] **Task 19.1: Create SLSA Go Builder Configuration Files**
    -   [x] Create `.slsa-goreleaser/linux-amd64.yml`
    -   [x] Create `.slsa-goreleaser/linux-arm64.yml`
    -   [x] Create `.slsa-goreleaser/windows-amd64.yml`
    -   [x] Create `.slsa-goreleaser/darwin-amd64.yml`
    -   [x] Create `.slsa-goreleaser/darwin-arm64.yml`
-   [ ] **Task 19.2: Create GitHub Workflow for SLSA Provenance**
    -   [x] Create `.github/workflows/slsa-provenance.yml`
    -   [x] Define triggers (`push` tags `v*`, `workflow_dispatch`).
    -   [x] Implement `generate_provenance_args` job to determine version, commit, date, tree state, and release parameters.
    -   [x] Implement `build_with_provenance` job using matrix for platforms.
    -   [x] Call reusable SLSA Go builder `slsa-framework/slsa-github-generator/.github/workflows/builder_go_slsa3.yml@v2.1.0`.
    -   [x] Pass necessary inputs: `go-version`, `config-file`, `evaluated-envs`, `upload-assets`, `upload-tag-name`, `prerelease`, `draft-release`.
    -   [x] Ensure correct permissions are set (`id-token: write`, `contents: write`, `actions: read`).
-   [ ] **Task 19.3: Verify SLSA Provenance Generation**
    -   [ ] Trigger the workflow manually or by pushing a test tag.
    -   [ ] Verify that provenance files (`.intoto.jsonl`) are generated for each binary.
    -   [ ] Verify that binaries and provenance files are uploaded to a GitHub release.
    -   [ ] (Optional) Use `slsa-verifier` to verify the generated provenance against the binary.

---
## Milestone 19: README Updates (2025-05-11)

**Goal:** Keep the project README.md up-to-date with relevant information.
---

## Milestone 20: Installer Script Fixes (2025-05-11)

**Goal:** Address issues in the installer scripts.

- [x] **Task 20.1: Fix Windows Installer Script (`install.ps1`) (2025-05-11)**
    - [x] Modified `install.ps1` to download the specific Windows release asset (e.g., `almd_VERSION_windows_amd64.zip`) instead of the full source code archive.
    - [x] Updated extraction logic to expect `almd.exe` at the root of the downloaded zip.
    - [x] This resolves the "Could not find extracted directory" error during installation.

- [x] **Task 20.2: Fix PowerShell variable syntax in `install.ps1` (2025-05-11)**
    - [x] Corrected variable expansion for `$TmpDir` in `Write-Host` command on line 96 of [`install.ps1`](install.ps1:96) to `${TmpDir}` to prevent parsing errors.
- [x] **Task 19.1: Add Installation Section to README.md (2025-05-11)**
    - [x] Added a new "ğŸš€ Installation" section to `README.md`.
    - [x] Included `curl` command for macOS/Linux and `powershell` command for Windows to download and run installer scripts from the `main` branch on GitHub.
    - [x] Ensured URLs point to `https://raw.githubusercontent.com/nightconcept/almandine/main/install.sh` and `https://raw.githubusercontent.com/nightconcept/almandine/main/install.ps1`.
    - [x] Placed the new section after "Features" and before "Requirements".
## Miscellaneous Tasks
## Milestone 21: Release Asset Signing (2025-05-11)

**Goal:** Ensure release assets are GPG signed and the signing script is functional.

- [ ] **Task 21.1: Debug and Fix `scripts/sign_releases.py` (2025-05-11)**
    - [ ] Investigate why the script appears stuck during execution.
    - [ ] Identify and resolve any issues preventing interactive input or script completion.
    - [ ] Ensure the script can successfully sign and upload asset signatures.

- [x] **Task Misc.1: Create SECURITY.md (2025-05-11)**
    - [x] Create `SECURITY.md` in the root directory.
    - [x] Ensure content meets requirements for vulnerability reporting, disclosure policy, contact links, keywords (vulnerability, disclosure), and time references.



================================================
File: scripts/README.md
================================================
# Release Signing Script (`sign_releases.py`)

This Python script automates the process of cryptographically signing GitHub release artifacts for a specified repository and re-uploading them along with their `.asc` signature files. This helps meet the OpenSSF "Signed-Releases" criteria by attesting to the provenance of the artifacts.

## Prerequisites

1.  **Python 3:** Ensure you have Python 3 installed on your system.
2.  **GnuPG (GPG):** GPG must be installed, and you need to have a GPG key pair generated and configured. The script will attempt to use the first available secret key suitable for signing.
3.  **Python Libraries:** Install the necessary Python libraries using pip:
    ```bash
    pip install requests python-gnupg
    ```
4.  **GitHub Personal Access Token:** You will need a GitHub Personal Access Token.
    *   **Permissions:** The token requires the `repo` scope (or `public_repo` if your repository is public and you only need to access/modify public releases).
    *   **Usage:** The script will prompt for this token if it's not provided via the `--github-token` command-line argument or the `GITHUB_TOKEN` environment variable.

## How to Run

1.  Navigate to the `scripts` directory within your project (e.g., `cd /path/to/your/project/scripts`).
2.  Execute the script from your terminal:

    ```bash
    python sign_releases.py OWNER/REPOSITORY_NAME
    ```
    Replace `OWNER/REPOSITORY_NAME` with the target repository (e.g., `nightconcept/almandine`).

### Command-Line Arguments

*   `repo` (Required): The repository name in `owner/repo` format (e.g., `nightconcept/almandine`).
*   `--github-token YOUR_GITHUB_TOKEN` (Optional): Your GitHub Personal Access Token. If not provided, the script will try to read it from the `GITHUB_TOKEN` environment variable or prompt you to enter it.
*   `--gpg-program /path/to/gpg` (Optional): Specify the full path to your GPG executable if it's not in your system's PATH (default is `gpg`).
*   `--num-releases N` (Optional): The number of recent releases to process. Defaults to `5`. The maximum is 30 (a GitHub API limit for some queries, and the OpenSSF check looks at the 30 most recent).
*   `--skip-already-signed` (Optional): If this flag is present, the script will skip processing an asset if a corresponding `.asc` signature file already exists in the release assets.
*   `--yes` (Optional): If this flag is present, the script will automatically confirm actions (like signing and uploading) without prompting the user. Use with caution.

### Script Behavior

When executed, the script will:
1.  Prompt for your GitHub Personal Access Token if not provided via argument or environment variable.
2.  Prompt for your GPG key passphrase (if your key is passphrase-protected).
3.  Identify the first available GPG secret key suitable for signing.
4.  Fetch the specified number of recent releases from the target GitHub repository.
5.  For each release:
    a.  Iterate through its assets.
    b.  Skip any files that appear to be existing signature files (e.g., `.asc`, `.sig`).
    c.  If `--skip-already-signed` is used, skip assets that already have a corresponding `.asc` signature uploaded.
    d.  Prompt for confirmation to sign and re-upload each eligible asset (unless `--yes` is used).
    e.  Download the asset to a temporary local directory.
    f.  Sign the downloaded asset using the identified GPG key, creating a detached signature file (`.asc`).
    g.  Upload the newly created `.asc` signature file to the GitHub release.
    h.  Clean up the temporary downloaded asset and signature file.
6.  Provide logging output for all actions and any errors encountered.

## Important Considerations

*   **GPG Key Selection:** The script automatically selects the first GPG secret key it finds that is suitable for signing. Ensure the desired key is available to GPG.
*   **Idempotency:** The `--skip-already-signed` flag helps prevent re-processing assets that have already been signed and had their signatures uploaded.
*   **Error Handling:** The script includes logging and attempts to handle common errors related to GitHub API interactions, GPG operations, and file system actions.
*   **Security:**
    *   Be cautious when entering your GitHub token and GPG passphrase.
    *   Avoid hardcoding sensitive credentials directly into scripts or committing them to version control. Using environment variables or interactive prompts (as the script does) is preferred.
*   **API Rate Limits:** While the script processes releases and assets one by one, be mindful of GitHub API rate limits if you are processing a very large number of releases or assets frequently.
*   **Manual Testing:** It is highly recommended to first test this script on a fork or a test repository with a few sample releases to ensure it behaves as expected with your GPG setup and GitHub token before running it on your main project repository.


================================================
File: scripts/sign_releases.py
================================================
import os
import requests
import gnupg
import getpass
import json
import argparse
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Constants
GITHUB_API_URL = "https://api.github.com"
RELEASES_PER_PAGE = 30 # Max allowed by GitHub API for releases, check looks for 30 most recent
SIGNATURE_EXTENSIONS = [".minisig", ".asc", ".sig", ".sign", ".sigstore", ".intoto.jsonl"]

def get_github_releases(repo_owner, repo_name, token, num_releases_to_check):
    """Fetches the specified number of releases from GitHub."""
    releases = []
    page = 1
    while len(releases) < num_releases_to_check:
        url = f"{GITHUB_API_URL}/repos/{repo_owner}/{repo_name}/releases?per_page={RELEASES_PER_PAGE}&page={page}"
        headers = {"Authorization": f"token {token}"}
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            current_page_releases = response.json()
            if not current_page_releases:
                break # No more releases
            releases.extend(current_page_releases)
            if len(current_page_releases) < RELEASES_PER_PAGE:
                break # Last page
            page += 1
        except requests.exceptions.RequestException as e:
            logging.error(f"Error fetching releases: {e}")
            return None
        if len(releases) >= num_releases_to_check:
            break
    return releases[:num_releases_to_check]

def download_asset(asset_url, asset_name, token):
    """Downloads a release asset."""
    headers = {"Authorization": f"token {token}", "Accept": "application/octet-stream"}
    try:
        logging.info(f"Downloading asset: {asset_name} from {asset_url}")
        response = requests.get(asset_url, headers=headers, stream=True)
        response.raise_for_status()
        with open(asset_name, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        logging.info(f"Successfully downloaded {asset_name}")
        return asset_name
    except requests.exceptions.RequestException as e:
        logging.error(f"Error downloading asset {asset_name}: {e}")
        return None

def sign_file(gpg, filepath, keyid, passphrase):
    """Signs a file using GPG and creates a detached signature."""
    signature_file = f"{filepath}.asc"
    try:
        logging.info(f"Signing file: {filepath} with key ID {keyid}")
        with open(filepath, 'rb') as f:
            status = gpg.sign_file(f, keyid=keyid, detach=True, output=signature_file, passphrase=passphrase)

        # Check if the signing was successful.
        # The 'status' object from python-gnupg has a 'status' attribute (string)
        # and 'stderr'. Success is typically indicated by status.status == 'signature created'.
        if status and hasattr(status, 'status') and status.status == 'signature created':
            logging.info(f"Successfully signed {filepath}, signature: {signature_file}")
            return signature_file
        else:
            # Log GPG's actual status and stderr for diagnostics
            gpg_status_msg = getattr(status, 'status', 'N/A (status object might be None or lack status attribute)')
            gpg_stderr_msg = getattr(status, 'stderr', 'N/A (status object might be None or lack stderr attribute)')
            logging.error(f"Error signing file {filepath}: GPG status '{gpg_status_msg}', stderr: '{gpg_stderr_msg}'")
            if os.path.exists(signature_file): # Clean up partial signature
                os.remove(signature_file)
            return None
    except Exception as e:
        logging.error(f"Exception during signing of {filepath}: {e}")
        if os.path.exists(signature_file):
            os.remove(signature_file)
        return None

def upload_asset(upload_url_template, filepath, token):
    """Uploads an asset to a GitHub release."""
    asset_name = os.path.basename(filepath)
    # GitHub's upload_url includes path parameters like {?name,label}, remove them.
    upload_url = upload_url_template.split('{')[0] + f"?name={asset_name}"
    headers = {
        "Authorization": f"token {token}",
        "Content-Type": "application/octet-stream"
    }
    try:
        logging.info(f"Uploading asset: {asset_name} to {upload_url}")
        with open(filepath, 'rb') as f:
            response = requests.post(upload_url, headers=headers, data=f)
        response.raise_for_status()
        logging.info(f"Successfully uploaded {asset_name}")
        return response.json()
    except requests.exceptions.RequestException as e:
        logging.error(f"Error uploading asset {asset_name}: {e}")
        if response:
            logging.error(f"Response content: {response.text}")
        return None
    except Exception as e:
        logging.error(f"An unexpected error occurred during upload of {asset_name}: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description="Sign GitHub release artifacts and re-upload them with signatures.")
    parser.add_argument("repo", help="Repository name in 'owner/repo' format (e.g., nightconcept/almandine).")
    parser.add_argument("--github-token", help="GitHub Personal Access Token. If not provided, will try to read from GITHUB_TOKEN env var or prompt.")
    parser.add_argument("--gpg-program", default="gpg", help="Path to GPG executable (if not in PATH).")
    parser.add_argument("--num-releases", type=int, default=5, help="Number of recent releases to process (max 30).")
    parser.add_argument("--skip-already-signed", action='store_true', help="Skip assets if a corresponding signature file already exists in the release.")
    parser.add_argument("--yes", action='store_true', help="Automatically confirm actions without prompting.")

    args = parser.parse_args()

    repo_owner, repo_name = args.repo.split('/')
    num_releases_to_check = min(args.num_releases, 30) # Cap at 30

    github_token = args.github_token or os.environ.get("GITHUB_TOKEN")
    if not github_token:
        github_token = getpass.getpass("Enter GitHub Personal Access Token: ")

    gpg = gnupg.GPG(gpgbinary=args.gpg_program)

    # Find the first available GPG secret key suitable for signing
    secret_keys = gpg.list_keys(secret=True)
    signing_key = None
    for key in secret_keys:
        for uid_details in key.get('uids', []):
            # A simple check, might need refinement based on GPG key capabilities
            if 'S' in key.get('cap', ''): # Check if key has signing capability
                signing_key = key
                break
        if signing_key:
            break

    if not signing_key:
        logging.error("No suitable GPG secret key found for signing. Please ensure you have a GPG key with signing capability.")
        logging.info("Available secret keys (if any):")
        for skey in secret_keys:
             logging.info(f"  KeyID: {skey['keyid']}, UIDs: {skey.get('uids', 'N/A')}, Capabilities: {skey.get('cap', 'N/A')}")
        return

    gpg_key_id = signing_key['keyid']
    logging.info(f"Using GPG Key ID: {gpg_key_id} ({signing_key.get('uids', ['No UID'])[0]}) for signing.")

    gpg_passphrase = getpass.getpass(f"Enter GPG passphrase for key {gpg_key_id} (leave blank if none): ")

    logging.info(f"Fetching last {num_releases_to_check} releases for {repo_owner}/{repo_name}...")
    releases = get_github_releases(repo_owner, repo_name, github_token, num_releases_to_check)

    if not releases:
        logging.info("No releases found or error fetching releases.")
        return

    for release in releases:
        release_name = release.get('name', release['tag_name'])
        logging.info(f"\nProcessing release: {release_name} (ID: {release['id']}, Tag: {release['tag_name']})")

        if 'assets' not in release or not release['assets']:
            logging.info(f"No assets found for release {release_name}.")
            continue

        upload_url_template = release['upload_url']
        existing_asset_names = {asset['name'] for asset in release['assets']}

        for asset in release['assets']:
            asset_name = asset['name']
            asset_url = asset['browser_download_url'] # This is the public URL, need API URL for download
            asset_api_url = asset['url'] # API URL for asset details and download

            # Skip if it's already a signature file
            if any(asset_name.endswith(ext) for ext in SIGNATURE_EXTENSIONS):
                logging.info(f"Skipping signature file: {asset_name}")
                continue

            # Skip if --skip-already-signed and signature exists
            signature_filename_asc = f"{asset_name}.asc"
            if args.skip_already_signed and signature_filename_asc in existing_asset_names:
                logging.info(f"Signature {signature_filename_asc} already exists for {asset_name}. Skipping.")
                continue

            if not args.yes:
                confirm = input(f"Sign and re-upload asset '{asset_name}' for release '{release_name}'? (y/N): ")
                if confirm.lower() != 'y':
                    logging.info(f"Skipping asset {asset_name} by user choice.")
                    continue

            downloaded_file_path = None
            signed_file_path = None
            temp_dir = f"temp_release_assets_{release['id']}"
            os.makedirs(temp_dir, exist_ok=True)

            original_asset_path_in_temp = os.path.join(temp_dir, asset_name)

            try:
                downloaded_file_path = download_asset(asset_api_url, original_asset_path_in_temp, github_token)
                if not downloaded_file_path:
                    continue

                signed_file_path = sign_file(gpg, downloaded_file_path, gpg_key_id, gpg_passphrase)
                if not signed_file_path:
                    continue

                # Upload original asset (if it was somehow modified or to ensure it's there)
                # This is generally not needed if we are just adding signatures,
                # but could be part of a "refresh" flow. For now, we assume original is fine.
                # If the workflow is to replace, then we'd upload downloaded_file_path.
                # For now, we only upload the signature.

                # Upload signature
                logging.info(f"Uploading signature {os.path.basename(signed_file_path)}...")
                upload_asset(upload_url_template, signed_file_path, github_token)

            finally:
                # Clean up temporary files
                if downloaded_file_path and os.path.exists(downloaded_file_path):
                    os.remove(downloaded_file_path)
                if signed_file_path and os.path.exists(signed_file_path):
                    os.remove(signed_file_path)
                if os.path.exists(temp_dir) and not os.listdir(temp_dir): # Remove dir if empty
                    os.rmdir(temp_dir)
                elif os.path.exists(temp_dir) and os.listdir(temp_dir):
                    logging.warning(f"Temporary directory {temp_dir} is not empty after processing asset {asset_name}. Manual cleanup may be required.")


    logging.info("\nScript finished.")

if __name__ == "__main__":
    main()







================================================
File: .github/copilot-instructions.md
================================================
# AI Project Guidelines (Condensed)

**Objective:** Define mandatory process, coding, testing, and interaction standards for AI assistance.

## 1. Preparation

* **Project Context (Session Start):** ALWAYS review key project docs: `project/PRD.md` (architecture, goals, tech stack, versions, structure, style guide), `project/digest.txt` (current state summary), `project/TASKS.md` (assignments).
* **Task Prep (Before Work):**
    * ALWAYS consult `project/TASKS.md` for your assignment. If missing, add it (concise description, `YYYY-MM-DD`).
    * ALWAYS review relevant existing code *before* suggesting changes.

## 2. Implementation Planning

**Present this plan before providing code for a task:**

* Problem description (brief).
* Solution overview (high-level).
* Implementation steps (list).
* Risks/Challenges (foreseen).

## 3. Development Workflow

* **Plan First:** Present plan (Sec 2) before coding.
* **Focus:** Target the specific task from `TASKS.md`. No unrelated refactoring unless tasked.
* **Modification Approach:**
    * Prioritize minimal, incremental, clean, elegant, idiomatic changes.
    * Explain significant suggestions (Sec 5.4).
    * Propose beneficial low-risk refactoring.
    * Avoid duplication; use helpers/modules.
    * Explain use of language strengths/pitfalls if relevant.
* **Dependencies:** No new/updated external dependencies without explicit maintainer approval (check `project/PRD.md` for approved stack/versions). Use only approved dependencies.
* **Commits (User Task):** Follow Conventional Commits (`https://www.conventionalcommits.org/en/v1.0.0/`).
* **Manual Testing:** Provide clear user instructions for manually testing the task's changes.

## 4. Folder Structure

* **Strict Adherence:** Follow structure defined in `project/PRD.md`.
* **Changes:** No adding/removing/relocating files/dirs without prior maintainer approval. Approved structure changes require updating `project/PRD.md` *before* implementation.
* **Source Location:** All source code must be in `src/`.
* **Precedence:** This rule is foundational.

## 5. Coding Standards

### 5.1. General & Robustness

* Follow language best practices unless overridden by `project/PRD.md` or these guidelines.
* Prioritize: Clarity, maintainability, efficiency.
* Consider performance & basic security.
* Implement robust error handling (language norms or `PRD.md` spec); handle errors gracefully.

### 5.2. Modularity & Structure

* Keep files focused (ideally < 500 lines); refactor large ones.
* Prefer small, single-purpose functions.
* Structure code logically (per `project/PRD.md`) into modules.
* Use clear, consistent imports (relative for local packages). Verify paths.

### 5.3. Style & Formatting

* **Priority:** 1) `project/PRD.md`, 2) These rules, 3) Language common practices.
* **Type Hinting:** Mandatory for functions/classes/modules (dynamic languages).
* **Indentation:** 2 spaces.
* **Function Calls:** No space: `func()` not `func ()`.
* **Line Structure:** Avoid collapsing statements if clarity suffers.
* **Scope:** Default local. More descriptive names for wider scope. Avoid single-letter vars (except iterators/tiny scope; `i` only for loops). Use `_` for ignored vars.
* **Casing:** Match current file style; else language common style. `UPPER_CASE` for constants only.
* **Booleans:** Prefer `is_` prefix for boolean functions.
* **File Headers:** Top comment: Title (descriptive, not filename) + brief purpose. No version/OS info.

### 5.4. Documentation & Comments

* **Docstrings:** Required for public functions, classes, modules (standard format).
* **Code Comments:** Explain non-obvious logic, complex algorithms, decisions (*why*, not *what*).
* **Reasoning Comments:** Use `# Reason:` for complex block rationale.
* **README Updates:** Update `project/README.md` for core features, dependency changes, or setup/build modifications.

## 6. Testing

* **Goal:** Tests are living documentation specifying behavior. Use common language framework.
* **Behavior Specification:** Tests specify behavior. Type/scope/timing (e.g., E2E, Unit, Integration) defined in `project/PRD.md` per project phase.
* **Location:** Place tests in `/src/test` (Lua: `/src/spec`), mirroring `src/` structure (Sec 4).
    * Ex: Tests for `src/engine/mod.js` -> `src/test/engine/mod_test.js`.
    * Ex: Lua spec for `src/engine/mod.lua` -> `src/spec/engine/mod_spec.lua`.
* **Content:** Tests clearly describe expected behavior per `PRD.md` goals for the current phase.
    * **Prototype Phase:** Primary focus on automated E2E tests validating core functionality.
* **Strategy & Coverage:** Defined in `PRD.md`, evolves with phases.
    * **Prototype Phase:** E2E priority. Comprehensive unit tests & code coverage metrics (e.g., 100% statement coverage) are **not** the focus *unless* specified in `project/PRD.md` for a later phase demanding them.
* **Updating Tests:** Review/update tests with code changes to reflect *current* expected behavior. Fix failing/outdated tests promptly.

## 7. AI Interaction Protocols

### 7.1. Engineering Role & Audience

* **Role:** Act as a **Senior Software Engineer**.
* **Audience:** Target **Mid-Level Software Engineers** (code = best practices, clear, documented; explanations thorough; justify complex choices).

### 7.2. Interaction Guidelines

* Ask clarifying questions if needed; do not assume.
* Verify facts (libs, APIs, file paths); do not invent. Use MCP servers if available.
* Do not delete/overwrite code unless instructed or part of the defined task.
* Report significant blockers/errors *during* implementation promptly with context and suggestions.
* If a task seems complex, state potential benefit from a more advanced model **boldly** at the start (e.g., "**Suggestion: This complex refactoring might benefit from a more advanced model.**").
* Be friendly, helpful, collaborative.
* Explicitly state when task requirements are met. Mark task complete in `project/TASKS.md`.


================================================
File: .github/dependabot.yml
================================================
version: 2
updates:
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      # Check for updates to GitHub Actions every week
      interval: "weekly"

  - package-ecosystem: gomod
    directory: /
    schedule:
      interval: daily



================================================
File: .github/scripts/determine_next_version.py
================================================
import os
import subprocess
import semver
import sys

def get_tags():
    try:
        result = subprocess.run(['git', 'tag', '-l', 'v*', '--sort=v:refname'], capture_output=True, text=True, check=True)
        tags = result.stdout.strip().split('\n')
        return [tag for tag in tags if tag] # Filter out empty strings if any
    except subprocess.CalledProcessError as e:
        print(f"Error fetching tags: {e}", file=sys.stderr)
        return []

def get_latest_semver(tags):
    latest_v = None
    for tag_str in reversed(tags): # Iterate from newest to oldest based on git sort
        try:
            v = semver.VersionInfo.parse(tag_str[1:]) # Remove 'v' prefix
            if latest_v is None or v > latest_v:
                latest_v = v
        except ValueError:
            # Not a valid semver tag, skip
            continue
    return latest_v

def main():
    bump_type = os.environ.get('BUMP_TYPE')
    if not bump_type:
        print("Error: BUMP_TYPE environment variable not set.", file=sys.stderr)
        sys.exit(1)

    tags = get_tags()
    latest_v = get_latest_semver(tags)

    next_v_str = ""
    is_prerelease = "true"

    if not latest_v:
        if bump_type == 'alpha':
            next_v_str = "0.2.0-alpha.1"
        else:
            print(f"Error: No existing tags found. Initial bump must be 'alpha' to start with 0.2.0-alpha.1.", file=sys.stderr)
            sys.exit(1)
    else:
        current_v = latest_v
        if bump_type == 'alpha':
            if current_v.prerelease and current_v.prerelease[0] == 'alpha':
                next_v = current_v.bump_prerelease(token='alpha')
            else: # New alpha series for current major.minor.patch or next patch
                # If current is final (e.g. 0.1.0), new alpha is 0.1.0-alpha.1
                # If current is rc (e.g. 0.1.0-rc.1), new alpha is 0.1.0-alpha.1
                # If current is beta (e.g. 0.1.0-beta.1), new alpha is 0.1.0-alpha.1
                next_v = semver.VersionInfo(current_v.major, current_v.minor, current_v.patch, prerelease='alpha.1')
            next_v_str = str(next_v)
        elif bump_type == 'beta':
            if current_v.prerelease and current_v.prerelease[0] == 'beta':
                next_v = current_v.bump_prerelease(token='beta')
            else: # New beta series, must come from alpha or be a new beta for a version
                # e.g., 0.1.0-alpha.2 -> 0.1.0-beta.1
                next_v = semver.VersionInfo(current_v.major, current_v.minor, current_v.patch, prerelease='beta.1')
            next_v_str = str(next_v)
        elif bump_type == 'rc':
            if current_v.prerelease and current_v.prerelease[0] == 'rc':
                next_v = current_v.bump_prerelease(token='rc')
            else: # New RC series
                next_v = semver.VersionInfo(current_v.major, current_v.minor, current_v.patch, prerelease='rc.1')
            next_v_str = str(next_v)
        elif bump_type == 'promote_to_final':
            if not current_v.prerelease:
                print(f"Error: Version {current_v} is already final. Cannot promote.", file=sys.stderr)
                sys.exit(1)
            next_v = current_v.finalize_version()
            next_v_str = str(next_v)
            is_prerelease = "false"
        elif bump_type == 'patch':
            base_v = current_v.finalize_version() # Ensure we bump from a stable part
            next_v = base_v.bump_patch()
            next_v_str = str(next_v)
            is_prerelease = "false"
        elif bump_type == 'minor':
            base_v = current_v.finalize_version()
            next_v = base_v.bump_minor()
            next_v_str = str(next_v)
            is_prerelease = "false"
        elif bump_type == 'major':
            base_v = current_v.finalize_version()
            next_v = base_v.bump_major()
            next_v_str = str(next_v)
            is_prerelease = "false"
        else:
            print(f"Error: Unknown BUMP_TYPE '{bump_type}'", file=sys.stderr)
            sys.exit(1)

    if not next_v_str.startswith('v'):
        next_v_tag = f"v{next_v_str}"
    else:
        next_v_tag = next_v_str


    print(f"Calculated next version: {next_v_tag}", file=sys.stderr)
    print(f"::set-output name=next_version::{next_v_tag}")
    print(f"::set-output name=is_prerelease::{is_prerelease}")

if __name__ == "__main__":
    main()



================================================
File: .github/workflows/ci.yml
================================================
name: Go CI
permissions:
  contents: read
  security-events: write

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    name: Test on Go ${{ matrix.go-version }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        go-version: [ '1.24' ]
    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 2

      - name: Set up Go
        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5.5.0
        with:
          go-version: ${{ matrix.go-version }}

      - name: Install Go tools
        run: |
          go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest
          go install github.com/mattn/goveralls@latest

      - name: Download Go modules
        run: |
          go mod download
          go mod verify

      - name: Run govulncheck
        uses: golang/govulncheck-action@b625fbe08f3bccbe446d94fbf87fcc875a4f50ee # v1.0.4

      - name: Lint source
        run: golangci-lint run ./...

      - name: Run tests with coverage
        run: go test -v ./... -race -coverprofile=coverage.out -covermode=atomic

      - name: Upload coverage to Coveralls
        if: matrix.go-version == '1.24' # Only upload from one Go version
        env:
          COVERALLS_TOKEN: ${{ secrets.COVERALLS_REPO_TOKEN }}
        run: |
          goveralls -coverprofile=coverage.out -service=github -repotoken $COVERALLS_TOKEN



================================================
File: .github/workflows/codeql.yml
================================================
# For most projects, this workflow file will not need changing; you simply need
# to commit it to your repository.
#
# You may wish to alter this file to override the set of languages analyzed,
# or to provide custom queries or build logic.
#
# ******** NOTE ********
# We have attempted to detect the languages in your repository. Please check
# the `language` matrix defined below to confirm you have the correct set of
# supported CodeQL languages.
#
name: "CodeQL"

on:
  push:
    branches: ["main"]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: ["main"]
  schedule:
    - cron: "0 0 * * 1"

permissions:
  contents: read

jobs:
  analyze:
    name: Analyze
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write

    strategy:
      fail-fast: false
      matrix:
        language: ["go"]
        # CodeQL supports [ $supported-codeql-languages ]
        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      # Initializes the CodeQL tools for scanning.
      - name: Initialize CodeQL
        uses: github/codeql-action/init@60168efe1c415ce0f5521ea06d5c2062adbeed1b # v3.28.17
        with:
          languages: ${{ matrix.language }}
          # If you wish to specify custom queries, you can do so here or in a config file.
          # By default, queries listed here will override any specified in a config file.
          # Prefix the list here with "+" to use these queries and those in the config file.

      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).
      # If this step fails, then you should remove it and run the build manually (see below)
      - name: Autobuild
        uses: github/codeql-action/autobuild@60168efe1c415ce0f5521ea06d5c2062adbeed1b # v3.28.17

      # â„¹ï¸ Command-line programs to run using the OS shell.
      # ğŸ“š See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun

      #   If the Autobuild fails above, remove it and uncomment the following three lines.
      #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.

      # - run: |
      #   echo "Run, Build Application using script"
      #   ./location_of_script_within_repo/buildscript.sh

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@60168efe1c415ce0f5521ea06d5c2062adbeed1b # v3.28.17
        with:
          category: "/language:${{matrix.language}}"



================================================
File: .github/workflows/dependency-review.yml
================================================
# Dependency Review Action
#
# This Action will scan dependency manifest files that change as part of a Pull Request,
# surfacing known-vulnerable versions of the packages declared or updated in the PR.
# Once installed, if the workflow run is marked as required,
# PRs introducing known-vulnerable packages will be blocked from merging.
#
# Source repository: https://github.com/actions/dependency-review-action
name: 'Dependency Review'
on: [pull_request]

permissions:
  contents: read

jobs:
  dependency-review:
    runs-on: ubuntu-latest
    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: 'Checkout Repository'
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: 'Dependency Review'
        uses: actions/dependency-review-action@38ecb5b593bf0eb19e335c03f97670f792489a8b # v4.7.0



================================================
File: .github/workflows/release.yml
================================================
name: Create Release

on:
  workflow_dispatch:
    inputs:
      bump_type:
        description: "Type of version bump (alpha, beta, rc, promote_to_final, patch, minor, major)"
        required: true
        default: "alpha"
        type: choice
        options:
          - alpha
          - beta
          - rc
          - promote_to_final
          - patch
          - minor
          - major
      draft_release:
        description: "Create as a draft release?"
        required: true
        default: "false"
        type: boolean

permissions:
  contents: read

jobs:
  determine_version:
    runs-on: ubuntu-latest
    outputs:
      next_version: ${{ steps.get_version.outputs.next_version }}
      is_prerelease: ${{ steps.get_version.outputs.is_prerelease }}
    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0 # Required to fetch all tags

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install semver

      - name: Determine next version
        id: get_version
        env:
          BUMP_TYPE: ${{ github.event.inputs.bump_type }}
        run: python .github/scripts/determine_next_version.py

  build_and_release:
    needs: determine_version
    if: needs.determine_version.outputs.next_version != ''
    runs-on: ubuntu-latest
    permissions:
      contents: write # Required to create releases and tags
    strategy:
      matrix:
        goos: [linux, windows, darwin]
        goarch: [amd64, arm64]
        exclude: # Add exclusions if some combinations are not needed/supported
          - goos: windows
            goarch: arm64 # Example: if windows arm64 is not a target

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Set up Go
        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5.5.0
        with:
          go-version: '1.21' # As per PRD

      - name: Set version output
        id: version_output
        run: |
          echo "NEXT_VERSION=${{ needs.determine_version.outputs.next_version }}" >> $GITHUB_ENV
          echo "IS_PRERELEASE=${{ needs.determine_version.outputs.is_prerelease }}" >> $GITHUB_ENV

      - name: Build application
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          VERSION: ${{ env.NEXT_VERSION }}
        run: |
          echo "Building for $GOOS/$GOARCH with version $VERSION"
          BINARY_NAME="almd"
          if [ "$GOOS" == "windows" ]; then
            BINARY_NAME="almd.exe"
          fi
          go build -v -o $BINARY_NAME -ldflags="-X 'main.version=$VERSION'" ./cmd/almd
          ls -la $BINARY_NAME # Verify binary exists

      - name: Archive binary
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          VERSION_NO_V: ${{ env.NEXT_VERSION }} # Assuming NEXT_VERSION has 'v' prefix
        run: |
          VERSION_TAG=${VERSION_NO_V#v} # Remove 'v' prefix for filename
          ARCHIVE_NAME="almd_${VERSION_TAG}_${GOOS}_${GOARCH}"
          BINARY_NAME="almd"
          if [ "$GOOS" == "windows" ]; then
            BINARY_NAME="almd.exe"
            zip "${ARCHIVE_NAME}.zip" $BINARY_NAME
            echo "ASSET_NAME=${ARCHIVE_NAME}.zip" >> $GITHUB_ENV
            echo "ASSET_PATH=${ARCHIVE_NAME}.zip" >> $GITHUB_ENV
          else
            tar -czvf "${ARCHIVE_NAME}.tar.gz" $BINARY_NAME
            echo "ASSET_NAME=${ARCHIVE_NAME}.tar.gz" >> $GITHUB_ENV
            echo "ASSET_PATH=${ARCHIVE_NAME}.tar.gz" >> $GITHUB_ENV
          fi
          ls -la $ASSET_PATH # Verify archive exists

      - name: Upload artifact for this job
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: almd-binaries-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.ASSET_PATH }}

  create_release_tag:
    needs: [determine_version, build_and_release] # Ensure build_and_release completes for all platforms
    runs-on: ubuntu-latest
    if: needs.determine_version.outputs.next_version != ''
    permissions:
      contents: write
    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0

      - name: Create Git Tag
        env:
          NEXT_VERSION: ${{ needs.determine_version.outputs.next_version }}
        run: |
          echo "Creating tag $NEXT_VERSION"
          git tag $NEXT_VERSION
          git push origin $NEXT_VERSION

      - name: Download all artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          path: release-artifacts # Download all artifacts to this directory
          # No specific name means download all artifacts from the run

      - name: List downloaded artifacts
        run: |
          ls -R release-artifacts

      - name: Create GitHub Release
        id: create_release
        uses: softprops/action-gh-release@da05d552573ad5aba039eaac05058a918a7bf631 # v2.2.2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ needs.determine_version.outputs.next_version }}
          name: Release ${{ needs.determine_version.outputs.next_version }}
          body: |
            Automated release for version ${{ needs.determine_version.outputs.next_version }}.
            See CHANGELOG.md for details (if available).
          draft: ${{ github.event.inputs.draft_release == 'true' }}
          prerelease: ${{ needs.determine_version.outputs.is_prerelease == 'true' }}
          files: |
            release-artifacts/almd-binaries-linux-amd64/*.tar.gz
            release-artifacts/almd-binaries-linux-arm64/*.tar.gz
            release-artifacts/almd-binaries-windows-amd64/*.zip
            release-artifacts/almd-binaries-darwin-amd64/*.tar.gz
            release-artifacts/almd-binaries-darwin-arm64/*.tar.gz



================================================
File: .github/workflows/scorecard.yml
================================================
# This workflow uses actions that are not certified by GitHub. They are provided
# by a third-party and are governed by separate terms of service, privacy
# policy, and support documentation.

name: Scorecard supply-chain security
on:
  # For Branch-Protection check. Only the default branch is supported. See
  # https://github.com/ossf/scorecard/blob/main/docs/checks.md#branch-protection
  branch_protection_rule:
  # To guarantee Maintained check is occasionally updated. See
  # https://github.com/ossf/scorecard/blob/main/docs/checks.md#maintained
  schedule:
    - cron: '26 19 * * 2'
  push:
    branches: [ "main" ]

# Declare default permissions as read only.
permissions: read-all

jobs:
  analysis:
    name: Scorecard analysis
    runs-on: ubuntu-latest
    # `publish_results: true` only works when run from the default branch. conditional can be removed if disabled.
    if: github.event.repository.default_branch == github.ref_name || github.event_name == 'pull_request'
    permissions:
      # Needed to upload the results to code-scanning dashboard.
      security-events: write
      # Needed to publish results and get a badge (see publish_results below).
      id-token: write
      # Uncomment the permissions below if installing in a private repository.
      # contents: read
      # actions: read

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: "Checkout code"
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: "Run analysis"
        uses: ossf/scorecard-action@f49aabe0b5af0936a0987cfb85d86b75731b0186 # v2.4.1
        with:
          results_file: results.sarif
          results_format: sarif
          # (Optional) "write" PAT token. Uncomment the `repo_token` line below if:
          # - you want to enable the Branch-Protection check on a *public* repository, or
          # - you are installing Scorecard on a *private* repository
          # To create the PAT, follow the steps in https://github.com/ossf/scorecard-action?tab=readme-ov-file#authentication-with-fine-grained-pat-optional.
          # repo_token: ${{ secrets.SCORECARD_TOKEN }}

          # Public repositories:
          #   - Publish results to OpenSSF REST API for easy access by consumers
          #   - Allows the repository to include the Scorecard badge.
          #   - See https://github.com/ossf/scorecard-action#publishing-results.
          # For private repositories:
          #   - `publish_results` will always be set to `false`, regardless
          #     of the value entered here.
          publish_results: true

          # (Optional) Uncomment file_mode if you have a .gitattributes with files marked export-ignore
          # file_mode: git

      # Upload the results as artifacts (optional). Commenting out will disable uploads of run results in SARIF
      # format to the repository Actions tab.
      - name: "Upload artifact"
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: SARIF file
          path: results.sarif
          retention-days: 5

      # Upload the results to GitHub's code scanning dashboard (optional).
      # Commenting out will disable upload of results to your repo's Code Scanning dashboard
      - name: "Upload to code-scanning"
        uses: github/codeql-action/upload-sarif@60168efe1c415ce0f5521ea06d5c2062adbeed1b # v3.28.17
        with:
          sarif_file: results.sarif



================================================
File: .github/workflows/slsa-provenance.yml
================================================
name: SLSA Provenance for Go

on:
  push:
    tags:
      - 'v*' # Trigger on version tags like v1.0.0, v2.3.4-alpha
  workflow_dispatch:
    inputs:
      ref:
        description: 'Git ref (branch, tag name e.g., "v1.2.3", or commit SHA) to build provenance for.'
        required: true
        default: 'main'
      draft_release:
        description: "If creating/updating a release, should it be a draft?"
        required: true
        default: "false"
        type: boolean

permissions:
  # Required for SLSA builder
  id-token: write # To sign the provenance.
  # Required for uploading assets to release & creating tags by proxy (if builder does that)
  contents: write
  # Required for SLSA builder to read workflow path
  actions: read

jobs:
  generate_provenance_args:
    runs-on: ubuntu-latest
    outputs:
      version_for_ldflags: ${{ steps.version_info.outputs.VERSION_FOR_LDFLAGS }}
      commit_sha: ${{ steps.version_info.outputs.COMMIT_SHA }}
      commit_date: ${{ steps.version_info.outputs.COMMIT_DATE }}
      tree_state: ${{ steps.version_info.outputs.TREE_STATE }}
      effective_release_tag: ${{ steps.version_info.outputs.EFFECTIVE_RELEASE_TAG }}
      is_prerelease_flag: ${{ steps.version_info.outputs.IS_PRERELEASE }}
      upload_release_assets: ${{ steps.version_info.outputs.UPLOAD_RELEASE_ASSETS }}
      actual_ref_to_checkout: ${{ steps.set_ref.outputs.ACTUAL_REF_TO_CHECKOUT }}

    steps:
      - name: Harden the runner
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: Determine Ref to Checkout
        id: set_ref
        run: |
          REF_TO_CHECKOUT=""
          if [[ "${{ github.event_name }}" == "push" && "${{ github.ref_type }}" == "tag" ]]; then
            REF_TO_CHECKOUT="${{ github.ref }}"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            REF_TO_CHECKOUT="${{ github.event.inputs.ref }}"
          else
            echo "::error::Unsupported event type or missing ref."
            exit 1
          fi
          echo "ACTUAL_REF_TO_CHECKOUT=$REF_TO_CHECKOUT" >> $GITHUB_OUTPUT
          echo "Resolved ref to checkout: $REF_TO_CHECKOUT"

      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ steps.set_ref.outputs.ACTUAL_REF_TO_CHECKOUT }}
          fetch-depth: 0 # Required for git describe --tags

      - name: Determine Version and Release Info
        id: version_info
        shell: bash
        run: |
          # Version for ldflags, e.g., v1.2.3 or v1.2.3-10-gabc123-dirty
          VERSION_FOR_LDFLAGS=$(git describe --tags --always --dirty --match="v*")
          echo "VERSION_FOR_LDFLAGS=$VERSION_FOR_LDFLAGS" >> $GITHUB_OUTPUT
          echo "Version for ldflags: $VERSION_FOR_LDFLAGS"

          COMMIT_SHA=$(git rev-parse HEAD)
          echo "COMMIT_SHA=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "Commit SHA: $COMMIT_SHA"

          COMMIT_DATE=$(git log -1 --pretty=%ct)
          echo "COMMIT_DATE=$COMMIT_DATE" >> $GITHUB_OUTPUT
          echo "Commit Date: $COMMIT_DATE"

          TREE_STATE="clean"
          if ! git diff --quiet; then
            TREE_STATE="dirty"
          fi
          echo "TREE_STATE=$TREE_STATE" >> $GITHUB_OUTPUT
          echo "Tree State: $TREE_STATE"

          EFFECTIVE_RELEASE_TAG=""
          UPLOAD_RELEASE_ASSETS="false"
          IS_PRERELEASE="false"

          if [[ "${{ github.event_name }}" == "push" && "${{ github.ref_type }}" == "tag" ]]; then
            # This is a tag push, github.ref_name is the tag (e.g., v1.2.3)
            EFFECTIVE_RELEASE_TAG="${{ github.ref_name }}"
            UPLOAD_RELEASE_ASSETS="true"
            echo "Event: Tag push. Effective Release Tag: $EFFECTIVE_RELEASE_TAG"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            # For workflow_dispatch, check if inputs.ref is a valid tag that exists
            # We use the already checked-out ref for git describe
            # If VERSION_FOR_LDFLAGS is a clean tag (no extra commits, no -dirty), then it's a tag.
            # And if that clean tag matches inputs.ref (if inputs.ref was intended as a tag).
            INPUT_REF="${{ github.event.inputs.ref }}"
            # Check if INPUT_REF is a simple tag name (e.g. v1.2.3) and if it matches the current fully resolved tag
            if [[ "$VERSION_FOR_LDFLAGS" == "$INPUT_REF" && ! "$VERSION_FOR_LDFLAGS" == *-* ]]; then
                EFFECTIVE_RELEASE_TAG="$INPUT_REF"
                UPLOAD_RELEASE_ASSETS="true"
                echo "Event: Workflow dispatch for tag. Effective Release Tag: $EFFECTIVE_RELEASE_TAG"
            else
                echo "Event: Workflow dispatch for branch/commit/non-clean-tag. No release will be created by default."
            fi
          fi
          echo "EFFECTIVE_RELEASE_TAG=$EFFECTIVE_RELEASE_TAG" >> $GITHUB_OUTPUT
          echo "UPLOAD_RELEASE_ASSETS=$UPLOAD_RELEASE_ASSETS" >> $GITHUB_OUTPUT

          if [[ -n "$EFFECTIVE_RELEASE_TAG" && ( "$EFFECTIVE_RELEASE_TAG" == *-alpha* || "$EFFECTIVE_RELEASE_TAG" == *-beta* || "$EFFECTIVE_RELEASE_TAG" == *-rc* ) ]]; then
            IS_PRERELEASE="true"
          fi
          echo "IS_PRERELEASE=$IS_PRERELEASE" >> $GITHUB_OUTPUT
          echo "Is Prerelease: $IS_PRERELEASE"

  build_with_provenance:
    needs: generate_provenance_args
    runs-on: ubuntu-latest # The SLSA builder runs on Ubuntu
    permissions:
      id-token: write # To sign the provenance.
      contents: write # To upload assets to release.
      actions: read   # To read the workflow path.
    strategy:
      matrix:
        goos: [linux, windows, darwin]
        goarch: [amd64, arm64]
        exclude:
          - goos: windows
            goarch: arm64

    steps:
      - name: Harden the runner
        uses: step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0 # v2.12.0
        with:
          egress-policy: audit

      - name: Run SLSA Go Builder
        uses: slsa-framework/slsa-github-generator/.github/workflows/builder_go_slsa3.yml@v2.1.0
        with:
          go-version: '1.21' # As per PRD
          config-file: .slsa-goreleaser/${{ matrix.os }}-${{ matrix.arch }}.yml
          evaluated-envs: "VERSION:${{ needs.generate_provenance_args.outputs.version_for_ldflags }},COMMIT:${{ needs.generate_provenance_args.outputs.commit_sha }},COMMIT_DATE:${{ needs.generate_provenance_args.outputs.commit_date }},TREE_STATE:${{ needs.generate_provenance_args.outputs.tree_state }}"
          upload-assets: ${{ needs.generate_provenance_args.outputs.upload_release_assets }}
          upload-tag-name: ${{ needs.generate_provenance_args.outputs.effective_release_tag }}
          prerelease: ${{ needs.generate_provenance_args.outputs.is_prerelease_flag }}
          draft-release: ${{ github.event.inputs.draft_release }}
          # private-repository: false # Default, set to true if this is a private repo and you accept name leakage
          # compile-builder: true # Only if needed for workaround for specific builder versions/issues



================================================
File: .slsa-goreleaser/darwin-amd64.yml
================================================
# SLSA Go builder configuration for Darwin AMD64
version: 1

env:
  - GO111MODULE=on
  - CGO_ENABLED=0

flags:
  - -trimpath
  # - -tags=netgo # Optional, include if your project uses netgo or other build tags

goos: darwin
goarch: amd64

# Entrypoint to compile.
main: ./cmd/almd

# Binary output name pattern.
# {{ .Os }} will be replaced by goos field.
# {{ .Arch }} will be replaced by goarch field.
binary: almd-{{ .Os }}-{{ .Arch }}

# ldflags generated dynamically in the workflow.
# These {{ .Env.VAR_NAME }} will be substituted by `evaluated-envs` in the GitHub workflow.
ldflags:
  - "-X main.version={{ .Env.VERSION }}"
  # - "-X main.Commit={{ .Env.COMMIT }}"
  # - "-X main.CommitDate={{ .Env.COMMIT_DATE }}"
  # - "-X main.TreeState={{ .Env.TREE_STATE }}"


================================================
File: .slsa-goreleaser/darwin-arm64.yml
================================================
# SLSA Go builder configuration for Darwin ARM64
version: 1

env:
  - GO111MODULE=on
  - CGO_ENABLED=0

flags:
  - -trimpath
  # - -tags=netgo # Optional, include if your project uses netgo or other build tags

goos: darwin
goarch: arm64

# Entrypoint to compile.
main: ./cmd/almd

# Binary output name pattern.
# {{ .Os }} will be replaced by goos field.
# {{ .Arch }} will be replaced by goarch field.
binary: almd-{{ .Os }}-{{ .Arch }}

# ldflags generated dynamically in the workflow.
# These {{ .Env.VAR_NAME }} will be substituted by `evaluated-envs` in the GitHub workflow.
ldflags:
  - "-X main.version={{ .Env.VERSION }}"
  # - "-X main.Commit={{ .Env.COMMIT }}"
  # - "-X main.CommitDate={{ .Env.COMMIT_DATE }}"
  # - "-X main.TreeState={{ .Env.TREE_STATE }}"


================================================
File: .slsa-goreleaser/linux-amd64.yml
================================================
# SLSA Go builder configuration for Linux AMD64
version: 1

env:
  - GO111MODULE=on
  - CGO_ENABLED=0

flags:
  - -trimpath
  # - -tags=netgo # Optional, include if your project uses netgo or other build tags

goos: linux
goarch: amd64

# Entrypoint to compile.
main: ./cmd/almd

# Binary output name pattern.
# {{ .Os }} will be replaced by goos field.
# {{ .Arch }} will be replaced by goarch field.
binary: almd-{{ .Os }}-{{ .Arch }}

# ldflags generated dynamically in the workflow.
# These {{ .Env.VAR_NAME }} will be substituted by `evaluated-envs` in the GitHub workflow.
ldflags:
  - "-X main.version={{ .Env.VERSION }}"
  # - "-X main.Commit={{ .Env.COMMIT }}"
  # - "-X main.CommitDate={{ .Env.COMMIT_DATE }}"
  # - "-X main.TreeState={{ .Env.TREE_STATE }}"


================================================
File: .slsa-goreleaser/linux-arm64.yml
================================================
# SLSA Go builder configuration for Linux ARM64
version: 1

env:
  - GO111MODULE=on
  - CGO_ENABLED=0

flags:
  - -trimpath
  # - -tags=netgo # Optional, include if your project uses netgo or other build tags

goos: linux
goarch: arm64

# Entrypoint to compile.
main: ./cmd/almd

# Binary output name pattern.
# {{ .Os }} will be replaced by goos field.
# {{ .Arch }} will be replaced by goarch field.
binary: almd-{{ .Os }}-{{ .Arch }}

# ldflags generated dynamically in the workflow.
# These {{ .Env.VAR_NAME }} will be substituted by `evaluated-envs` in the GitHub workflow.
ldflags:
  - "-X main.version={{ .Env.VERSION }}"
  # - "-X main.Commit={{ .Env.COMMIT }}"
  # - "-X main.CommitDate={{ .Env.COMMIT_DATE }}"
  # - "-X main.TreeState={{ .Env.TREE_STATE }}"


================================================
File: .slsa-goreleaser/windows-amd64.yml
================================================
# SLSA Go builder configuration for Windows AMD64
version: 1

env:
  - GO111MODULE=on
  - CGO_ENABLED=0

flags:
  - -trimpath
  # - -tags=netgo # Optional, include if your project uses netgo or other build tags

goos: windows
goarch: amd64

# Entrypoint to compile.
main: ./cmd/almd

# Binary output name pattern.
# {{ .Os }} will be replaced by goos field.
# {{ .Arch }} will be replaced by goarch field.
# The SLSA builder automatically appends .exe for windows.
binary: almd-{{ .Os }}-{{ .Arch }}

# ldflags generated dynamically in the workflow.
# These {{ .Env.VAR_NAME }} will be substituted by `evaluated-envs` in the GitHub workflow.
ldflags:
  - "-X main.version={{ .Env.VERSION }}"
  # - "-X main.Commit={{ .Env.COMMIT }}"
  # - "-X main.CommitDate={{ .Env.COMMIT_DATE }}"
  # - "-X main.TreeState={{ .Env.TREE_STATE }}"
